Running on clpc158.cs.ox.ac.uk
Running with: fsvi cl --data_training continual_learning_cifar --data_ood not_specified --model_type fsvi_cnn --optimizer adam --optimizer_var not_specified --momentum 0.0 --momentum_var 0.0 --schedule not_specified --architecture six_layers --activation relu --prior_mean 0.0 --prior_cov 0.01 --prior_covs 0.0 --prior_type bnn_induced --epochs 50 --start_var_opt 0 --batch_size 512 --learning_rate 0.0003 --learning_rate_var 0.001 --dropout_rate 0.0 --regularization 0.0 --inducing_points 0 --n_marginals 1 --n_condition 0 --inducing_input_type train_pixel_rand_0.5 --inducing_input_ood_data not_specified --inducing_input_ood_data_size 50000 --kl_scale normalized --feature_map_type not_specified --td_prior_scale 0.0 --feature_update 1 --n_samples 5 --n_samples_eval 5 --tau 1.0 --noise_std 1.0 --ind_lim ind_-1_1 --logging_frequency 10 --figsize 10 4 --seed 9 --save_path debug --name  --stochastic_prior_mean not_specified --batch_normalization_mod not_specified --final_layer_variational --kl_sup not_specified --init_logvar 0.0 0.0 --init_logvar_lin 0.0 0.0 --init_logvar_conv 0.0 0.0 --perturbation_param 0.01 --logroot ablation --subdir reproduce_main_results_2 --wandb_project not_specified --n_inducing_inputs 50 --n_inducing_inputs_first_task 10 --n_inducing_inputs_second_task 200 --inducing_inputs_bound 0.0 0.0 --inducing_inputs_add_mode 0 --logging 1 --use_val_split --not_use_val_split --coreset random --coreset_entropy_mode soft_lowest --coreset_entropy_offset 0.0 --coreset_kl_heuristic lowest --coreset_kl_offset 0.0 --coreset_elbo_heuristic lowest --coreset_elbo_offset 0.0 --coreset_elbo_n_samples not_specified --coreset_n_tasks not_specified --coreset_entropy_n_mixed 1 --n_coreset_inputs_per_task 200 --n_permuted_tasks 10 --n_omniglot_tasks 20 --epochs_first_task 200 --n_epochs_save_params not_specified --n_augment not_specified --augment_mode constant --n_valid same --learning_rate_first_task 5e-4 --save_alt --first_task_load_exp_path not_specified --only_task_id not_specified --loss_type 1 --n_omniglot_coreset_chars 2 --n_inducing_input_adjust_amount not_specified
WARNING: TensorFlow is set to only use CPU.
Jax is running on gpu
WARNING: TensorFlow is set to only use CPU.

Device: gpu

Input arguments:
 {
    "command":"cl",
    "data_training":"continual_learning_cifar",
    "data_ood":[
        "not_specified"
    ],
    "model_type":"fsvi_cnn",
    "optimizer":"adam",
    "optimizer_var":"not_specified",
    "momentum":0.0,
    "momentum_var":0.0,
    "schedule":"not_specified",
    "architecture":"six_layers",
    "activation":"relu",
    "prior_mean":"0.0",
    "prior_cov":"0.01",
    "prior_covs":[
        0.0
    ],
    "prior_type":"bnn_induced",
    "epochs":50,
    "start_var_opt":0,
    "batch_size":512,
    "learning_rate":0.0003,
    "learning_rate_var":0.001,
    "dropout_rate":0.0,
    "regularization":0.0,
    "inducing_points":0,
    "n_marginals":1,
    "n_condition":512,
    "inducing_input_type":"train_pixel_rand_0.5",
    "inducing_input_ood_data":[
        "not_specified"
    ],
    "inducing_input_ood_data_size":50000,
    "kl_scale":"normalized",
    "feature_map_jacobian":false,
    "feature_map_jacobian_train_only":false,
    "feature_map_type":"not_specified",
    "td_prior_scale":0.0,
    "feature_update":1,
    "full_cov":false,
    "n_samples":5,
    "n_samples_eval":5,
    "tau":1.0,
    "noise_std":1.0,
    "ind_lim":"ind_-1_1",
    "logging_frequency":10,
    "figsize":[
        "10",
        "4"
    ],
    "seed":9,
    "save_path":"debug",
    "save":false,
    "name":"",
    "evaluate":false,
    "resume_training":false,
    "no_final_layer_bias":false,
    "extra_linear_layer":false,
    "map_initialization":false,
    "stochastic_linearization":false,
    "grad_flow_jacobian":false,
    "stochastic_prior_mean":"not_specified",
    "batch_normalization":false,
    "batch_normalization_mod":"not_specified",
    "final_layer_variational":true,
    "kl_sup":"not_specified",
    "kl_sampled":false,
    "fixed_inner_layers_variational_var":false,
    "init_logvar":[
        0.0,
        0.0
    ],
    "init_logvar_lin":[
        0.0,
        0.0
    ],
    "init_logvar_conv":[
        0.0,
        0.0
    ],
    "perturbation_param":0.01,
    "debug":false,
    "logroot":"ablation",
    "subdir":"reproduce_main_results_2",
    "wandb_project":"not_specified",
    "n_inducing_inputs":50,
    "n_inducing_inputs_first_task":"10",
    "n_inducing_inputs_second_task":"200",
    "inducing_inputs_bound":[
        0.0,
        0.0
    ],
    "fix_shuffle":false,
    "use_generative_model":false,
    "debug_n_train":null,
    "inducing_inputs_add_mode":0,
    "inducing_input_adjustment":false,
    "not_use_coreset":false,
    "inducing_input_augmentation":false,
    "plotting":false,
    "logging":1,
    "use_val_split":false,
    "not_use_val_split":true,
    "coreset":"random",
    "coreset_entropy_mode":"soft_lowest",
    "coreset_entropy_offset":"0.0",
    "coreset_kl_heuristic":"lowest",
    "coreset_kl_offset":"0.0",
    "coreset_elbo_heuristic":"lowest",
    "coreset_elbo_offset":"0.0",
    "coreset_elbo_n_samples":5,
    "coreset_n_tasks":"not_specified",
    "coreset_entropy_n_mixed":1,
    "n_coreset_inputs_per_task":"200",
    "full_ntk":false,
    "constant_inducing_points":false,
    "n_permuted_tasks":10,
    "n_omniglot_tasks":20,
    "epochs_first_task":"200",
    "identity_cov":false,
    "n_epochs_save_params":"not_specified",
    "n_augment":"not_specified",
    "augment_mode":"constant",
    "n_valid":"same",
    "learning_rate_first_task":"5e-4",
    "save_alt":true,
    "save_first_task":false,
    "first_task_load_exp_path":"not_specified",
    "only_task_id":"not_specified",
    "loss_type":1,
    "only_trainable_head":false,
    "n_omniglot_coreset_chars":2,
    "omniglot_randomize_test_split":false,
    "omniglot_randomize_task_sequence":false,
    "n_inducing_input_adjust_amount":"not_specified",
    "save_all_params":false,
    "task":"continual_learning_cifar",
    "init_logvar_minval":0.0,
    "init_logvar_maxval":0.0,
    "init_logvar_lin_minval":0.0,
    "init_logvar_lin_maxval":0.0,
    "init_logvar_conv_minval":0.0,
    "init_logvar_conv_maxval":0.0
} 


MAP initialization: False
Full NTK computation: False
Stochastic linearization (posterior): False
init_logvar_lin_minval: -10.0
init_logvar_lin_maxval: -8.0
init_logvar_conv_minval: -10.0
init_logvar_conv_maxval: -8.0
Full NTK computation: False
Stochastic linearization (prior): False


Learning task 1
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------
  epoch    mean acc    t1 acc
-------  ----------  --------
      0       38.27     38.27
      1       42.91     42.91
      2       46.70     46.70
      3       48.64     48.64
      4       51.16     51.16
      5       52.00     52.00
      6       54.49     54.49
      7       55.12     55.12
      8       55.20     55.20
      9       56.99     56.99
     10       59.44     59.44
     11       59.85     59.85
     12       61.25     61.25
     13       60.58     60.58
     14       62.32     62.32
     15       59.57     59.57
     16       63.54     63.54
     17       63.90     63.90
     18       64.26     64.26
     19       63.93     63.93
     20       64.58     64.58
     21       65.66     65.66
     22       65.89     65.89
     23       66.61     66.61
     24       65.53     65.53
     25       65.01     65.01
     26       63.81     63.81
     27       67.43     67.43
     28       65.75     65.75
     29       67.67     67.67
     30       68.18     68.18
     31       68.16     68.16
     32       69.41     69.41
     33       68.18     68.18
     34       68.29     68.29
     35       68.70     68.70
     36       68.65     68.65
     37       69.96     69.96
     38       69.72     69.72
     39       69.81     69.81
     40       69.18     69.18
     41       70.64     70.64
     42       69.97     69.97
     43       69.15     69.15
     44       70.57     70.57
     45       70.31     70.31
     46       71.42     71.42
     47       70.91     70.91
     48       71.07     71.07
     49       71.68     71.68
     50       72.55     72.55
     51       70.77     70.77
     52       70.65     70.65
     53       72.16     72.16
     54       71.68     71.68
     55       72.69     72.69
     56       72.98     72.98
     57       73.05     73.05
     58       73.09     73.09
     59       73.15     73.15
     60       73.06     73.06
     61       74.09     74.09
     62       72.61     72.61
     63       74.14     74.14
     64       73.58     73.58
     65       72.67     72.67
     66       73.13     73.13
     67       73.92     73.92
     68       74.12     74.12
     69       73.90     73.90
     70       73.69     73.69
     71       73.15     73.15
     72       73.52     73.52
     73       73.92     73.92
     74       73.95     73.95
     75       73.22     73.22
     76       74.39     74.39
     77       74.25     74.25
     78       75.11     75.11
     79       75.46     75.46
     80       74.52     74.52
     81       75.48     75.48
     82       75.59     75.59
     83       73.56     73.56
     84       75.56     75.56
     85       75.14     75.14
     86       75.82     75.82
     87       75.64     75.64
     88       75.56     75.56
     89       74.90     74.90
     90       75.44     75.44
     91       75.79     75.79
     92       76.09     76.09
     93       75.84     75.84
     94       75.58     75.58
     95       75.85     75.85
     96       76.01     76.01
     97       75.09     75.09
     98       75.67     75.67
     99       76.01     76.01
    100       75.69     75.69
    101       75.94     75.94
    102       76.52     76.52
    103       76.01     76.01
    104       75.37     75.37
    105       76.39     76.39
    106       75.62     75.62
    107       76.20     76.20
    108       76.29     76.29
    109       76.09     76.09
    110       76.57     76.57
    111       76.21     76.21
    112       77.05     77.05
    113       75.54     75.54
    114       76.85     76.85
    115       75.46     75.46
    116       77.37     77.37
    117       77.31     77.31
    118       75.76     75.76
    119       77.18     77.18
    120       76.77     76.77
    121       76.47     76.47
    122       76.57     76.57
    123       76.32     76.32
    124       77.26     77.26
    125       74.94     74.94
    126       76.33     76.33
    127       77.22     77.22
    128       77.11     77.11
    129       77.68     77.68
    130       77.14     77.14
    131       77.40     77.40
    132       76.84     76.84
    133       76.46     76.46
    134       76.95     76.95
    135       78.03     78.03
    136       77.48     77.48
    137       77.44     77.44
    138       77.12     77.12
    139       76.30     76.30
    140       77.46     77.46
    141       77.41     77.41
    142       77.41     77.41
    143       77.15     77.15
    144       77.72     77.72
    145       76.87     76.87
    146       76.97     76.97
    147       77.64     77.64
    148       78.29     78.29
    149       77.73     77.73
    150       77.92     77.92
    151       78.21     78.21
    152       77.08     77.08
    153       77.75     77.75
    154       77.49     77.49
    155       76.72     76.72
    156       77.93     77.93
    157       77.46     77.46
    158       77.54     77.54
    159       78.16     78.16
    160       78.15     78.15
    161       77.97     77.97
    162       77.85     77.85
    163       77.17     77.17
    164       77.88     77.88
    165       77.99     77.99
    166       77.83     77.83
    167       77.91     77.91
    168       78.60     78.60
    169       78.28     78.28
    170       77.90     77.90
    171       78.00     78.00
    172       77.87     77.87
    173       77.82     77.82
    174       78.00     78.00
    175       78.47     78.47
    176       78.46     78.46
    177       78.62     78.62
    178       77.34     77.34
    179       77.92     77.92
    180       78.13     78.13
    181       78.37     78.37
    182       78.16     78.16
    183       78.33     78.33
    184       77.89     77.89
    185       78.14     78.14
    186       78.03     78.03
    187       77.94     77.94
    188       77.89     77.89
    189       77.77     77.77
    190       78.67     78.67
    191       78.23     78.23
    192       78.45     78.45
    193       78.63     78.63
    194       77.24     77.24
    195       78.30     78.30
    196       78.52     78.52
    197       77.93     77.93
    198       78.00     78.00
    199       78.60     78.60
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7860 
Accuracies (test): [0.786]
---


Learning task 2
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------  --------
  epoch    mean acc    t1 acc    t2 acc
-------  ----------  --------  --------
      0       56.46     78.42     34.50
      1       60.96     78.41     43.50
      2       62.62     78.65     46.60
      3       63.25     78.61     47.90
      4       65.17     78.54     51.80
      5       66.48     78.46     54.50
      6       67.44     78.38     56.50
      7       68.23     78.36     58.10
      8       69.13     78.37     59.90
      9       70.17     78.25     62.10
     10       70.75     78.29     63.20
     11       71.30     77.90     64.70
     12       71.68     78.16     65.20
     13       72.25     78.09     66.40
     14       72.36     77.93     66.80
     15       72.75     77.99     67.50
     16       73.02     77.93     68.10
     17       73.77     78.05     69.50
     18       73.75     77.90     69.60
     19       73.91     77.92     69.90
     20       74.08     77.95     70.20
     21       74.41     78.03     70.80
     22       74.95     77.91     72.00
     23       74.77     77.84     71.70
     24       75.11     77.73     72.50
     25       75.21     77.82     72.60
     26       75.40     77.80     73.00
     27       75.90     77.80     74.00
     28       75.76     77.72     73.80
     29       75.88     77.76     74.00
     30       76.14     77.98     74.30
     31       76.14     77.89     74.40
     32       75.98     77.67     74.30
     33       76.17     77.55     74.80
     34       76.27     77.73     74.80
     35       76.56     77.72     75.40
     36       76.61     77.51     75.70
     37       76.69     77.48     75.90
     38       76.66     77.21     76.10
     39       76.74     77.48     76.00
     40       76.82     77.44     76.20
     41       76.85     77.70     76.00
     42       76.97     77.34     76.60
     43       76.86     77.62     76.10
     44       77.08     77.26     76.90
     45       77.03     77.65     76.40
     46       77.03     77.46     76.60
     47       77.16     77.51     76.80
     48       77.00     77.61     76.40
     49       77.20     77.51     76.90
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7721 
Accuracies (test): [0.7751, 0.769]
---


Learning task 3
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------  --------  --------
  epoch    mean acc    t1 acc    t2 acc    t3 acc
-------  ----------  --------  --------  --------
      0       67.44     77.01     77.00     48.30
      1       69.99     76.38     76.90     56.70
      2       69.35     76.16     73.80     58.10
      3       70.52     77.05     75.50     59.00
      4       71.00     77.20     76.80     59.00
      5       70.83     77.19     75.40     59.90
      6       71.46     76.99     75.30     62.10
      7       72.00     76.90     76.30     62.80
      8       72.66     76.88     75.90     65.20
      9       72.39     76.78     74.40     66.00
     10       73.24     76.92     76.60     66.20
     11       73.13     77.10     75.80     66.50
     12       72.78     76.23     75.30     66.80
     13       73.60     77.00     75.70     68.10
     14       73.65     76.86     75.70     68.40
     15       74.00     76.41     76.50     69.10
     16       73.41     76.82     74.50     68.90
     17       74.40     76.60     76.40     70.20
     18       73.86     76.18     75.70     69.70
     19       74.59     76.58     75.50     71.70
     20       74.06     76.07     75.40     70.70
     21       74.66     76.88     75.70     71.40
     22       74.85     76.95     75.30     72.30
     23       74.43     76.89     74.90     71.50
     24       74.62     76.57     76.10     71.20
     25       74.70     76.49     75.60     72.00
     26       74.81     76.64     76.30     71.50
     27       74.36     76.38     74.20     72.50
     28       75.32     76.76     76.20     73.00
     29       75.53     76.99     76.30     73.30
     30       74.58     76.63     74.90     72.20
     31       75.40     76.69     75.70     73.80
     32       75.28     76.85     75.50     73.50
     33       74.96     76.58     75.30     73.00
     34       74.96     76.37     75.60     72.90
     35       74.88     76.34     76.00     72.30
     36       75.40     76.80     76.10     73.30
     37       75.64     76.61     76.00     74.30
     38       75.50     76.20     76.30     74.00
     39       75.25     76.56     75.90     73.30
     40       74.96     76.69     75.30     72.90
     41       75.47     76.52     76.30     73.60
     42       75.50     76.61     76.10     73.80
     43       75.30     76.00     76.10     73.80
     44       75.53     76.40     75.80     74.40
     45       75.50     76.61     75.40     74.50
     46       75.78     76.63     76.20     74.50
     47       75.43     76.48     75.70     74.10
     48       75.62     76.17     76.20     74.50
     49       75.89     76.88     75.90     74.90
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7589 
Accuracies (test): [0.7688, 0.759, 0.749]
---


Learning task 4
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------  --------  --------  --------
  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc
-------  ----------  --------  --------  --------  --------
      0       68.36     76.93     75.20     74.20     47.10
      1       71.43     76.83     76.00     74.60     58.30
      2       71.84     75.78     75.50     75.20     60.90
      3       72.48     76.33     76.00     74.40     63.20
      4       72.90     76.00     76.50     74.00     65.10
      5       72.89     76.07     76.60     73.70     65.20
      6       73.34     75.97     76.60     74.20     66.60
      7       73.38     75.81     76.30     73.90     67.50
      8       73.92     75.79     76.90     75.00     68.00
      9       74.08     75.72     76.90     74.80     68.90
     10       73.98     75.53     75.90     74.60     69.90
     11       74.00     75.58     75.70     74.20     70.50
     12       74.34     76.07     76.30     74.60     70.40
     13       74.40     76.09     77.20     73.20     71.10
     14       74.29     75.67     76.50     73.70     71.30
     15       74.31     75.76     76.30     73.60     71.60
     16       74.67     75.69     76.40     73.90     72.70
     17       74.57     75.77     75.50     73.90     73.10
     18       75.13     75.74     76.70     74.30     73.80
     19       75.22     75.90     76.60     74.30     74.10
     20       75.04     75.66     75.90     74.00     74.60
     21       75.11     75.66     76.60     73.90     74.30
     22       75.06     76.04     75.80     74.10     74.30
     23       75.54     75.97     76.70     74.10     75.40
     24       75.31     75.72     76.10     74.20     75.20
     25       75.13     75.62     75.50     74.40     75.00
     26       75.58     75.71     76.10     74.90     75.60
     27       75.70     75.82     76.90     74.50     75.60
     28       75.65     75.39     76.50     74.70     76.00
     29       75.43     75.42     75.60     74.50     76.20
     30       75.81     75.93     75.80     74.50     77.00
     31       75.55     75.38     76.20     74.60     76.00
     32       75.86     75.63     76.80     74.10     76.90
     33       75.77     75.59     76.70     73.50     77.30
     34       75.75     75.29     76.30     74.40     77.00
     35       76.13     75.32     77.00     75.00     77.20
     36       75.85     75.80     76.20     74.50     76.90
     37       75.76     75.64     75.60     74.40     77.40
     38       76.06     75.76     76.30     74.50     77.70
     39       75.84     75.75     76.10     74.00     77.50
     40       75.84     75.77     76.40     73.40     77.80
     41       75.89     75.64     75.70     74.00     78.20
     42       75.92     75.69     75.80     74.10     78.10
     43       76.06     75.62     76.60     73.60     78.40
     44       75.87     75.39     75.80     73.70     78.60
     45       76.03     75.74     75.60     74.40     78.40
     46       76.19     75.65     76.20     74.40     78.50
     47       76.14     75.76     75.90     74.00     78.90
     48       76.49     75.67     77.10     74.30     78.90
     49       76.43     75.71     76.80     74.20     79.00
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7643 
Accuracies (test): [0.7571, 0.768, 0.742, 0.79]
---


Learning task 5
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------  --------  --------  --------  --------
  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc
-------  ----------  --------  --------  --------  --------  --------
      0       70.46     75.98     76.80     74.10     79.30     46.10
      1       71.39     75.57     75.40     73.90     78.00     54.10
      2       71.97     75.85     75.90     73.80     78.50     55.80
      3       72.07     75.77     75.60     74.40     78.10     56.50
      4       72.29     75.86     75.90     73.80     77.90     58.00
      5       72.61     75.94     76.00     73.10     78.70     59.30
      6       73.07     75.84     75.70     73.90     79.00     60.90
      7       73.27     75.45     75.60     75.10     78.60     61.60
      8       73.35     75.83     76.20     74.30     78.40     62.00
      9       73.42     75.70     75.20     75.00     78.30     62.90
     10       73.42     75.98     75.40     73.90     78.70     63.10
     11       73.77     75.96     76.40     73.80     78.70     64.00
     12       73.74     75.98     75.60     74.60     78.70     63.80
     13       73.93     76.03     75.60     74.30     78.40     65.30
     14       73.75     75.73     75.00     74.40     78.20     65.40
     15       73.78     75.59     75.00     74.80     78.40     65.10
     16       74.30     75.82     76.10     74.50     78.40     66.70
     17       74.24     76.08     76.10     74.50     78.50     66.00
     18       73.93     75.84     75.40     73.60     78.30     66.50
     19       74.12     75.82     75.30     74.30     78.40     66.80
     20       74.26     75.89     75.60     73.90     78.90     67.00
     21       74.02     75.91     74.80     73.70     78.50     67.20
     22       74.18     75.92     75.20     73.70     78.30     67.80
     23       74.42     75.62     75.20     74.10     78.40     68.80
     24       74.47     75.97     75.30     74.30     78.50     68.30
     25       74.20     75.59     75.20     73.70     78.30     68.20
     26       74.47     75.63     75.80     73.70     78.30     68.90
     27       74.45     75.75     75.10     73.90     78.20     69.30
     28       74.81     76.03     75.40     74.20     79.20     69.20
     29       74.68     75.88     75.60     74.10     78.70     69.10
     30       74.67     76.07     75.30     73.70     78.20     70.10
     31       74.96     75.91     76.00     74.20     78.30     70.40
     32       74.88     75.81     75.70     73.30     78.80     70.80
     33       74.84     76.00     75.60     73.80     78.40     70.40
     34       75.07     76.05     75.70     74.40     77.90     71.30
     35       75.04     75.68     75.40     74.80     78.20     71.10
     36       74.38     75.32     75.00     73.60     77.50     70.50
     37       74.97     75.77     75.50     73.50     78.40     71.70
     38       75.07     75.75     75.30     74.60     78.00     71.70
     39       74.76     75.90     74.30     73.80     77.80     72.00
     40       74.58     75.70     74.20     73.70     77.50     71.80
     41       75.23     75.74     75.40     73.90     78.40     72.70
     42       75.01     75.96     75.00     73.50     78.10     72.50
     43       75.08     75.92     75.00     73.70     78.20     72.60
     44       74.94     75.52     74.20     74.20     77.90     72.90
     45       75.09     75.87     74.90     73.80     77.90     73.00
     46       74.89     75.83     75.00     72.50     77.80     73.30
     47       75.38     76.11     75.70     72.70     78.30     74.10
     48       75.10     75.79     74.40     73.50     78.10     73.70
     49       75.25     75.95     74.40     73.50     78.20     74.20
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7525 
Accuracies (test): [0.7595, 0.744, 0.735, 0.782, 0.742]
---


Learning task 6
Nomenclature:
	acc: accuracy in %
	t1: the first task

-------  ----------  --------  --------  --------  --------  --------  --------
  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc
-------  ----------  --------  --------  --------  --------  --------  --------
      0       72.19     75.93     74.60     72.80     78.20     74.00     57.60
      1       72.95     75.53     74.40     74.40     77.50     73.00     62.90
      2       72.92     75.22     74.80     72.90     77.70     73.50     63.40
      3       73.38     75.49     75.30     73.20     77.40     73.40     65.50
      4       73.34     75.34     74.50     73.80     77.50     72.60     66.30
      5       73.22     75.15     74.70     73.50     77.40     72.70     65.90
      6       73.79     75.52     75.00     72.90     78.00     73.50     67.80
      7       73.59     75.36     75.00     73.20     77.30     73.50     67.20
      8       74.00     75.61     74.40     73.40     77.40     73.70     69.50
      9       74.12     75.43     75.40     73.30     77.50     73.00     70.10
     10       74.16     75.24     74.70     73.30     77.60     73.20     70.90
     11       74.42     75.42     75.00     72.90     78.20     73.40     71.60
/users/timner/.conda/envs/fsvi-cl/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.6.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
/users/timner/.conda/envs/fsvi-cl/lib/python3.8/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  dtype=np.int):
/users/timner/.conda/envs/fsvi-cl/lib/python3.8/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/users/timner/.conda/envs/fsvi-cl/lib/python3.8/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
     12       74.31     75.28     74.90     73.20     78.00     73.30     71.20
     13       74.17     75.39     74.80     72.60     77.80     72.90     71.50
     14       74.26     75.37     75.00     72.50     77.70     73.00     72.00
     15       74.54     75.51     75.20     73.30     77.40     73.20     72.60
     16       74.64     75.17     74.90     73.70     77.60     73.30     73.20
     17       74.84     75.45     75.50     73.90     77.70     73.10     73.40
     18       74.47     75.31     75.10     72.70     77.80     72.70     73.20
     19       74.67     75.43     75.20     73.20     77.60     72.60     74.00
     20       74.83     75.45     75.50     73.50     77.70     72.70     74.10
     21       74.85     75.50     75.40     73.40     77.70     72.30     74.80
     22       75.13     75.49     76.00     73.70     78.20     72.10     75.30
     23       75.22     75.45     76.20     72.90     78.60     72.70     75.50
     24       74.61     75.23     74.50     73.70     77.30     71.20     75.70
     25       74.79     75.36     75.90     72.90     77.70     72.40     74.50
     26       75.02     75.25     75.40     74.00     77.40     72.10     76.00
     27       74.99     75.35     75.50     73.60     77.50     72.30     75.70
     28       74.96     75.39     74.60     74.10     77.10     72.50     76.10
     29       75.23     75.56     76.00     74.00     78.10     71.90     75.80
     30       75.08     75.57     75.10     73.20     77.80     72.10     76.70
     31       74.92     75.22     75.10     73.50     77.30     71.90     76.50
     32       74.86     75.45     74.70     72.90     77.40     72.10     76.60
     33       74.91     75.14     75.20     72.90     78.00     71.80     76.40
     34       75.14     75.26     75.70     72.90     77.10     72.50     77.40
     35       75.24     74.83     76.00     73.20     77.50     72.40     77.50
     36       75.17     75.05     75.80     73.40     77.50     71.40     77.90
     37       75.09     75.34     74.60     73.50     77.70     71.90     77.50
     38       75.32     75.21     75.90     73.20     77.40     72.10     78.10
     39       75.25     75.41     75.70     73.40     77.70     71.70     77.60
     40       75.39     75.62     75.60     73.00     77.80     72.50     77.80
     41       75.46     75.45     75.50     72.80     77.80     72.00     79.20
     42       75.44     75.31     75.70     72.50     77.90     72.30     78.90
     43       75.52     75.39     75.80     72.70     78.20     72.10     78.90
     44       75.67     75.51     76.00     72.80     78.50     72.30     78.90
     45       75.54     75.43     76.40     73.10     77.70     72.20     78.40
     46       75.23     75.27     75.60     72.50     77.70     72.00     78.30
     47       75.54     75.34     76.40     72.20     77.90     72.70     78.70
     48       75.78     75.37     76.70     72.50     78.00     72.50     79.60
     49       75.55     75.39     76.20     73.00     77.50     72.20     79.00
Adding inducing inputs to the coreset randomly
For tasks seen so far, 
---
Mean accuracy (test): 0.7555 
Accuracies (test): [0.7539, 0.762, 0.73, 0.775, 0.722, 0.79]
---


------------------- DONE -------------------


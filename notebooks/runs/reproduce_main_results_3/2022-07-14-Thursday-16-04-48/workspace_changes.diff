diff --git a/Makefile b/Makefile
index 15d63ea6..32bf2468 100644
--- a/Makefile
+++ b/Makefile
@@ -8,7 +8,7 @@ remote_path_483 = timner@cl483:/scratch/data/qixuan
 remote_path_oat_qixuan = qixeng@cl:/users/qixeng/workspace
 remote_path_arc = newc5095@arc:/data/stat-ecr/newc5095/code/git
 local_path = $(shell pwd)
-dest = $(remote_path_oat)
+dest = $(remote_path_483)
 
 
 .PHONY: rsync
diff --git a/benchmarking_tasks/continual_learning/method_cl_fsvi.py b/benchmarking_tasks/continual_learning/method_cl_fsvi.py
index 66031d27..50448678 100644
--- a/benchmarking_tasks/continual_learning/method_cl_fsvi.py
+++ b/benchmarking_tasks/continual_learning/method_cl_fsvi.py
@@ -11,11 +11,11 @@ import tensorflow as tf
 from jax import jit
 
 from benchmarking_tasks.continual_learning.method_cl_template import MethodCLTemplate
-import sfsvi.general_utils.log import (
+from fsvi_cl.general_utils.log import (
     Hyperparameters,
 )
-import sfsvi.utils.utils import get_minibatch
-import sfsvi.utils.utils import initialize_random_keys
+from fsvi_cl.utils.utils import get_minibatch
+from fsvi_cl.utils.utils import initialize_random_keys
 from fsvi_cl.src_cl.utils.args_cl import NOT_SPECIFIED
 from fsvi_cl.src_cl.utils.coreset.coreset import Coreset
 from fsvi_cl.src_cl.utils.coreset.coreset_selection import get_coreset_indices
diff --git a/benchmarking_tasks/continual_learning/trainer_cl.py b/benchmarking_tasks/continual_learning/trainer_cl.py
index 7c4415ea..b440a2e7 100644
--- a/benchmarking_tasks/continual_learning/trainer_cl.py
+++ b/benchmarking_tasks/continual_learning/trainer_cl.py
@@ -3,11 +3,11 @@ from typing import Callable
 import pandas as pd
 
 from benchmarking_tasks.continual_learning.method_cl_template import MethodCLTemplate
-import sfsvi.general_utils.log import Hyperparameters
-import sfsvi.general_utils.log import create_logdir
-import sfsvi.general_utils.log import save_chkpt
-import sfsvi.general_utils.log import save_kwargs
-import sfsvi.general_utils.log import set_up_logging
+from fsvi_cl.general_utils.log import Hyperparameters
+from fsvi_cl.general_utils.log import create_logdir
+from fsvi_cl.general_utils.log import save_chkpt
+from fsvi_cl.general_utils.log import save_kwargs
+from fsvi_cl.general_utils.log import set_up_logging
 from fsvi_cl.src_cl.utils.args_cl import NOT_SPECIFIED
 from fsvi_cl.src_cl.utils.data_loaders.get_data import make_iterators
 from fsvi_cl.src_cl.utils.data_loaders.get_data import prepare_data
diff --git a/cli.py b/cli.py
index d06fa9b2..4a904949 100644
--- a/cli.py
+++ b/cli.py
@@ -1,8 +1,5 @@
-import pdb
-from typing import Dict
-
 import argparse
-import sys
+from typing import Dict
 
 from fsvi_cl.baselines.frcl.run_frcl import run_frcl
 from fsvi_cl.baselines.fromp.run_fromp import run_fromp
@@ -22,15 +19,12 @@ print("Jax is running on", xla_bridge.get_backend().platform)
 
 from fsvi_cl.src_cl.utils.args_cl import add_cl_args
 from fsvi_cl.run_cl import run as cl_run
-from run_base import run as base_run
-from run_base import add_base_args
 
 
 def define_parser():
     parser = argparse.ArgumentParser(description="Function-Space Variation Inference")
     subparsers = parser.add_subparsers(required=True, dest="command")
     add_cl_args(subparsers.add_parser("cl"))
-    add_base_args(subparsers.add_parser("base"))
     return parser
 
 
@@ -61,8 +55,6 @@ def cli():
 
     if args.command == "cl":
         cl_run(args)
-    elif args.command == "base":
-        base_run(args)
     else:
         raise NotImplementedError(f"Unknown command {args.command}")
 
diff --git a/environment.yml b/environment.yml
index a76b771a..934b4172 100644
--- a/environment.yml
+++ b/environment.yml
@@ -41,3 +41,7 @@ dependencies:
     - retry==0.9.2
     - dm-haiku==0.0.4
     - optax==0.0.2
+    - dm-sonnet
+    - gpflow
+    - tensorflow-probability
+    - tensorflow-addons
diff --git a/fsvi_cl/baselines/frcl/continual_learning_frcl.py b/fsvi_cl/baselines/frcl/continual_learning_frcl.py
index 58958e3b..1b35c355 100644
--- a/fsvi_cl/baselines/frcl/continual_learning_frcl.py
+++ b/fsvi_cl/baselines/frcl/continual_learning_frcl.py
@@ -131,7 +131,7 @@ def train(
         elif select_method == "random_choice":
             x_inducing_init = x_inducing
         elif select_method == "random_noise":
-            x_inducing = tf.random.uniform((n_inputs_to_add,) + input_shape[1:], dtype=tf.float64)
+            x_inducing = tf.random.uniform((n_inputs_to_add,) + tuple(input_shape[1:]), dtype=tf.float64)
             x_inducing_init = x_inducing
         elif select_method == "random_per_class":
             x_candidate, y_candidate = x_discr.numpy(), y_discr.numpy()
diff --git a/fsvi_cl/baselines/frcl/run_frcl.py b/fsvi_cl/baselines/frcl/run_frcl.py
index 5bd1c91d..afb41a7c 100644
--- a/fsvi_cl/baselines/frcl/run_frcl.py
+++ b/fsvi_cl/baselines/frcl/run_frcl.py
@@ -16,7 +16,7 @@ import tensorflow as tf
 # import jax
 # jax.config.update('jax_platform_name', 'cpu')
 from fsvi_cl.baselines.frcl.continual_learning_frcl import train
-import sfsvi.general_utils.log import (
+from fsvi_cl.general_utils.log import (
     create_logdir,
     Hyperparameters,
     set_up_logging,
@@ -114,6 +114,7 @@ def main(args, orig_cmd=None):
     hparams.from_argparse(args)
     if hparams.no_artifact:
         logger = None
+        logdir = None
     else:
         logdir = create_logdir(hparams.logroot, hparams.subdir, cmd=orig_cmd)
         logger = set_up_logging(log_path=logdir / "log")
diff --git a/fsvi_cl/baselines/fromp/continual_learning_fromp.py b/fsvi_cl/baselines/fromp/continual_learning_fromp.py
index d1c4180f..19ab7ec4 100644
--- a/fsvi_cl/baselines/fromp/continual_learning_fromp.py
+++ b/fsvi_cl/baselines/fromp/continual_learning_fromp.py
@@ -2,7 +2,7 @@ import numpy as np
 import torch
 import jax
 
-import sfsvi.utils.utils import select_inducing_inputs
+from fsvi_cl.utils.utils import select_inducing_inputs
 from fsvi_cl.src_cl.utils.coreset.coreset_heuristics import add_by_random_per_class
 from fsvi_cl.src_cl.utils.data_loaders.get_data import make_iterators, prepare_data
 from fsvi_cl.baselines.fromp.models_fromp import MLP, SplitMLP
diff --git a/fsvi_cl/baselines/fromp/run_fromp.py b/fsvi_cl/baselines/fromp/run_fromp.py
index 0e06919d..f849f7c0 100644
--- a/fsvi_cl/baselines/fromp/run_fromp.py
+++ b/fsvi_cl/baselines/fromp/run_fromp.py
@@ -56,7 +56,7 @@ import argparse
 import numpy as np
 import torch
 from fsvi_cl.baselines.fromp.continual_learning_fromp import train
-import sfsvi.general_utils.log import (
+from fsvi_cl.general_utils.log import (
     create_logdir,
     Hyperparameters,
     set_up_logging,
@@ -141,6 +141,7 @@ def main(args, orig_cmd=None):
     hparams.from_argparse(args)
     if hparams.no_artifact:
         logger = None
+        logdir = None
     else:
         logdir = create_logdir(hparams.logroot, hparams.subdir, cmd=orig_cmd)
         logger = set_up_logging(log_path=logdir / "log")
diff --git a/fsvi_cl/baselines/vcl/alg/deprecated_data_loading.py b/fsvi_cl/baselines/vcl/alg/deprecated_data_loading.py
index 3167d850..d4754c4e 100644
--- a/fsvi_cl/baselines/vcl/alg/deprecated_data_loading.py
+++ b/fsvi_cl/baselines/vcl/alg/deprecated_data_loading.py
@@ -5,7 +5,7 @@ from typing import Tuple
 
 import numpy as np
 
-import sfsvi.utils.utils import TUPLE_OF_TWO_TUPLES
+from fsvi_cl.utils.utils import TUPLE_OF_TWO_TUPLES
 from fsvi_cl.src_cl.utils.data_loaders.mnist_and_cifar import \
     select_task_examples
 from fsvi_cl.src_cl.utils.datasets_cl import DatasetSplit
diff --git a/fsvi_cl/baselines/vcl/cl_vcl.py b/fsvi_cl/baselines/vcl/cl_vcl.py
index e7874d54..34a37687 100644
--- a/fsvi_cl/baselines/vcl/cl_vcl.py
+++ b/fsvi_cl/baselines/vcl/cl_vcl.py
@@ -4,7 +4,7 @@ import numpy as np
 
 from fsvi_cl.baselines.vcl.alg.data_generator import CustomGenerator, is_single_head
 from fsvi_cl.baselines.vcl.alg import vcl, coreset
-import sfsvi.general_utils.log import save_chkpt, create_logdir, set_up_logging
+from fsvi_cl.general_utils.log import save_chkpt, create_logdir, set_up_logging
 
 
 def main(args, orig_cmd=None):
@@ -12,6 +12,7 @@ def main(args, orig_cmd=None):
     print(f"Available GPUs, {tf.config.list_physical_devices('GPU')}")
     if args.no_artifact:
         logger = None
+        logdir = None
     else:
         logdir = create_logdir(args.logroot, args.subdir, cmd=orig_cmd)
         logger = set_up_logging(log_path=logdir / "log")
diff --git a/fsvi_cl/general_utils/kl.py b/fsvi_cl/general_utils/kl.py
index ac90a3d9..9bbfc23b 100644
--- a/fsvi_cl/general_utils/kl.py
+++ b/fsvi_cl/general_utils/kl.py
@@ -1,39 +1,6 @@
 from jax import numpy as jnp
 
 
-def jax_kl_general(mean_p, mean_q, cov_p, cov_q, noise=0.0, breakdown=False):
-    """
-    calculate KL(p || q)
-    """
-    # convert from float32 to float64 to avoid overflow error in matrix multiplicaiton
-    # mean_p, mean_q, cov_p, cov_q = list(map(lambda x: np.array(x).astype(np.float64), [mean_p, mean_q, cov_p, cov_q]))
-
-    noise_matrix = jnp.eye(cov_q.shape[0], dtype=jnp.float32) * noise
-    cov_q += noise_matrix
-    cov_p += noise_matrix
-
-    D = mean_q.shape[0]
-    diff = mean_q - mean_p
-
-    # np.linalg.det uses Cholesky decomposition
-    det_term = jax_robust_det_kl_term_numpy(cov_p=cov_p, cov_q=cov_q)
-    inv_cov_q = jnp.linalg.inv(cov_q)
-    tr_term = jnp.trace(jnp.matmul(inv_cov_q, cov_p))
-    quad_term = jnp.matmul(jnp.matmul(diff.T, inv_cov_q), diff)
-    # print("inv_cov_q", inv_cov_q)
-    # print("singular values of inv_cov_q", jnp.linalg.svd(inv_cov_q)[1])
-    # print("singular values of cov_p", jnp.linalg.svd(cov_p)[1])
-    # print("tr_term", tr_term)
-    # print("det_term", det_term)
-    # print("quad_term", quad_term)
-    # print("D", D)
-    kl = 0.5 * (tr_term + det_term + quad_term - D)
-    if breakdown:
-        return kl, {"det_term": det_term, "tr_term": tr_term, "quad_term": quad_term}
-    else:
-        return kl
-
-
 def jax_kl_diag(mean_q, mean_p, cov_q, cov_p, noise=0.0) -> float:
     """
     calculate KL(q || p)
@@ -65,23 +32,3 @@ def jax_robust_det_kl_term_numpy(cov_p, cov_q):
     det_term_q = sign * log_det
     det_term = det_term_q - det_term_p
     return det_term
-
-
-def jax_kl_multioutput(mean_p, mean_q, cov_p, cov_q, noise=0.0, diag_kl=False, breakdown=False):
-    function_KL = 0
-    ndim = cov_p.ndim
-    terms = []
-    for i in range(cov_p.shape[-1]):
-        cov_p_tp = cov_p[:, :, i, i] if ndim == 4 else cov_p[:, :, i]
-        mean_p_tp = mean_p[:, i]
-        cov_q_tp = cov_q[:, :, i, i] if ndim == 4 else cov_q[:, :, i]
-        mean_q_tp = mean_q[:, i]
-        if diag_kl:
-            kl = jax_kl_diag(mean_p_tp, mean_q_tp, cov_p_tp, cov_q_tp, noise=noise)
-        else:
-            kl = jax_kl_general(mean_p_tp, mean_q_tp, cov_p_tp, cov_q_tp, noise=noise, breakdown=breakdown)
-            if breakdown:
-                terms.append(kl[1])
-                kl = kl[0]
-        function_KL += kl
-    return function_KL if not breakdown else (function_KL, terms)
diff --git a/fsvi_cl/general_utils/log.py b/fsvi_cl/general_utils/log.py
index 5d7da40b..e051d4b7 100644
--- a/fsvi_cl/general_utils/log.py
+++ b/fsvi_cl/general_utils/log.py
@@ -4,15 +4,12 @@ import json
 import logging
 import os
 import pickle
-import socket
 import subprocess
 import sys
 from datetime import datetime
 from pathlib import Path
 from typing import Dict
 
-import psutil
-import torch
 from retry import retry
 
 
@@ -100,19 +97,6 @@ def save_command_line(path, cmd=None):
         f.write("python " + " ".join(sys.argv if cmd is None else cmd))
 
 
-def is_azure():
-    return os.environ.get("IS_AZURE") == "1"
-
-
-def num_available_gpus():
-    return torch.cuda.device_count()
-
-
-def running_in_slurm():
-    job_id = os.environ.get("SLURM_JOB_ID")
-    return job_id is not None
-
-
 def save_slurm_status(path):
     job_id = os.environ.get("SLURM_JOB_ID")
     array_job_id = os.environ.get("SLURM_ARRAY_JOB_ID")
diff --git a/fsvi_cl/general_utils/ntk_utils.py b/fsvi_cl/general_utils/ntk_utils.py
index d811eccb..6a1642bd 100644
--- a/fsvi_cl/general_utils/ntk_utils.py
+++ b/fsvi_cl/general_utils/ntk_utils.py
@@ -8,7 +8,7 @@ import tree
 from jax import numpy as jnp, jit
 from tqdm import tqdm
 
-import sfsvi.general_utils.custom_empirical_ntk import empirical_ntk_fn
+from fsvi_cl.general_utils.custom_empirical_ntk import empirical_ntk_fn
 
 NESTED_OR_ARRAY = Union[hk.Params, jnp.ndarray, np.ndarray]
 
@@ -42,60 +42,6 @@ def diag_ntk_for_loop(
     return cov
 
 
-def diag_ntk_for_loop_no_jit(
-    apply_fn: Callable, x: jnp.ndarray, params: hk.Params, sigma: hk.Params, diag=True
-):
-    """
-
-    @param apply_fn: should have signature (params, inputs, **kwargs) and should return an np.ndarray outputs.
-    @param x:
-    @param params:
-    @param sigma:
-    @return:
-        diag_ntk_sum_array: array of shape (batch_dim, output_dim)
-    """
-    assert diag
-    kernel_fn = empirical_ntk_fn(
-        f=apply_fn, trace_axes=(), diagonal_axes=(-1,), vmap_axes=0, implementation=2,
-    )
-
-    def _one_iteration(one_sample_x: jnp.ndarray):
-        return kernel_fn(one_sample_x, None, params, sigma)
-
-    covs = []
-    for i in tqdm(range(x.shape[0]), desc="using neural-tangent repo implementation for per-sample ntk evaluation"):
-        covs.append(_one_iteration(x[i : i + 1]))
-    cov = jnp.squeeze(jnp.array(covs), axis=(1, 2))
-    return cov
-
-
-def diag_ntk_vmap_no_jit(
-    apply_fn: Callable, x: jnp.ndarray, params: hk.Params, sigma: hk.Params, diag=True
-):
-    """
-
-    @param apply_fn: should have signature (params, inputs, **kwargs) and should return an np.ndarray outputs.
-    @param x:
-    @param params:
-    @param sigma:
-    @return:
-        diag_ntk_sum_array: array of shape (batch_dim, output_dim)
-    """
-    assert diag
-    kernel_fn = empirical_ntk_fn(
-        f=apply_fn, trace_axes=(), diagonal_axes=(-1,), vmap_axes=0, implementation=2,
-    )
-
-    def _one_iteration(one_sample_x: jnp.ndarray):
-        expanded = jnp.expand_dims(one_sample_x, axis=0)
-        return kernel_fn(expanded, None, params, sigma)
-
-    vmapped_fn = jax.vmap(_one_iteration)
-    covs = vmapped_fn(x)
-    cov = jnp.squeeze(jnp.array(covs), axis=(1, 2))
-    return cov
-
-
 def neural_tangent_ntk(
     apply_fn: Callable, x: jnp.ndarray, params: hk.Params, sigma: hk.Params, diag=False
 ):
@@ -131,48 +77,6 @@ def neural_tangent_ntk(
     return reshaped_cov
 
 
-def implicit_ntk(fwd_fn: Callable, params: hk.Params, sigma: hk.Params, diag=False):
-    """
-    Calculate J * diag(sigma) * J^T, where J is Jacobian of model with respect to model parameters
-     using implicit implementation and einsum
-
-    @param fwd_fn: a function that only takes in parameters and returns model output of shape (batch_dim, output_dim)
-    @param params: the model parameters
-    @param sigma: it has the same structure and array shapes as the parameters of model
-    @param diag: if True, only calculating the diagonal of NTK
-    @return:
-        diag_ntk_sum_array: array of shape (batch_dim, output_dim) if diag==True else
-         (batch_dim, output_dim, batch_dim, output_dim)
-    """
-
-    def delta_vjp_jvp(delta):
-        def delta_vjp(delta):
-            return jax.vjp(fwd_fn, params)[1](delta)
-
-        if sigma is None:
-            vj_prod = delta_vjp(delta)
-        else:
-            vj_prod = tree.map_structure(
-                lambda x1, x2: x1 * x2, sigma, delta_vjp(delta)[0]
-            )
-            vj_prod = (vj_prod,)
-
-        return jax.jvp(fwd_fn, (params,), vj_prod)[1]
-
-    predict_struct = jax.eval_shape(fwd_fn, params)
-    fx_dummy = jnp.ones(predict_struct.shape, predict_struct.dtype)
-    gram_matrix = jax.jacobian(delta_vjp_jvp)(fx_dummy)
-    return _reshape_and_take_diag(gram_matrix) if diag else gram_matrix
-
-
-def _reshape_and_take_diag(gram_matrix):
-    batch_dim, output_dim = gram_matrix.shape[:2]
-    gram_matrix_2D = jnp.reshape(gram_matrix, (batch_dim * output_dim, -1))
-    diag_gram = jnp.diag(gram_matrix_2D)
-    diag_gram_reshaped = jnp.reshape(diag_gram, (batch_dim, output_dim))
-    return diag_gram_reshaped
-
-
 # @partial(jit, static_argnums=(0,3,4,))
 def explicit_ntk(
     fwd_fn: Callable, params: hk.Params, sigma: hk.Params, diag, grad_flow_jacobian,
@@ -207,23 +111,6 @@ def explicit_ntk(
         # jac_sigma_product has the same shape as jac_2D
         jac_sigma_product = jnp.multiply(jac_2D, sigma_flatten)
 
-        # ## Multivariate final-layer:
-        # if len(sigma.shape) == 2:
-        #     sigma = jnp.matmul(sigma, sigma.transpose())
-        #     sigma += jnp.eye(sigma.shape[-1]) * 1e-7
-        # elif len(sigma.shape) == 3:
-        #     sigma = jnp.matmul(sigma, sigma.transpose([0,2,1]))
-        #     sigma += jnp.repeat(jnp.expand_dims(jnp.eye(sigma.shape[-1]) * 1e-7, 0), repeats=sigma.shape[0], axis=0)
-        # else:
-        #     raise NotImplementedError
-        #
-        # if len(jac.shape) == 3:
-        #     jac_sigma_product = jnp.matmul(jac.transpose([0, 2, 1]), sigma).reshape((batch_dim * output_dim, -1))
-        # elif len(jac.shape) == 4:
-        #     jac_sigma_product = jnp.matmul(jac.transpose([0, 2, 3, 1]), sigma).reshape((batch_dim * output_dim, -1))
-        # else:
-        #     raise NotImplementedError
-
         # diag_ntk has shape (batch_dim * output_dim,)
         if diag:
             ntk = jnp.einsum("ij,ji->i", jac_sigma_product, jac_2D.T)
@@ -238,24 +125,3 @@ def explicit_ntk(
     diag_ntk = tree.map_structure(_get_diag_ntk, jacobian, sigma)
     diag_ntk_sum_array = jnp.stack(tree.flatten(diag_ntk), axis=0).sum(axis=0)
     return diag_ntk_sum_array
-
-
-def uncat_as(ref: NESTED_OR_ARRAY, x: np.ndarray) -> NESTED_OR_ARRAY:
-    """
-    Does the reverse of `np.concatenate` and `flatten`. Works with both tree and ndarray (jax or numpy).
-
-    Reshape x to have the same structure or shape as ref.
-    """
-    is_nested = tree.is_nested(ref)
-    if is_nested:
-        seq = tree.flatten(ref)
-        result = []
-        processed = 0
-        for s in seq:
-            result.append(x[processed : processed + s.size].reshape(s.shape))
-            processed += s.size
-        result = tree.unflatten_as(ref, result)
-    else:
-        result = x.reshape(ref.shape)
-
-    return result
diff --git a/fsvi_cl/models/custom_cnns.py b/fsvi_cl/models/custom_cnns.py
index 30e0b6d5..cefcd94e 100644
--- a/fsvi_cl/models/custom_cnns.py
+++ b/fsvi_cl/models/custom_cnns.py
@@ -4,11 +4,11 @@ import haiku as hk
 import jax.numpy as jnp
 
 from haiku import BatchNorm as BatchNorm_reg
-import sfsvi.utils.haiku_mod import BatchNorm as BatchNorm_mod
+from fsvi_cl.models.haiku_mod import BatchNorm as BatchNorm_mod
 
-import sfsvi.utils.haiku_mod import conv2D_stochastic, dense_stochastic_hk
-import sfsvi.utils.jax_utils import KeyHelper
-import sfsvi.utils.utils import get_inner_layers_stochastic
+from fsvi_cl.models.haiku_mod import conv2D_stochastic, dense_stochastic_hk
+from fsvi_cl.general_utils.jax_utils import KeyHelper
+from fsvi_cl.utils.utils import get_inner_layers_stochastic
 
 
 class CNN(hk.Module):
diff --git a/fsvi_cl/models/custom_mlps.py b/fsvi_cl/models/custom_mlps.py
index 3acf29a0..85a85b15 100644
--- a/fsvi_cl/models/custom_mlps.py
+++ b/fsvi_cl/models/custom_mlps.py
@@ -1,15 +1,14 @@
-from typing import Callable, Sequence
+from typing import Callable
 
 import haiku as hk
-import jax
 import jax.numpy as jnp
 
 from haiku import BatchNorm as BatchNorm_reg
-import sfsvi.utils.haiku_mod import BatchNorm as BatchNorm_mod
+from fsvi_cl.models.haiku_mod import BatchNorm as BatchNorm_mod
 
-import sfsvi.utils.haiku_mod import conv2D_stochastic, dense_stochastic_hk
-import sfsvi.utils.jax_utils import KeyHelper
-import sfsvi.utils.utils import get_inner_layers_stochastic
+from fsvi_cl.models.haiku_mod import dense_stochastic_hk
+from fsvi_cl.general_utils.jax_utils import KeyHelper
+from fsvi_cl.utils.utils import get_inner_layers_stochastic
 
 
 class MLP(hk.Module):
diff --git a/fsvi_cl/models/networks.py b/fsvi_cl/models/networks.py
index 0003ef4c..f2b8b8ce 100644
--- a/fsvi_cl/models/networks.py
+++ b/fsvi_cl/models/networks.py
@@ -7,14 +7,14 @@ import jax
 import jax.numpy as jnp
 from jax import jit
 
-import sfsvi.models import custom_cnns
-import sfsvi.models import custom_mlps
-import sfsvi.utils.haiku_mod import gaussian_sample_pytree
-import sfsvi.utils.haiku_mod import partition_all_params
-import sfsvi.utils.haiku_mod import partition_params_final_layer_bnn
-import sfsvi.utils.haiku_mod import predicate_batchnorm
-import sfsvi.utils.haiku_mod import predicate_mean
-import sfsvi.utils.utils_linearization import convert_predict_f_only_mean
+from fsvi_cl.models import custom_cnns
+from fsvi_cl.models import custom_mlps
+from fsvi_cl.models.haiku_mod import gaussian_sample_pytree
+from fsvi_cl.models.haiku_mod import partition_all_params
+from fsvi_cl.models.haiku_mod import partition_params_final_layer_bnn
+from fsvi_cl.models.haiku_mod import predicate_batchnorm
+from fsvi_cl.models.haiku_mod import predicate_mean
+from fsvi_cl.src_cl.utils.utils_linearization import convert_predict_f_only_mean
 
 relu = jax.nn.relu
 tanh = jnp.tanh
diff --git a/fsvi_cl/run_cl.py b/fsvi_cl/run_cl.py
index 6940f632..f435bb29 100644
--- a/fsvi_cl/run_cl.py
+++ b/fsvi_cl/run_cl.py
@@ -21,7 +21,7 @@ sys.path.insert(0, root_folder)
 sys.path.insert(0, os.path.join(root_folder, "function_space_variational_inference"))
 from benchmarking_tasks.continual_learning.trainer_cl import TrainerCL
 from benchmarking_tasks.continual_learning.method_cl_fsvi import MethodCLFSVI
-import sfsvi.general_utils.log import save_kwargs
+from fsvi_cl.general_utils.log import save_kwargs
 from fsvi_cl.src_cl.utils.args_cl import add_cl_args, NOT_SPECIFIED
 
 tf_cpu_only = True  # TODO: check how this affects determinism -- keep set to False
diff --git a/fsvi_cl/src_cl/exps/ablation/configs/reproduce_main_results.py b/fsvi_cl/src_cl/exps/ablation/configs/reproduce_main_results.py
index 4695f62e..34f81af2 100644
--- a/fsvi_cl/src_cl/exps/ablation/configs/reproduce_main_results.py
+++ b/fsvi_cl/src_cl/exps/ablation/configs/reproduce_main_results.py
@@ -3,7 +3,7 @@ import pickle
 from typing import Dict
 from typing import List
 
-import sfsvi.general_utils.log import PROJECT_ROOT
+from fsvi_cl.general_utils.log import PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils import generate_cmds as gc
 from fsvi_cl.src_cl.exps.utils.configs import ABLATION_ROOT
 from fsvi_cl.src_cl.exps.utils.configs import CL_TEMPLATE
diff --git a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion.py b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion.py
index cdd0cc1d..86bd5c94 100644
--- a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion.py
+++ b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion.py
@@ -3,7 +3,7 @@ from typing import Dict, List
 import os
 import pickle
 
-import sfsvi.general_utils.log import PROJECT_ROOT
+from fsvi_cl.general_utils.log import PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils import best_configs as bc
 from fsvi_cl.src_cl.exps.utils import generate_cmds as gc
 from fsvi_cl.src_cl.exps.utils.configs import (
diff --git a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_epochs.py b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_epochs.py
index 80c9b763..364ded83 100644
--- a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_epochs.py
+++ b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_epochs.py
@@ -3,7 +3,7 @@ from typing import Dict, List
 import os
 import pickle
 
-import sfsvi.general_utils.log import PROJECT_ROOT
+from fsvi_cl.general_utils.log import PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils import best_configs as bc
 from fsvi_cl.src_cl.exps.utils import generate_cmds as gc
 from fsvi_cl.src_cl.exps.utils.configs import (
diff --git a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_old_code.py b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_old_code.py
index 54751a53..d0e703bc 100644
--- a/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_old_code.py
+++ b/fsvi_cl/src_cl/exps/ablation/configs/rerun_sfashion_old_code.py
@@ -3,7 +3,7 @@ from typing import Dict, List
 import os
 import pickle
 
-import sfsvi.general_utils.log import PROJECT_ROOT
+from fsvi_cl.general_utils.log import PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils import generate_cmds as gc
 from fsvi_cl.src_cl.exps.utils.configs import (
 	CL_TEMPLATE,
diff --git a/fsvi_cl/src_cl/exps/ablation/main.sh b/fsvi_cl/src_cl/exps/ablation/main.sh
index 2532188a..eb471f13 100644
--- a/fsvi_cl/src_cl/exps/ablation/main.sh
+++ b/fsvi_cl/src_cl/exps/ablation/main.sh
@@ -213,4 +213,8 @@ echo $ROOT_PATH
 
 #$ROOT_PATH/slurm/submit_job_array.sh ./jobs/rerun_sfashion_epochs.sh --gres=gpu:1 --job-name="sfashion" --exclude=clpc144
 
-$ROOT_PATH/slurm/submit_job_array.sh ./jobs/reproduce_main_results.sh --gres=gpu:1 --job-name="reprod" --exclude=clpc144
+#$ROOT_PATH/slurm/submit_job_array.sh ./jobs/reproduce_main_results.sh --gres=gpu:1 --job-name="reprod" --exclude=clpc144
+
+$ROOT_PATH/slurm/submit_job_array.sh ./jobs/reproduce_main_results_2.sh --gres=gpu:1 --job-name="reprod" --exclude=clpc144,oat18
+
+#$ROOT_PATH/slurm/submit_job_array.sh ./jobs/reproduce_main_results_3.sh --gres=gpu:1 --job-name="reprod" --exclude=clpc144
diff --git a/fsvi_cl/src_cl/exps/plots/v0/toy_2d_uncertainty_plots.py b/fsvi_cl/src_cl/exps/plots/v0/toy_2d_uncertainty_plots.py
index 7a497ab6..35386d3d 100644
--- a/fsvi_cl/src_cl/exps/plots/v0/toy_2d_uncertainty_plots.py
+++ b/fsvi_cl/src_cl/exps/plots/v0/toy_2d_uncertainty_plots.py
@@ -3,7 +3,7 @@ import pdb
 import os
 import sys
 
-import sfsvi.general_utils.log import save_chkpt
+from fsvi_cl.general_utils.log import save_chkpt
 
 ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
diff --git a/fsvi_cl/src_cl/exps/publish/frcl.py b/fsvi_cl/src_cl/exps/publish/frcl.py
index adac35d2..e0618b72 100644
--- a/fsvi_cl/src_cl/exps/publish/frcl.py
+++ b/fsvi_cl/src_cl/exps/publish/frcl.py
@@ -15,7 +15,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
 	sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
 
diff --git a/fsvi_cl/src_cl/exps/publish/fromp.py b/fsvi_cl/src_cl/exps/publish/fromp.py
index 4809f378..92c2498b 100644
--- a/fsvi_cl/src_cl/exps/publish/fromp.py
+++ b/fsvi_cl/src_cl/exps/publish/fromp.py
@@ -16,7 +16,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
 	sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_cifar.py b/fsvi_cl/src_cl/exps/publish/fsvi_cifar.py
index 34e7e6fa..37c2dc7a 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_cifar.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_cifar.py
@@ -9,7 +9,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
 	sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_match.py b/fsvi_cl/src_cl/exps/publish/fsvi_match.py
index ac7ad036..79d9b003 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_match.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_match.py
@@ -6,7 +6,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
     sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_minimal_coreset.py b/fsvi_cl/src_cl/exps/publish/fsvi_minimal_coreset.py
index 6767ca5e..e2475ad1 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_minimal_coreset.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_minimal_coreset.py
@@ -7,7 +7,7 @@ if ROOT not in sys.path:
     sys.path.insert(0, ROOT)
 
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_no_coreset.py b/fsvi_cl/src_cl/exps/publish/fsvi_no_coreset.py
index ef7bf588..dfdeaebb 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_no_coreset.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_no_coreset.py
@@ -6,7 +6,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
     sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_omniglot.py b/fsvi_cl/src_cl/exps/publish/fsvi_omniglot.py
index ec41ffb0..261e5acc 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_omniglot.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_omniglot.py
@@ -9,7 +9,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
 	sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
 
diff --git a/fsvi_cl/src_cl/exps/publish/fsvi_optimized.py b/fsvi_cl/src_cl/exps/publish/fsvi_optimized.py
index 2a7982b2..20542a89 100644
--- a/fsvi_cl/src_cl/exps/publish/fsvi_optimized.py
+++ b/fsvi_cl/src_cl/exps/publish/fsvi_optimized.py
@@ -6,7 +6,7 @@ ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
 if ROOT not in sys.path:
     sys.path.insert(0, ROOT)
 
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
diff --git a/fsvi_cl/src_cl/exps/publish/toy2d.py b/fsvi_cl/src_cl/exps/publish/toy2d.py
index e67ca54a..72192d14 100644
--- a/fsvi_cl/src_cl/exps/publish/toy2d.py
+++ b/fsvi_cl/src_cl/exps/publish/toy2d.py
@@ -13,7 +13,7 @@ if ROOT not in sys.path:
 
 from fsvi_cl.src_cl.exps.plots.v0.toy_2d_uncertainty_plots import get_plot_data
 from fsvi_cl.src_cl.exps.toy.uncertainty_plots import generate_test_data
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/publish/vcl.py b/fsvi_cl/src_cl/exps/publish/vcl.py
index a4f2585c..027dbf9f 100644
--- a/fsvi_cl/src_cl/exps/publish/vcl.py
+++ b/fsvi_cl/src_cl/exps/publish/vcl.py
@@ -16,7 +16,7 @@ if ROOT not in sys.path:
 
 from fsvi_cl.src_cl.exps.plots_preprocessing.vcl import get_result_vcl
 from fsvi_cl.src_cl.exps.publish.fsvi_match import get_example_config
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 import fsvi_cl.src_cl.exps.utils.load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/utils/baselines_configs.py b/fsvi_cl/src_cl/exps/utils/baselines_configs.py
index 3c5b2ce8..2234bc27 100644
--- a/fsvi_cl/src_cl/exps/utils/baselines_configs.py
+++ b/fsvi_cl/src_cl/exps/utils/baselines_configs.py
@@ -4,7 +4,7 @@ from typing import Dict, List
 from fsvi_cl.baselines.vcl.run_vcl import add_vcl_args
 from fsvi_cl.baselines.frcl.run_frcl import add_frcl_args
 from fsvi_cl.baselines.fromp.run_fromp import add_fromp_args
-import sfsvi.general_utils.log import EXPS_ROOT, PROJECT_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT, PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils.config_template import ConfigTemplate
 
 CL_ROOT = PROJECT_ROOT / "fsvi_cl"
@@ -111,26 +111,26 @@ def get_vcl_split_MNIST_with_coreset_config() -> Dict:
     return VCL_TEMPLATE.parse_args(cmd_str, template_info=True)
 
 
-def baseline_configs_to_file(configs: List[Dict], subdir: str, folder: str = "jobs"):
+def baseline_configs_to_file(configs: List[Dict], subdir: str, folder: str = "jobs", root=BASELINE_ROOT):
     # TODO: this is a quite hacky way
     frcl_configs = [c for c in configs if "frcl" in c["template"]]
     fromp_configs = [c for c in configs if "fromp" in c["template"]]
     vcl_configs = [c for c in configs if "vcl" in c["template"]]
     FRCL_TEMPLATE.configs_to_file(
         configs=frcl_configs,
-        file_path=BASELINE_ROOT / folder / f"{subdir}.sh",
+        file_path=root / folder / f"{subdir}.sh",
         prefix=FRCL_PREFIX,
         mode="w",
     )
     FROMP_TEMPLATE.configs_to_file(
         configs=fromp_configs,
-        file_path=BASELINE_ROOT / folder / f"{subdir}.sh",
+        file_path=root / folder / f"{subdir}.sh",
         prefix=FROMP_PREFIX,
         mode="a",
     )
     VCL_TEMPLATE.configs_to_file(
         configs=vcl_configs,
-        file_path=BASELINE_ROOT / folder / f"{subdir}.sh",
+        file_path=root / folder / f"{subdir}.sh",
         prefix=VCL_PREFIX,
         mode="a",
     )
diff --git a/fsvi_cl/src_cl/exps/utils/diagonse.py b/fsvi_cl/src_cl/exps/utils/diagonse.py
index 044b9c0a..8531984c 100644
--- a/fsvi_cl/src_cl/exps/utils/diagonse.py
+++ b/fsvi_cl/src_cl/exps/utils/diagonse.py
@@ -5,7 +5,7 @@ import sys
 root_folder = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../.."))
 sys.path.insert(0, root_folder)
 sys.path.insert(0, os.path.join(root_folder, "function_space_vi"))
-import sfsvi.general_utils.log import EXPS_ROOT
+from fsvi_cl.general_utils.log import EXPS_ROOT
 from fsvi_cl.src_cl.exps.utils import load_utils as lutils
 
 
diff --git a/fsvi_cl/src_cl/exps/utils/load_utils.py b/fsvi_cl/src_cl/exps/utils/load_utils.py
index 61ae5b45..361bcdcd 100644
--- a/fsvi_cl/src_cl/exps/utils/load_utils.py
+++ b/fsvi_cl/src_cl/exps/utils/load_utils.py
@@ -16,7 +16,7 @@ from typing import List, Dict, Tuple, Callable, Union, Sequence
 from collections import defaultdict
 
 import tensorflow as tf
-import sfsvi.general_utils.log import save_chkpt, PROJECT_ROOT
+from fsvi_cl.general_utils.log import save_chkpt, PROJECT_ROOT
 from fsvi_cl.src_cl.exps.utils.config_template import ConfigTemplate
 from tqdm import tqdm
 import pandas as pd
@@ -617,7 +617,7 @@ def get_make_immutable_config(keys):
 
 
 def make_immutable_sub_spec(e: Dict, keys: List[str]) -> Tuple:
-    return tuple([if_list_to_tuple(to_int_if_possible(e["config"][k])) for k in keys])
+    return tuple([if_list_to_tuple(to_int_if_possible(e["config"].get(k, "NOT_EXIST"))) for k in keys])
 
 
 def make_mutable_sub_spec(e: Dict, keys: List[str]) -> Dict:
@@ -1130,9 +1130,9 @@ def load_data(exp: Dict) -> List:
     """return DatasetSplit"""
     load_exp(exp)
     kwargs = exp["chkpt"]["hparams"]
-    import sfsvi.general_utils.log import Hyperparameters
+    from fsvi_cl.general_utils.log import Hyperparameters
     from fsvi_cl.src_cl.utils.data_loaders.get_data import prepare_data
-    import sfsvi.utils.utils import initialize_random_keys
+    from fsvi_cl.utils.utils import initialize_random_keys
 
     hparams = Hyperparameters(**kwargs)
     (
@@ -1256,9 +1256,9 @@ def get_samples(
 def load_model(exp: Dict):
     load_exp(exp)
     kwargs = exp["chkpt"]["hparams"]
-    import sfsvi.general_utils.log import Hyperparameters
+    from fsvi_cl.general_utils.log import Hyperparameters
     from fsvi_cl.src_cl.utils.data_loaders.get_data import prepare_data
-    import sfsvi.utils.utils import initialize_random_keys
+    from fsvi_cl.utils.utils import initialize_random_keys
     from fsvi_cl.src_cl.utils.initializer import Initializer
 
     default_config = CL_TEMPLATE.default_config()
diff --git a/fsvi_cl/src_cl/utils/coreset/coreset_heuristics.py b/fsvi_cl/src_cl/utils/coreset/coreset_heuristics.py
index a11ae5da..7d6b957f 100644
--- a/fsvi_cl/src_cl/utils/coreset/coreset_heuristics.py
+++ b/fsvi_cl/src_cl/utils/coreset/coreset_heuristics.py
@@ -8,9 +8,9 @@ import numpy as np
 from jax import numpy as jnp
 from tqdm import tqdm
 
-import sfsvi.utils.utils import kl_diag as kl_diag_jax, to_float_if_possible
-import sfsvi.utils.haiku_mod import partition_params
-import sfsvi.utils.utils_linearization import bnn_linearized_predictive_v2
+from fsvi_cl.utils.utils import kl_diag as kl_diag_jax, to_float_if_possible
+from fsvi_cl.models.haiku_mod import partition_params
+from fsvi_cl.src_cl.utils.utils_linearization import bnn_linearized_predictive_v2
 from fsvi_cl.src_cl.utils.utils_cl import eps
 
 
diff --git a/fsvi_cl/src_cl/utils/coreset/coreset_selection.py b/fsvi_cl/src_cl/utils/coreset/coreset_selection.py
index 210d1c2d..d7b4d952 100644
--- a/fsvi_cl/src_cl/utils/coreset/coreset_selection.py
+++ b/fsvi_cl/src_cl/utils/coreset/coreset_selection.py
@@ -4,9 +4,9 @@ from typing import Callable
 import numpy as np
 import haiku as hk
 
-import sfsvi.models.networks import Model
-import sfsvi.utils.jax_utils import KeyHelper
-import sfsvi.utils.utils import TUPLE_OF_TWO_TUPLES
+from fsvi_cl.models.networks import Model
+from fsvi_cl.general_utils.jax_utils import KeyHelper
+from fsvi_cl.utils.utils import TUPLE_OF_TWO_TUPLES
 from fsvi_cl.src_cl.utils.coreset.coreset_heuristics import add_by_random, add_by_random_per_class, add_by_entropy, add_by_kl, \
     add_by_elbo
 from fsvi_cl.src_cl.utils.prior import CLPrior
diff --git a/fsvi_cl/src_cl/utils/inducing_points.py b/fsvi_cl/src_cl/utils/inducing_points.py
index 883cf791..5f3e10d4 100644
--- a/fsvi_cl/src_cl/utils/inducing_points.py
+++ b/fsvi_cl/src_cl/utils/inducing_points.py
@@ -6,7 +6,7 @@ from typing import Callable, Dict
 
 import numpy as np
 
-import sfsvi.utils.jax_utils import KeyHelper
+from fsvi_cl.general_utils.jax_utils import KeyHelper
 from fsvi_cl.src_cl.utils.args_cl import NOT_SPECIFIED
 from fsvi_cl.src_cl.utils.coreset.coreset import Coreset
 
diff --git a/fsvi_cl/src_cl/utils/initializer.py b/fsvi_cl/src_cl/utils/initializer.py
index c56c90ab..f5909890 100644
--- a/fsvi_cl/src_cl/utils/initializer.py
+++ b/fsvi_cl/src_cl/utils/initializer.py
@@ -5,10 +5,10 @@ import jax.numpy as jnp
 import numpy as np
 import optax
 
-import sfsvi.models.networks import CNN, Model
-import sfsvi.models.networks import MLP as MLP
-import sfsvi.utils import utils
-import sfsvi.utils.haiku_mod import predicate_var, predicate_batchnorm
+from fsvi_cl.models.networks import CNN, Model
+from fsvi_cl.models.networks import MLP as MLP
+from fsvi_cl.utils import utils
+from fsvi_cl.models.haiku_mod import predicate_var, predicate_batchnorm
 from fsvi_cl.src_cl.utils.objectives_cl import Objectives_hk
 from fsvi_cl.src_cl.utils.prior import CLPrior
 
diff --git a/fsvi_cl/src_cl/utils/objectives_cl.py b/fsvi_cl/src_cl/utils/objectives_cl.py
index 30cdfffa..9c00a4f1 100644
--- a/fsvi_cl/src_cl/utils/objectives_cl.py
+++ b/fsvi_cl/src_cl/utils/objectives_cl.py
@@ -1,4 +1,3 @@
-import pdb
 from functools import partial
 from typing import Dict
 
@@ -7,10 +6,10 @@ import jax.numpy as jnp
 from jax import jit
 import haiku as hk
 
-import sfsvi.models.networks import Model
-import sfsvi.utils import utils_linearization
-import sfsvi.utils.utils import TUPLE_OF_TWO_TUPLES, _slice_cov_diag, kl_diag_tfd, kl_full_cov
-import sfsvi.utils.haiku_mod import partition_params
+from fsvi_cl.models.networks import Model
+from fsvi_cl.src_cl.utils import utils_linearization
+from fsvi_cl.utils.utils import TUPLE_OF_TWO_TUPLES, _slice_cov_diag, kl_diag_tfd, kl_full_cov
+from fsvi_cl.models.haiku_mod import partition_params
 
 
 @partial(jit, static_argnums=(0,3,))
diff --git a/fsvi_cl/src_cl/utils/prior.py b/fsvi_cl/src_cl/utils/prior.py
index 341388fb..e497434a 100644
--- a/fsvi_cl/src_cl/utils/prior.py
+++ b/fsvi_cl/src_cl/utils/prior.py
@@ -5,7 +5,7 @@ import haiku as hk
 import jax
 import jax.numpy as jnp
 
-import sfsvi.utils import utils_linearization
+from fsvi_cl.src_cl.utils import utils_linearization
 from fsvi_cl.src_cl.utils.utils_cl import generate_4d_identity_cov
 
 
diff --git a/fsvi_cl/src_cl/utils/utils_cl.py b/fsvi_cl/src_cl/utils/utils_cl.py
index a726e900..fb298466 100644
--- a/fsvi_cl/src_cl/utils/utils_cl.py
+++ b/fsvi_cl/src_cl/utils/utils_cl.py
@@ -13,9 +13,9 @@ import tabulate
 import tensorflow_probability.substrates.jax.distributions as tfd
 from jax import jit, numpy as jnp
 
-import sfsvi.general_utils.log import save_chkpt
-import sfsvi.utils.utils import tfd
-import sfsvi.utils.utils import TUPLE_OF_TWO_TUPLES
+from fsvi_cl.general_utils.log import save_chkpt
+from fsvi_cl.utils.utils import tfd
+from fsvi_cl.utils.utils import TUPLE_OF_TWO_TUPLES
 
 if getpass.getuser() == "timner":
     sns.set()
diff --git a/fsvi_cl/utils/haiku_mod.py b/fsvi_cl/utils/haiku_mod.py
index 3f87d52b..17e73377 100644
--- a/fsvi_cl/utils/haiku_mod.py
+++ b/fsvi_cl/utils/haiku_mod.py
@@ -14,23 +14,24 @@
 # ==============================================================================
 
 
-from typing import Optional, Sequence, Union, Tuple
+from typing import Optional
+from typing import Sequence
+from typing import Tuple
+from typing import Union
 
 import haiku as hk
 import jax
 import jax.numpy as jnp
 import numpy as np
-from haiku._src import utils
-from jax import random, lax, jit
-from tensorflow_probability.substrates.jax import distributions as tfd
-
-from typing import Optional, Sequence
-
 from haiku._src import base
 from haiku._src import initializers
 from haiku._src import module
 from haiku._src import moving_averages
 from haiku._src import utils
+from jax import jit
+from jax import lax
+from jax import random
+from tensorflow_probability.substrates.jax import distributions as tfd
 
 hk.get_parameter = base.get_parameter
 hk.initializers = initializers
@@ -38,7 +39,7 @@ hk.Module = module.Module
 hk.ExponentialMovingAverage = moving_averages.ExponentialMovingAverage
 del base, initializers, module, moving_averages
 
-import sfsvi.general_utils.haiku_utils import map_variable_name
+from fsvi_cl.general_utils.haiku_utils import map_variable_name
 
 dtype_default = jnp.float32
 
diff --git a/fsvi_cl/utils/utils.py b/fsvi_cl/utils/utils.py
index 829f6e8c..af8d8026 100644
--- a/fsvi_cl/utils/utils.py
+++ b/fsvi_cl/utils/utils.py
@@ -19,7 +19,7 @@ from jax import random
 from tensorflow_probability.substrates import jax as tfp
 from tensorflow_probability.substrates.jax import distributions as tfd
 
-import sfsvi.utils.jax_utils import KeyHelper
+from fsvi_cl.general_utils.jax_utils import KeyHelper
 
 
 kl_logstd_jitter = 1e-10
diff --git a/fsvi_cl/utils/utils_linearization.py b/fsvi_cl/utils/utils_linearization.py
index 4992de0d..27ebf48e 100644
--- a/fsvi_cl/utils/utils_linearization.py
+++ b/fsvi_cl/utils/utils_linearization.py
@@ -12,12 +12,12 @@ from jax import jit
 from jax import numpy as jnp
 from tensorflow_probability.substrates import jax as tfp
 
-import sfsvi.general_utils.haiku_utils import map_variable_name
-import sfsvi.general_utils.ntk_utils import diag_ntk_for_loop
-import sfsvi.general_utils.ntk_utils import explicit_ntk
-import sfsvi.general_utils.ntk_utils import neural_tangent_ntk
-import sfsvi.utils import utils
-import sfsvi.utils.haiku_mod import partition_params
+from fsvi_cl.general_utils.haiku_utils import map_variable_name
+from fsvi_cl.general_utils.ntk_utils import diag_ntk_for_loop
+from fsvi_cl.general_utils.ntk_utils import explicit_ntk
+from fsvi_cl.general_utils.ntk_utils import neural_tangent_ntk
+from fsvi_cl.utils import utils
+from fsvi_cl.utils.haiku_mod import partition_params
 
 tfd = tfp.distributions
 
diff --git a/publish/Reproduce.ipynb b/publish/Reproduce.ipynb
index f15af79a..e5db64eb 100644
--- a/publish/Reproduce.ipynb
+++ b/publish/Reproduce.ipynb
@@ -65,7 +65,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -75,58 +75,16 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "2022-01-28 11:23:27.058873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
-     ]
-    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Making GPU operations deterministic by settingos.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_reductions\"\"andos.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
-      "WARNING: uncertainty_baselines could not be loaded.\n",
-      "WARNING: bayesian_benchmarks could not be loaded.\n",
-      "WARNING: bayesian_benchmarks could not be loaded.\n",
-      "WARNING: bayesian_benchmarks could not be loaded.\n",
-      "WARNING: UCI trainer could not be loaded\n",
-      "WARNING: Offline RL trainer could not be loaded\n",
-      "WARNING: Offline RL evaluator could not be loaded\n",
-      "WARNING: Continual learning trainer could not be loaded\n",
-      "---------------- Could not load either VCL, FRCL, or FROMP! ----------------\n",
-      "WARNING: TensorFlow is set to only use CPU.\n",
-      "Jax is running on gpu\n",
-      "WARNING: TensorFlow is set to only use CPU.\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "2022-01-28 11:23:28.720364: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
-      "2022-01-28 11:23:28.720946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
-      "2022-01-28 11:23:28.950835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
-      "2022-01-28 11:23:28.951269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
-      "pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
-      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
-      "2022-01-28 11:23:28.951289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
-      "2022-01-28 11:23:28.953376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
-      "2022-01-28 11:23:28.953410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
-      "2022-01-28 11:23:28.954046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
-      "2022-01-28 11:23:28.954220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
-      "2022-01-28 11:23:28.955427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
-      "2022-01-28 11:23:28.955935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
-      "2022-01-28 11:23:28.956044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
-      "2022-01-28 11:23:28.956124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
-      "2022-01-28 11:23:28.956737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
-      "2022-01-28 11:23:28.957143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
+      "Making GPU operations deterministic by setting os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_reductions\"\"and os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n"
      ]
     }
    ],
@@ -405,21 +363,21 @@
      "evalue": "",
      "output_type": "error",
      "traceback": [
-      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
-      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
-      "\u001B[0;32m/tmp/ipykernel_2106650/308567527.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# run config,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/cli.py\u001B[0m in \u001B[0;36mrun_config\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mcmd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"cl\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mCL_TEMPLATE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig_to_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdefine_parser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcl_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(args, orig_cmd)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'kwargs'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"save\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"debug\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m(kwargs, orig_cmd)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0;31m# PASS VARIABLES TO TRAINER\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m     \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"save\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"resume_training\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, orig_cmd, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m                     )\n\u001B[1;32m     77\u001B[0m                     \u001B[0mparams_prior\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m                 params, state, opt_state, params_prior = self.run_one_task(\n\u001B[0m\u001B[1;32m     79\u001B[0m                     \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m                     \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_task\u001B[0;34m(self, params, state, opt_state, params_prior, task_id)\u001B[0m\n\u001B[1;32m    111\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnb_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m                 \u001B[0;31m# log_gpu_usage(desc=f\"task_id={task_id}, epoch={epoch}\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m                 params, state, opt_state = self.run_one_epoch(\n\u001B[0m\u001B[1;32m    114\u001B[0m                     \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m                     \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_epoch\u001B[0;34m(self, params, state, opt_state, task_id, epoch, n_batches, training_log, task_iterators, prior_fn, nb_epochs)\u001B[0m\n\u001B[1;32m    154\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"task_id {task_id}, epoch {epoch} starts\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m             params, state, opt_state = self.run_one_optimization_step(\n\u001B[0m\u001B[1;32m    157\u001B[0m                 \u001B[0mtraining_log\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining_log\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_optimization_step\u001B[0;34m(self, params, state, opt_state, task_iterators, prior_fn, training_log, task_id, epoch)\u001B[0m\n\u001B[1;32m    233\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_type\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m         )\n\u001B[0;32m--> 235\u001B[0;31m         \u001B[0mloss_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    236\u001B[0m         \u001B[0mtraining_log\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_batch_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf\"loss_info_epoch_{epoch}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mloss_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/tree/__init__.py\u001B[0m in \u001B[0;36mmap_structure\u001B[0;34m(func, *structures, **kwargs)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m   return unflatten_as(structures[0],\n\u001B[0;32m--> 510\u001B[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001B[0m\u001B[1;32m    511\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/tree/__init__.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m   return unflatten_as(structures[0],\n\u001B[0;32m--> 510\u001B[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001B[0m\u001B[1;32m    511\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    233\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_type\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m         )\n\u001B[0;32m--> 235\u001B[0;31m         \u001B[0mloss_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    236\u001B[0m         \u001B[0mtraining_log\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_batch_log\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf\"loss_info_epoch_{epoch}\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mloss_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/jax/interpreters/xla.py\u001B[0m in \u001B[0;36m__array__\u001B[0;34m(self, dtype, context)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1227\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1228\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1229\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1230\u001B[0m   \u001B[0msetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"__array__\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
+      "\u001b[0;32m/tmp/ipykernel_2106650/308567527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run config,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/cli.py\u001b[0m in \u001b[0;36mrun_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cl\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mCL_TEMPLATE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcl_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_cmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args, orig_cmd)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwargs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_cmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"debug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(kwargs, orig_cmd)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# PASS VARIABLES TO TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_cmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_cmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume_training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, orig_cmd, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     )\n\u001b[1;32m     77\u001b[0m                     \u001b[0mparams_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 params, state, opt_state, params_prior = self.run_one_task(\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001b[0m in \u001b[0;36mrun_one_task\u001b[0;34m(self, params, state, opt_state, params_prior, task_id)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# log_gpu_usage(desc=f\"task_id={task_id}, epoch={epoch}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 params, state, opt_state = self.run_one_epoch(\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(self, params, state, opt_state, task_id, epoch, n_batches, training_log, task_iterators, prior_fn, nb_epochs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"task_id {task_id}, epoch {epoch} starts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             params, state, opt_state = self.run_one_optimization_step(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mtraining_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001b[0m in \u001b[0;36mrun_one_optimization_step\u001b[0;34m(self, params, state, opt_state, task_iterators, prior_fn, training_log, task_id, epoch)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mtraining_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_batch_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"loss_info_epoch_{epoch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 510\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 510\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mtraining_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_batch_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"loss_info_epoch_{epoch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, context)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
      ]
     }
    ],
@@ -517,187 +475,20 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 1,
    "metadata": {
     "scrolled": true
    },
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "\n",
-      "Device: gpu\n",
-      "\n",
-      "Input arguments:\n",
-      " {\n",
-      "    \"command\":\"cl\",\n",
-      "    \"data_training\":\"continual_learning_toy_reprod\",\n",
-      "    \"data_ood\":\"not_specified\",\n",
-      "    \"model_type\":\"fsvi_mlp\",\n",
-      "    \"optimizer\":\"adam\",\n",
-      "    \"architecture\":[\n",
-      "        20,\n",
-      "        20\n",
-      "    ],\n",
-      "    \"activation\":\"relu\",\n",
-      "    \"prior_mean\":0.0,\n",
-      "    \"prior_cov\":0.1,\n",
-      "    \"prior_type\":\"bnn_induced\",\n",
-      "    \"epochs\":300,\n",
-      "    \"batch_size\":128,\n",
-      "    \"learning_rate\":0.0005,\n",
-      "    \"dropout_rate\":0.0,\n",
-      "    \"regularization\":0.0,\n",
-      "    \"n_inducing_inputs\":20,\n",
-      "    \"n_inducing_inputs_first_task\":\"not_specified\",\n",
-      "    \"n_inducing_inputs_second_task\":\"not_specified\",\n",
-      "    \"inducing_input_type\":\"uniform_rand\",\n",
-      "    \"kl_scale\":\"equal\",\n",
-      "    \"full_cov\":false,\n",
-      "    \"n_samples\":5,\n",
-      "    \"tau\":1.0,\n",
-      "    \"noise_std\":1.0,\n",
-      "    \"inducing_inputs_bound\":[\n",
-      "        -4.0,\n",
-      "        4.0\n",
-      "    ],\n",
-      "    \"fix_shuffle\":false,\n",
-      "    \"logging_frequency\":10,\n",
-      "    \"figsize\":[\n",
-      "        \"10\",\n",
-      "        \"4\"\n",
-      "    ],\n",
-      "    \"seed\":6,\n",
-      "    \"save_path\":\"debug\",\n",
-      "    \"save\":false,\n",
-      "    \"save_alt\":true,\n",
-      "    \"resume_training\":false,\n",
-      "    \"debug\":true,\n",
-      "    \"logroot\":\"toy\",\n",
-      "    \"subdir\":\"test\",\n",
-      "    \"inducing_inputs_add_mode\":0,\n",
-      "    \"inducing_input_adjustment\":false,\n",
-      "    \"not_use_coreset\":false,\n",
-      "    \"inducing_input_augmentation\":true,\n",
-      "    \"n_samples_eval\":5,\n",
-      "    \"plotting\":false,\n",
-      "    \"logging\":1,\n",
-      "    \"use_val_split\":false,\n",
-      "    \"not_use_val_split\":true,\n",
-      "    \"coreset\":\"random\",\n",
-      "    \"coreset_entropy_mode\":\"soft_highest\",\n",
-      "    \"coreset_entropy_offset\":\"0.0\",\n",
-      "    \"coreset_kl_heuristic\":\"lowest\",\n",
-      "    \"coreset_kl_offset\":\"0.0\",\n",
-      "    \"coreset_elbo_heuristic\":\"lowest\",\n",
-      "    \"coreset_elbo_offset\":\"0.0\",\n",
-      "    \"coreset_elbo_n_samples\":5,\n",
-      "    \"coreset_n_tasks\":\"not_specified\",\n",
-      "    \"coreset_entropy_n_mixed\":1,\n",
-      "    \"n_coreset_inputs_per_task\":\"not_specified\",\n",
-      "    \"full_ntk\":false,\n",
-      "    \"constant_inducing_points\":false,\n",
-      "    \"n_permuted_tasks\":10,\n",
-      "    \"n_omniglot_tasks\":20,\n",
-      "    \"epochs_first_task\":\"300\",\n",
-      "    \"identity_cov\":false,\n",
-      "    \"n_epochs_save_params\":\"not_specified\",\n",
-      "    \"n_augment\":\"30\",\n",
-      "    \"augment_mode\":\"linear\",\n",
-      "    \"stochastic_linearization\":false,\n",
-      "    \"final_layer_variational\":false,\n",
-      "    \"n_valid\":\"same\",\n",
-      "    \"learning_rate_first_task\":\"not_specified\",\n",
-      "    \"save_first_task\":false,\n",
-      "    \"first_task_load_exp_path\":\"not_specified\",\n",
-      "    \"only_task_id\":\"not_specified\",\n",
-      "    \"loss_type\":1,\n",
-      "    \"only_trainable_head\":false,\n",
-      "    \"n_omniglot_coreset_chars\":2,\n",
-      "    \"omniglot_randomize_test_split\":false,\n",
-      "    \"omniglot_randomize_task_sequence\":false,\n",
-      "    \"n_inducing_input_adjust_amount\":\"not_specified\",\n",
-      "    \"save_all_params\":true,\n",
-      "    \"task\":\"continual_learning_toy_reprod\"\n",
-      "} \n",
-      "\n",
-      "logdir is /scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/exps/toy/runs/test/2022-01-28-Friday-11-23-56\n",
-      "range dimensions\n",
-      "((0, 2), (0, 2), (0, 2), (0, 2), (0, 2))\n",
-      "\n",
-      "MAP initialization: False\n",
-      "Full NTK computation: False\n",
-      "Stochastic linearization (posterior): False\n",
-      "Full NTK computation: False\n",
-      "Stochastic linearization (prior): False\n",
-      "\n",
-      "\n",
-      "Learning task 1\n",
-      "entropies [0.6931]\n",
-      "----  ------  -----  ----  --------  --------\n",
-      "  ep    elbo    llk    kl       acc        t1\n",
-      "----  ------  -----  ----  --------  --------\n",
-      "   1       0      0     0     99.25     99.25\n",
-      "entropies [0.6931]\n",
-      "   2       0      0     0     98.00     98.00\n",
-      "entropies [0.693]\n",
-      "   3       0      0     0     85.00     85.00\n",
-      "entropies [0.6929]\n",
-      "   4       0      0     0     73.25     73.25\n",
-      "entropies [0.6927]\n",
-      "   5       0      0     0     66.50     66.50\n",
-      "entropies [0.692]\n",
-      "   6       0      0     0     58.75     58.75\n",
-      "entropies [0.6918]\n",
-      "   7       0      0     0     60.50     60.50\n",
-      "entropies [0.6926]\n",
-      "   8       0      0     0     77.25     77.25\n",
-      "entropies [0.6907]\n",
-      "   9       0      0     0     56.50     56.50\n",
-      "entropies [0.6915]\n",
-      "  10       0      0     0     64.25     64.25\n",
-      "entropies [0.6918]\n",
-      "  11       0      0     0     69.50     69.50\n",
-      "entropies [0.6915]\n",
-      "  12       0      0     0     69.50     69.50\n",
-      "entropies [0.692]\n",
-      "  13       0      0     0     86.50     86.50\n",
-      "entropies [0.6914]\n",
-      "  14       0      0     0     79.00     79.00\n",
-      "entropies [0.6909]\n",
-      "  15       0      0     0     81.75     81.75\n",
-      "entropies [0.6909]\n",
-      "  16       0      0     0     83.50     83.50\n",
-      "entropies [0.6883]\n",
-      "  17       0      0     0     63.50     63.50\n",
-      "entropies [0.6894]\n",
-      "  18       0      0     0     74.50     74.50\n",
-      "entropies [0.6837]\n",
-      "  19       0      0     0     52.00     52.00\n",
-      "entropies [0.6904]\n",
-      "  20       0      0     0     91.25     91.25\n"
-     ]
-    },
-    {
-     "ename": "KeyboardInterrupt",
-     "evalue": "",
+     "ename": "NameError",
+     "evalue": "name 'run_config' is not defined",
      "output_type": "error",
      "traceback": [
-      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
-      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
-      "\u001B[0;32m/tmp/ipykernel_2106650/4126562246.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/cli.py\u001B[0m in \u001B[0;36mrun_config\u001B[0;34m(config)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0mcmd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"cl\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mCL_TEMPLATE\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig_to_str\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdefine_parser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcl_run\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(args, orig_cmd)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'kwargs'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"save\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"debug\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/run.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m(kwargs, orig_cmd)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[0;31m# PASS VARIABLES TO TRAINER\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m     \u001B[0mlogdir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morig_cmd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"save\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"resume_training\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, orig_cmd, **kwargs)\u001B[0m\n\u001B[1;32m     76\u001B[0m                     )\n\u001B[1;32m     77\u001B[0m                     \u001B[0mparams_prior\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m                 params, state, opt_state, params_prior = self.run_one_task(\n\u001B[0m\u001B[1;32m     79\u001B[0m                     \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m                     \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_task\u001B[0;34m(self, params, state, opt_state, params_prior, task_id)\u001B[0m\n\u001B[1;32m    111\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnb_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m                 \u001B[0;31m# log_gpu_usage(desc=f\"task_id={task_id}, epoch={epoch}\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m                 params, state, opt_state = self.run_one_epoch(\n\u001B[0m\u001B[1;32m    114\u001B[0m                     \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m                     \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_epoch\u001B[0;34m(self, params, state, opt_state, task_id, epoch, n_batches, training_log, task_iterators, prior_fn, nb_epochs)\u001B[0m\n\u001B[1;32m    154\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"task_id {task_id}, epoch {epoch} starts\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m             params, state, opt_state = self.run_one_optimization_step(\n\u001B[0m\u001B[1;32m    157\u001B[0m                 \u001B[0mtraining_log\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining_log\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m                 \u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/scratch/data/qixuan/function-space-variational-inference/fsvi_cl/src_cl/trainers/continual_learning.py\u001B[0m in \u001B[0;36mrun_one_optimization_step\u001B[0;34m(self, params, state, opt_state, task_iterators, prior_fn, training_log, task_id, epoch)\u001B[0m\n\u001B[1;32m    216\u001B[0m             \u001B[0monly_one_task\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0monly_task_id\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mNOT_SPECIFIED\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m         )\n\u001B[0;32m--> 218\u001B[0;31m         params, state, opt_state, loss_info = update(\n\u001B[0m\u001B[1;32m    219\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/jax/_src/traceback_util.py\u001B[0m in \u001B[0;36mreraise_with_filtered_traceback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mreraise_with_filtered_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    140\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_under_reraiser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/jax/api.py\u001B[0m in \u001B[0;36mf_jitted\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    405\u001B[0m           \u001B[0;32mreturn\u001B[0m \u001B[0mcache_miss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;31m# probably won't return\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 407\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcpp_jitted_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    408\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m   \u001B[0mf_jitted\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cpp_jitted_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcpp_jitted_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;32m/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/haiku/_src/data_structures.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(treedef, leaves)\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[0mFlatMapping\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m     \u001B[0;32mlambda\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_leaves\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_structure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m     lambda treedef, leaves: FlatMapping(FlatComponents(leaves, treedef)))\n\u001B[0m\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[0;31m#      _                               _           _\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
-      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-1-35487a5d3405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
+      "\u001b[0;31mNameError\u001b[0m: name 'run_config' is not defined"
      ]
     }
    ],
@@ -725,9 +516,9 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python [conda env:fsvi]",
+   "display_name": "Python 3 (ipykernel)",
    "language": "python",
-   "name": "conda-env-fsvi-py"
+   "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
@@ -744,4 +535,4 @@
  },
  "nbformat": 4,
  "nbformat_minor": 2
-}
\ No newline at end of file
+}
diff --git a/publish/notebooks/common.py b/publish/notebooks/common.py
index 81f63788..536d9be0 100644
--- a/publish/notebooks/common.py
+++ b/publish/notebooks/common.py
@@ -9,7 +9,7 @@ if root not in sys.path:
 from cli import run_config
 
 
-TEST = True
+TEST = False
 configs_folder = os.path.join(root, "fsvi_cl/src_cl/exps/publish/configs")
 
 
diff --git a/slurm/submit_job_array.sh b/slurm/submit_job_array.sh
index 4c806896..032abc8a 100755
--- a/slurm/submit_job_array.sh
+++ b/slurm/submit_job_array.sh
@@ -1,6 +1,6 @@
 #!/bin/bash
 
-jobs_in_parallel=10
+jobs_in_parallel=5
 
 [ ! -f "$1" ] && echo "Error: file passed does not exist." && exit 1
 

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC:\n",
    "* [Environment Setup](#setup)\n",
    "* [Results](#results)\n",
    "    * [S-FSVI](#res1)\n",
    "    * [S-FSVI (larger networks)](#res2)\n",
    "    * [S-FSVI (no coreset)](#res3)\n",
    "    * [S-FSVI (minimal coreset)](#res4)\n",
    "    * [VCL (random-choice coreset)](#res5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run as Colab notebook\n",
    "\n",
    "**Important: Before connecting to a kernel, select a GPU runtime. To do so, open the `Runtime` tab above, click `Change runtime type`, and select `GPU`. Run the setup cell below only after you've done this.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pull S-FSVI repository\n",
    "!git clone https://github.com/timrudner/S-FSVI.git\n",
    "# patch required packages\n",
    "!pip install -r ./S-FSVI/colab_requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**After successfully running the cell above, you need to restart the runtime. To do so, open the “Runtime” tab above and and click “Restart runtime”. Once the runtime was restarted, run the cell below. There is no need to re-run the installation in the cell above.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add the repo to path\n",
    "import os\n",
    "import sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"S-FSVI\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run as Jupyter notebook (-->skip ahead to “Results” if you are running this as a Colab notebook<--)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install conda environment `fsvi`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!conda env update -f ../environment.yml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Troubleshooting:\n",
    "\n",
    " - In case there is an error when installing sklearn: run `pip install Cython==0.29.23` manually and then run the above command again.\n",
    " - In case you have access to a GPU, see instructions [here](https://github.com/google/jax#pip-installation-gpu-cuda) for installing the GPU version of `jaxlib`. This will make the experiment run significantly faster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the command below to install the conda environment as a kernel of the jupyter notebook. Then switch to this kernel using the Jupyter Notebook menu bar by selecting `Kernel`, `Change kernel`, and then selecting `fsvi`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m ipykernel install --user --name=fsvi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Troubleshooting: For further details, see [here](https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# assuming os.getcwd() returns the directory containing this jupyter notebook\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results <a name=\"results\"></a>\n",
    "\n",
    "To read a model checkpoint instead of training the model from scratch, pass load_chkpt=True to the function read_config_and_run .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/scratch/timner/applications/anaconda3/envs/fsvi/lib/python3.8/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: TensorFlow is set to only use CPU.\n",
      "Jax is running on gpu\n",
      "WARNING: TensorFlow is set to only use CPU.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "import os\n",
    "import sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)\n",
    "    \n",
    "    \n",
    "from notebooks.nb_utils.common import read_config_and_run, show_final_average_accuracy\n",
    "import sfsvi.exps.utils.load_utils as lutils\n",
    "\n",
    "task_sequence = \"pmnist_sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-FSVI (ours) <a name=\"res1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading experiments: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1127.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache:\n",
      "Running on clpc158.cs.ox.ac.uk\n",
      "Jax is running on gpu\n",
      "\n",
      "\n",
      "Input arguments:\n",
      " {\n",
      "    \"command\":\"cl\",\n",
      "    \"data_training\":\"continual_learning_pmnist\",\n",
      "    \"data_ood\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"model_type\":\"fsvi_mlp\",\n",
      "    \"optimizer\":\"adam\",\n",
      "    \"optimizer_var\":\"not_specified\",\n",
      "    \"momentum\":0.0,\n",
      "    \"momentum_var\":0.0,\n",
      "    \"schedule\":\"not_specified\",\n",
      "    \"architecture\":[\n",
      "        100,\n",
      "        100\n",
      "    ],\n",
      "    \"activation\":\"relu\",\n",
      "    \"prior_mean\":\"0.0\",\n",
      "    \"prior_cov\":\"0.001\",\n",
      "    \"prior_covs\":[\n",
      "        0.0\n",
      "    ],\n",
      "    \"prior_type\":\"bnn_induced\",\n",
      "    \"epochs\":10,\n",
      "    \"start_var_opt\":0,\n",
      "    \"batch_size\":128,\n",
      "    \"learning_rate\":0.0005,\n",
      "    \"learning_rate_var\":0.001,\n",
      "    \"dropout_rate\":0.0,\n",
      "    \"regularization\":0.0,\n",
      "    \"inducing_points\":0,\n",
      "    \"n_marginals\":1,\n",
      "    \"n_condition\":128,\n",
      "    \"inducing_input_type\":\"uniform_rand\",\n",
      "    \"inducing_input_ood_data\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"inducing_input_ood_data_size\":50000,\n",
      "    \"kl_scale\":\"equal\",\n",
      "    \"feature_map_jacobian\":false,\n",
      "    \"feature_map_jacobian_train_only\":false,\n",
      "    \"feature_map_type\":\"not_specified\",\n",
      "    \"td_prior_scale\":0.0,\n",
      "    \"feature_update\":1,\n",
      "    \"full_cov\":false,\n",
      "    \"n_samples\":5,\n",
      "    \"n_samples_eval\":5,\n",
      "    \"tau\":1.0,\n",
      "    \"noise_std\":1.0,\n",
      "    \"ind_lim\":\"ind_-1_1\",\n",
      "    \"logging_frequency\":10,\n",
      "    \"figsize\":[\n",
      "        \"10\",\n",
      "        \"4\"\n",
      "    ],\n",
      "    \"seed\":8,\n",
      "    \"save\":false,\n",
      "    \"name\":\"\",\n",
      "    \"evaluate\":false,\n",
      "    \"resume_training\":false,\n",
      "    \"no_final_layer_bias\":false,\n",
      "    \"extra_linear_layer\":false,\n",
      "    \"map_initialization\":false,\n",
      "    \"stochastic_linearization\":false,\n",
      "    \"grad_flow_jacobian\":false,\n",
      "    \"stochastic_prior_mean\":\"not_specified\",\n",
      "    \"batch_normalization\":false,\n",
      "    \"batch_normalization_mod\":\"not_specified\",\n",
      "    \"final_layer_variational\":false,\n",
      "    \"kl_sup\":\"not_specified\",\n",
      "    \"kl_sampled\":false,\n",
      "    \"fixed_inner_layers_variational_var\":false,\n",
      "    \"init_logvar\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_lin\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_conv\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"perturbation_param\":0.01,\n",
      "    \"logroot\":\"ablation\",\n",
      "    \"subdir\":\"reproduce_main_results_2\",\n",
      "    \"wandb_project\":\"not_specified\",\n",
      "    \"n_inducing_inputs\":40,\n",
      "    \"n_inducing_inputs_first_task\":\"not_specified\",\n",
      "    \"n_inducing_inputs_second_task\":\"not_specified\",\n",
      "    \"inducing_inputs_bound\":[\n",
      "        0.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"fix_shuffle\":false,\n",
      "    \"use_generative_model\":false,\n",
      "    \"inducing_inputs_add_mode\":0,\n",
      "    \"inducing_input_adjustment\":false,\n",
      "    \"not_use_coreset\":false,\n",
      "    \"inducing_input_augmentation\":false,\n",
      "    \"plotting\":false,\n",
      "    \"logging\":1,\n",
      "    \"use_val_split\":false,\n",
      "    \"not_use_val_split\":true,\n",
      "    \"coreset\":\"random\",\n",
      "    \"coreset_entropy_mode\":\"soft_highest\",\n",
      "    \"coreset_entropy_offset\":\"0.0\",\n",
      "    \"coreset_kl_heuristic\":\"lowest\",\n",
      "    \"coreset_kl_offset\":\"0.0\",\n",
      "    \"coreset_elbo_heuristic\":\"lowest\",\n",
      "    \"coreset_elbo_offset\":\"0.0\",\n",
      "    \"coreset_elbo_n_samples\":5,\n",
      "    \"coreset_n_tasks\":\"not_specified\",\n",
      "    \"coreset_entropy_n_mixed\":1,\n",
      "    \"n_coreset_inputs_per_task\":\"not_specified\",\n",
      "    \"full_ntk\":false,\n",
      "    \"constant_inducing_points\":false,\n",
      "    \"n_permuted_tasks\":10,\n",
      "    \"n_omniglot_tasks\":20,\n",
      "    \"epochs_first_task\":10,\n",
      "    \"identity_cov\":false,\n",
      "    \"n_epochs_save_params\":\"not_specified\",\n",
      "    \"n_augment\":\"not_specified\",\n",
      "    \"augment_mode\":\"constant\",\n",
      "    \"n_valid\":\"same\",\n",
      "    \"learning_rate_first_task\":\"not_specified\",\n",
      "    \"save_alt\":true,\n",
      "    \"save_first_task\":false,\n",
      "    \"first_task_load_exp_path\":\"not_specified\",\n",
      "    \"only_task_id\":\"not_specified\",\n",
      "    \"loss_type\":1,\n",
      "    \"only_trainable_head\":false,\n",
      "    \"n_omniglot_coreset_chars\":2,\n",
      "    \"omniglot_randomize_test_split\":false,\n",
      "    \"omniglot_randomize_task_sequence\":false,\n",
      "    \"n_inducing_input_adjust_amount\":\"not_specified\",\n",
      "    \"save_all_params\":false,\n",
      "    \"task\":\"continual_learning_pmnist\",\n",
      "    \"architecture_arg\":\"fc_100_100\",\n",
      "    \"init_logvar_minval\":0.0,\n",
      "    \"init_logvar_maxval\":0.0,\n",
      "    \"init_logvar_lin_minval\":0.0,\n",
      "    \"init_logvar_lin_maxval\":0.0,\n",
      "    \"init_logvar_conv_minval\":0.0,\n",
      "    \"init_logvar_conv_maxval\":0.0\n",
      "} \n",
      "\n",
      "\n",
      "MAP initialization: False\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (posterior): False\n",
      "init_logvar_lin_minval: -10.0\n",
      "init_logvar_lin_maxval: -8.0\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (prior): False\n",
      "\n",
      "\n",
      "Learning task 1\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------\n",
      "  epoch    mean acc    t1 acc\n",
      "-------  ----------  --------\n",
      "      0       85.62     85.62\n",
      "      1       91.46     91.46\n",
      "      2       93.21     93.21\n",
      "      3       94.17     94.17\n",
      "      4       94.66     94.66\n",
      "      5       95.05     95.05\n",
      "      6       95.61     95.61\n",
      "      7       96.05     96.05\n",
      "      8       95.96     95.96\n",
      "      9       96.43     96.43\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9643 \n",
      "Accuracies (test): [0.9643]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 2\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc\n",
      "-------  ----------  --------  --------\n",
      "      0       94.22     96.45     91.98\n",
      "      1       95.06     96.50     93.62\n",
      "      2       95.24     96.15     94.33\n",
      "      3       95.62     96.29     94.94\n",
      "      4       95.84     96.36     95.31\n",
      "      5       95.87     96.21     95.53\n",
      "      6       96.02     96.22     95.81\n",
      "      7       96.17     96.29     96.05\n",
      "      8       96.32     96.26     96.38\n",
      "      9       96.45     96.39     96.50\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9645 \n",
      "Accuracies (test): [0.9639, 0.965]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 3\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc\n",
      "-------  ----------  --------  --------  --------\n",
      "      0       95.13     96.12     96.24     93.02\n",
      "      1       95.77     96.21     96.46     94.64\n",
      "      2       95.92     96.19     96.39     95.18\n",
      "      3       96.06     96.16     96.39     95.62\n",
      "      4       96.15     96.33     96.30     95.81\n",
      "      5       96.31     96.33     96.39     96.20\n",
      "      6       96.36     96.28     96.32     96.49\n",
      "      7       96.40     96.21     96.33     96.66\n",
      "      8       96.49     96.27     96.31     96.90\n",
      "      9       96.51     96.30     96.33     96.91\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9651 \n",
      "Accuracies (test): [0.963, 0.9633, 0.9691]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 4\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "      0       95.60     96.26     96.26     96.86     93.01\n",
      "      1       96.01     96.21     96.25     97.01     94.57\n",
      "      2       96.18     96.29     96.22     96.87     95.34\n",
      "      3       96.34     96.26     96.38     96.86     95.84\n",
      "      4       96.41     96.38     96.29     96.76     96.23\n",
      "      5       96.50     96.28     96.24     96.89     96.58\n",
      "      6       96.56     96.34     96.28     96.97     96.64\n",
      "      7       96.55     96.25     96.28     96.86     96.82\n",
      "      8       96.62     96.36     96.25     96.88     96.99\n",
      "      9       96.62     96.30     96.23     96.93     97.01\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9662 \n",
      "Accuracies (test): [0.963, 0.9623, 0.9693, 0.9701]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 5\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "      0       95.89     96.41     96.27     96.85     96.96     92.95\n",
      "      1       96.20     96.27     96.24     96.81     96.99     94.70\n",
      "      2       96.33     96.27     96.21     96.83     97.03     95.31\n",
      "      3       96.33     96.22     96.15     96.75     96.79     95.72\n",
      "      4       96.47     96.27     96.24     96.88     96.87     96.08\n",
      "      5       96.45     96.14     96.10     96.80     96.83     96.40\n",
      "      6       96.51     96.16     96.28     96.70     96.75     96.64\n",
      "      7       96.57     96.30     96.21     96.79     96.84     96.71\n",
      "      8       96.53     96.12     96.13     96.74     96.79     96.86\n",
      "      9       96.51     96.12     96.13     96.71     96.70     96.88\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9651 \n",
      "Accuracies (test): [0.9612, 0.9613, 0.9671, 0.967, 0.9688]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 6\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "      0       95.88     96.20     96.15     96.75     96.73     96.82     92.64\n",
      "      1       96.17     96.19     96.25     96.75     96.79     96.76     94.28\n",
      "      2       96.32     96.26     96.19     96.68     96.84     96.90     95.05\n",
      "      3       96.36     96.18     96.10     96.72     96.85     96.75     95.55\n",
      "      4       96.36     96.17     96.03     96.70     96.78     96.70     95.79\n",
      "      5       96.38     96.12     96.05     96.60     96.84     96.72     95.98\n",
      "      6       96.47     96.18     96.21     96.63     96.74     96.82     96.27\n",
      "      7       96.42     96.04     96.07     96.56     96.77     96.80     96.31\n",
      "      8       96.46     96.18     96.20     96.53     96.76     96.71     96.36\n",
      "      9       96.53     96.20     96.12     96.60     96.79     96.81     96.69\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9653 \n",
      "Accuracies (test): [0.962, 0.9612, 0.966, 0.9679, 0.9681, 0.9669]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 7\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       95.79     95.95     96.07     96.50     96.69     96.69     96.52     92.14\n",
      "      1       96.05     95.97     96.06     96.46     96.78     96.62     96.53     93.91\n",
      "      2       96.18     96.01     96.06     96.46     96.74     96.67     96.53     94.77\n",
      "      3       96.28     96.08     96.18     96.50     96.67     96.66     96.56     95.32\n",
      "      4       96.26     95.99     96.19     96.44     96.68     96.59     96.42     95.53\n",
      "      5       96.31     95.99     96.09     96.43     96.71     96.68     96.42     95.87\n",
      "      6       96.32     96.05     96.15     96.43     96.62     96.56     96.42     96.02\n",
      "      7       96.34     96.09     96.20     96.39     96.71     96.51     96.40     96.11\n",
      "      8       96.34     96.02     96.06     96.35     96.63     96.51     96.40     96.41\n",
      "      9       96.35     95.94     96.02     96.45     96.67     96.48     96.38     96.52\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9635 \n",
      "Accuracies (test): [0.9594, 0.9602, 0.9645, 0.9667, 0.9648, 0.9638, 0.9652]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 8\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       95.73     95.98     95.89     96.31     96.45     96.46     96.29     96.46     91.99\n",
      "      1       95.86     95.85     95.88     96.19     96.39     96.23     96.25     96.20     93.86\n",
      "      2       96.02     95.91     95.95     96.25     96.43     96.26     96.28     96.39     94.71\n",
      "      3       95.99     95.78     95.73     96.12     96.35     96.26     96.15     96.30     95.20\n",
      "      4       96.09     95.87     95.89     96.21     96.41     96.40     96.16     96.25     95.53\n",
      "      5       96.10     95.89     95.86     96.17     96.39     96.21     96.21     96.32     95.73\n",
      "      6       96.12     96.00     95.82     96.11     96.42     96.23     96.23     96.30     95.87\n",
      "      7       96.06     95.70     95.69     96.07     96.27     96.13     96.17     96.30     96.12\n",
      "      8       96.10     95.78     95.74     96.19     96.29     96.28     96.10     96.25     96.15\n",
      "      9       96.16     95.87     95.79     96.17     96.37     96.23     96.14     96.38     96.36\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9616 \n",
      "Accuracies (test): [0.9587, 0.9579, 0.9617, 0.9637, 0.9623, 0.9614, 0.9638, 0.9636]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 9\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       95.62     95.70     95.59     96.14     96.37     96.14     95.84     96.20     96.30     92.27\n",
      "      1       95.80     95.87     95.57     96.04     96.33     96.12     95.90     96.21     96.23     93.91\n",
      "      2       95.80     95.90     95.57     95.82     96.23     95.98     95.81     96.21     96.18     94.51\n",
      "      3       95.86     95.76     95.48     96.08     96.24     96.05     95.85     96.12     96.08     95.12\n",
      "      4       95.86     95.81     95.48     96.00     96.15     95.94     95.80     96.06     96.12     95.38\n",
      "      5       95.90     95.75     95.55     95.95     96.14     96.02     95.77     96.07     96.04     95.84\n",
      "      6       95.94     95.76     95.71     95.95     96.17     95.97     95.87     95.97     96.03     96.05\n",
      "      7       95.99     95.86     95.59     95.97     96.21     96.03     95.88     96.08     96.07     96.20\n",
      "      8       95.97     95.84     95.53     95.95     96.16     95.97     95.88     96.04     96.06     96.31\n",
      "      9       96.03     95.95     95.62     95.89     96.26     95.96     95.82     96.08     96.10     96.55\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9603 \n",
      "Accuracies (test): [0.9595, 0.9562, 0.9589, 0.9626, 0.9596, 0.9582, 0.9608, 0.961, 0.9655]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 10\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc    t10 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "      0       95.53     95.93     95.55     95.85     96.16     95.93     95.87     96.05     95.93     96.51      91.55\n",
      "      1       95.65     95.82     95.62     95.86     96.06     95.86     95.76     95.99     95.81     96.40      93.35\n",
      "      2       95.72     95.78     95.51     95.86     96.08     95.84     95.73     95.87     95.85     96.35      94.38\n",
      "      3       95.76     95.77     95.52     95.78     96.09     95.83     95.71     95.90     95.89     96.40      94.75\n",
      "      4       95.78     95.68     95.42     95.76     96.03     95.93     95.71     95.92     95.78     96.41      95.19\n",
      "      5       95.83     95.84     95.58     95.86     96.03     95.75     95.48     95.93     95.82     96.49      95.51\n",
      "      6       95.81     95.86     95.45     95.66     95.95     95.67     95.65     95.90     95.79     96.36      95.78\n",
      "      7       95.81     95.55     95.52     95.67     95.96     95.78     95.59     95.87     95.88     96.35      95.95\n",
      "      8       95.82     95.64     95.42     95.64     95.94     95.69     95.60     95.89     95.78     96.35      96.20\n",
      "      9       95.85     95.65     95.45     95.76     95.93     95.74     95.60     95.88     95.75     96.37      96.35\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9585 \n",
      "Accuracies (test): [0.9565, 0.9545, 0.9576, 0.9593, 0.9574, 0.956, 0.9588, 0.9575, 0.9637, 0.9635]\n",
      "---\n",
      "\n",
      "\n",
      "------------------- DONE -------------------\n",
      "\n",
      "\n",
      "0.95848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = read_config_and_run(\"fsvi_match.pkl\", task_sequence)\n",
    "exp = lutils.read_exp(logdir)\n",
    "show_final_average_accuracy(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-FSVI (larger networks) <a name=\"res2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading experiments: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1157.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache:\n",
      "Running on oat1.cs.ox.ac.uk\n",
      "Jax is running on gpu\n",
      "\n",
      "\n",
      "Input arguments:\n",
      " {\n",
      "    \"command\":\"cl\",\n",
      "    \"data_training\":\"continual_learning_pmnist\",\n",
      "    \"data_ood\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"model_type\":\"fsvi_mlp\",\n",
      "    \"optimizer\":\"adam\",\n",
      "    \"optimizer_var\":\"not_specified\",\n",
      "    \"momentum\":0.0,\n",
      "    \"momentum_var\":0.0,\n",
      "    \"schedule\":\"not_specified\",\n",
      "    \"architecture\":[\n",
      "        500,\n",
      "        500\n",
      "    ],\n",
      "    \"activation\":\"relu\",\n",
      "    \"prior_mean\":\"0.0\",\n",
      "    \"prior_cov\":\"0.001\",\n",
      "    \"prior_covs\":[\n",
      "        0.0\n",
      "    ],\n",
      "    \"prior_type\":\"bnn_induced\",\n",
      "    \"epochs\":20,\n",
      "    \"start_var_opt\":0,\n",
      "    \"batch_size\":128,\n",
      "    \"learning_rate\":0.0001,\n",
      "    \"learning_rate_var\":0.001,\n",
      "    \"dropout_rate\":0.0,\n",
      "    \"regularization\":0.0,\n",
      "    \"inducing_points\":0,\n",
      "    \"n_marginals\":1,\n",
      "    \"n_condition\":128,\n",
      "    \"inducing_input_type\":\"uniform_rand\",\n",
      "    \"inducing_input_ood_data\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"inducing_input_ood_data_size\":50000,\n",
      "    \"kl_scale\":\"equal\",\n",
      "    \"feature_map_jacobian\":false,\n",
      "    \"feature_map_jacobian_train_only\":false,\n",
      "    \"feature_map_type\":\"not_specified\",\n",
      "    \"td_prior_scale\":0.0,\n",
      "    \"feature_update\":1,\n",
      "    \"full_cov\":false,\n",
      "    \"n_samples\":5,\n",
      "    \"n_samples_eval\":5,\n",
      "    \"tau\":1.0,\n",
      "    \"noise_std\":1.0,\n",
      "    \"ind_lim\":\"ind_-1_1\",\n",
      "    \"logging_frequency\":10,\n",
      "    \"figsize\":[\n",
      "        \"10\",\n",
      "        \"4\"\n",
      "    ],\n",
      "    \"seed\":7,\n",
      "    \"save\":false,\n",
      "    \"name\":\"\",\n",
      "    \"evaluate\":false,\n",
      "    \"resume_training\":false,\n",
      "    \"no_final_layer_bias\":false,\n",
      "    \"extra_linear_layer\":false,\n",
      "    \"map_initialization\":false,\n",
      "    \"stochastic_linearization\":false,\n",
      "    \"grad_flow_jacobian\":false,\n",
      "    \"stochastic_prior_mean\":\"not_specified\",\n",
      "    \"batch_normalization\":false,\n",
      "    \"batch_normalization_mod\":\"not_specified\",\n",
      "    \"final_layer_variational\":false,\n",
      "    \"kl_sup\":\"not_specified\",\n",
      "    \"kl_sampled\":false,\n",
      "    \"fixed_inner_layers_variational_var\":false,\n",
      "    \"init_logvar\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_lin\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_conv\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"perturbation_param\":0.01,\n",
      "    \"logroot\":\"ablation\",\n",
      "    \"subdir\":\"reproduce_main_results_2\",\n",
      "    \"wandb_project\":\"not_specified\",\n",
      "    \"n_inducing_inputs\":30,\n",
      "    \"n_inducing_inputs_first_task\":\"not_specified\",\n",
      "    \"n_inducing_inputs_second_task\":\"not_specified\",\n",
      "    \"inducing_inputs_bound\":[\n",
      "        0.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"fix_shuffle\":false,\n",
      "    \"use_generative_model\":false,\n",
      "    \"inducing_inputs_add_mode\":0,\n",
      "    \"inducing_input_adjustment\":false,\n",
      "    \"not_use_coreset\":false,\n",
      "    \"inducing_input_augmentation\":false,\n",
      "    \"plotting\":false,\n",
      "    \"logging\":1,\n",
      "    \"use_val_split\":false,\n",
      "    \"not_use_val_split\":true,\n",
      "    \"coreset\":\"random\",\n",
      "    \"coreset_entropy_mode\":\"soft_highest\",\n",
      "    \"coreset_entropy_offset\":\"0.0\",\n",
      "    \"coreset_kl_heuristic\":\"lowest\",\n",
      "    \"coreset_kl_offset\":\"0.0\",\n",
      "    \"coreset_elbo_heuristic\":\"lowest\",\n",
      "    \"coreset_elbo_offset\":\"0.0\",\n",
      "    \"coreset_elbo_n_samples\":5,\n",
      "    \"coreset_n_tasks\":\"not_specified\",\n",
      "    \"coreset_entropy_n_mixed\":1,\n",
      "    \"n_coreset_inputs_per_task\":\"not_specified\",\n",
      "    \"full_ntk\":false,\n",
      "    \"constant_inducing_points\":false,\n",
      "    \"n_permuted_tasks\":10,\n",
      "    \"n_omniglot_tasks\":20,\n",
      "    \"epochs_first_task\":20,\n",
      "    \"identity_cov\":false,\n",
      "    \"n_epochs_save_params\":\"not_specified\",\n",
      "    \"n_augment\":\"not_specified\",\n",
      "    \"augment_mode\":\"constant\",\n",
      "    \"n_valid\":\"same\",\n",
      "    \"learning_rate_first_task\":\"not_specified\",\n",
      "    \"save_alt\":true,\n",
      "    \"save_first_task\":false,\n",
      "    \"first_task_load_exp_path\":\"not_specified\",\n",
      "    \"only_task_id\":\"not_specified\",\n",
      "    \"loss_type\":1,\n",
      "    \"only_trainable_head\":false,\n",
      "    \"n_omniglot_coreset_chars\":2,\n",
      "    \"omniglot_randomize_test_split\":false,\n",
      "    \"omniglot_randomize_task_sequence\":false,\n",
      "    \"n_inducing_input_adjust_amount\":\"not_specified\",\n",
      "    \"save_all_params\":false,\n",
      "    \"task\":\"continual_learning_pmnist\",\n",
      "    \"architecture_arg\":\"fc_500_500\",\n",
      "    \"init_logvar_minval\":0.0,\n",
      "    \"init_logvar_maxval\":0.0,\n",
      "    \"init_logvar_lin_minval\":0.0,\n",
      "    \"init_logvar_lin_maxval\":0.0,\n",
      "    \"init_logvar_conv_minval\":0.0,\n",
      "    \"init_logvar_conv_maxval\":0.0\n",
      "} \n",
      "\n",
      "\n",
      "MAP initialization: False\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (posterior): False\n",
      "init_logvar_lin_minval: -10.0\n",
      "init_logvar_lin_maxval: -8.0\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (prior): False\n",
      "\n",
      "\n",
      "Learning task 1\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------\n",
      "  epoch    mean acc    t1 acc\n",
      "-------  ----------  --------\n",
      "      0       81.58     81.58\n",
      "      1       89.26     89.26\n",
      "      2       91.07     91.07\n",
      "      3       92.42     92.42\n",
      "      4       93.64     93.64\n",
      "      5       94.21     94.21\n",
      "      6       94.77     94.77\n",
      "      7       95.24     95.24\n",
      "      8       95.73     95.73\n",
      "      9       96.07     96.07\n",
      "     10       96.47     96.47\n",
      "     11       96.78     96.78\n",
      "     12       97.04     97.04\n",
      "     13       97.18     97.18\n",
      "     14       97.39     97.39\n",
      "     15       97.51     97.51\n",
      "     16       97.66     97.66\n",
      "     17       97.72     97.72\n",
      "     18       97.71     97.71\n",
      "     19       97.76     97.76\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9776 \n",
      "Accuracies (test): [0.9776]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 2\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc\n",
      "-------  ----------  --------  --------\n",
      "      0       95.94     97.82     94.06\n",
      "      1       96.50     97.80     95.20\n",
      "      2       96.88     97.79     95.96\n",
      "      3       97.04     97.80     96.27\n",
      "      4       97.23     97.84     96.63\n",
      "      5       97.40     97.81     96.99\n",
      "      6       97.39     97.77     97.01\n",
      "      7       97.53     97.81     97.26\n",
      "      8       97.64     97.88     97.40\n",
      "      9       97.64     97.76     97.52\n",
      "     10       97.72     97.79     97.65\n",
      "     11       97.76     97.82     97.70\n",
      "     12       97.80     97.82     97.78\n",
      "     13       97.88     97.86     97.90\n",
      "     14       97.91     97.84     97.97\n",
      "     15       97.92     97.88     97.97\n",
      "     16       97.92     97.89     97.96\n",
      "     17       97.92     97.81     98.03\n",
      "     18       97.97     97.80     98.15\n",
      "     19       97.95     97.84     98.06\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9795 \n",
      "Accuracies (test): [0.9784, 0.9806]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 3\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc\n",
      "-------  ----------  --------  --------  --------\n",
      "      0       96.44     97.73     98.07     93.52\n",
      "      1       96.97     97.77     98.13     95.00\n",
      "      2       97.20     97.81     98.06     95.74\n",
      "      3       97.44     97.79     98.14     96.39\n",
      "      4       97.49     97.71     98.11     96.66\n",
      "      5       97.64     97.82     98.12     96.98\n",
      "      6       97.67     97.78     98.11     97.11\n",
      "      7       97.79     97.85     98.15     97.37\n",
      "      8       97.81     97.82     98.17     97.43\n",
      "      9       97.85     97.83     98.17     97.54\n",
      "     10       97.87     97.79     98.03     97.78\n",
      "     11       97.86     97.79     98.10     97.70\n",
      "     12       97.92     97.84     98.08     97.83\n",
      "     13       97.95     97.80     98.12     97.92\n",
      "     14       97.98     97.89     98.04     98.00\n",
      "     15       97.98     97.85     98.11     97.98\n",
      "     16       97.99     97.86     98.03     98.07\n",
      "     17       97.98     97.77     98.10     98.07\n",
      "     18       98.04     97.88     98.15     98.08\n",
      "     19       97.96     97.77     98.00     98.12\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9796 \n",
      "Accuracies (test): [0.9777, 0.98, 0.9812]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 4\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "      0       96.86     97.77     98.12     98.07     93.50\n",
      "      1       97.19     97.76     98.13     98.01     94.85\n",
      "      2       97.34     97.68     98.11     98.04     95.55\n",
      "      3       97.53     97.69     98.07     98.06     96.29\n",
      "      4       97.59     97.78     98.07     98.00     96.52\n",
      "      5       97.60     97.76     98.04     98.01     96.60\n",
      "      6       97.73     97.79     98.17     97.99     96.98\n",
      "      7       97.74     97.77     98.05     98.01     97.15\n",
      "      8       97.77     97.77     98.02     98.05     97.25\n",
      "      9       97.82     97.84     98.04     98.07     97.32\n",
      "     10       97.81     97.77     98.10     97.99     97.38\n",
      "     11       97.85     97.79     98.12     98.05     97.45\n",
      "     12       97.83     97.76     98.00     98.00     97.55\n",
      "     13       97.84     97.76     98.07     98.00     97.52\n",
      "     14       97.89     97.80     98.06     98.01     97.69\n",
      "     15       97.89     97.66     97.99     98.03     97.86\n",
      "     16       97.89     97.74     98.09     97.99     97.73\n",
      "     17       97.92     97.79     98.05     98.01     97.83\n",
      "     18       97.91     97.73     98.01     98.03     97.89\n",
      "     19       97.94     97.73     98.10     98.01     97.92\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9794 \n",
      "Accuracies (test): [0.9773, 0.981, 0.9801, 0.9792]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 5\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "      0       97.12     97.82     98.02     97.98     97.92     93.85\n",
      "      1       97.47     97.66     98.05     98.03     97.91     95.69\n",
      "      2       97.55     97.72     98.02     98.01     97.80     96.19\n",
      "      3       97.65     97.74     98.11     98.00     97.87     96.54\n",
      "      4       97.72     97.79     98.00     98.06     97.81     96.92\n",
      "      5       97.75     97.75     98.04     98.01     97.83     97.11\n",
      "      6       97.81     97.79     98.08     98.07     97.84     97.26\n",
      "      7       97.83     97.78     98.13     98.00     97.79     97.46\n",
      "      8       97.89     97.85     98.09     98.10     97.88     97.54\n",
      "      9       97.83     97.83     98.05     97.89     97.80     97.59\n",
      "     10       97.82     97.73     98.05     98.00     97.76     97.58\n",
      "     11       97.85     97.77     97.99     97.98     97.73     97.78\n",
      "     12       97.88     97.76     98.05     98.01     97.82     97.76\n",
      "     13       97.85     97.70     98.04     97.92     97.75     97.86\n",
      "     14       97.87     97.72     98.08     97.93     97.74     97.86\n",
      "     15       97.86     97.73     98.04     97.86     97.79     97.89\n",
      "     16       97.87     97.74     98.01     98.02     97.71     97.86\n",
      "     17       97.86     97.74     97.98     97.94     97.72     97.94\n",
      "     18       97.90     97.71     97.99     97.96     97.84     98.00\n",
      "     19       97.91     97.76     97.95     97.95     97.75     98.12\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9791 \n",
      "Accuracies (test): [0.9776, 0.9795, 0.9795, 0.9775, 0.9812]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 6\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "      0       97.19     97.75     98.02     98.02     97.71     97.85     93.78\n",
      "      1       97.42     97.75     97.97     98.03     97.71     97.86     95.18\n",
      "      2       97.49     97.73     98.00     97.93     97.67     97.91     95.69\n",
      "      3       97.59     97.77     97.91     97.95     97.65     97.94     96.30\n",
      "      4       97.64     97.71     98.02     97.96     97.79     97.85     96.48\n",
      "      5       97.68     97.67     98.04     98.00     97.73     97.84     96.78\n",
      "      6       97.68     97.73     97.96     97.96     97.66     97.83     96.95\n",
      "      7       97.73     97.71     97.91     98.02     97.73     97.85     97.19\n",
      "      8       97.76     97.71     97.89     98.05     97.73     97.92     97.24\n",
      "      9       97.79     97.79     97.90     98.00     97.81     97.89     97.37\n",
      "     10       97.78     97.71     97.97     98.09     97.66     97.85     97.40\n",
      "     11       97.81     97.71     97.97     98.02     97.78     97.89     97.49\n",
      "     12       97.79     97.74     97.99     97.95     97.62     97.89     97.54\n",
      "     13       97.84     97.68     97.97     98.11     97.73     97.87     97.70\n",
      "     14       97.81     97.70     97.96     98.03     97.68     97.83     97.69\n",
      "     15       97.82     97.67     98.00     97.86     97.73     97.89     97.75\n",
      "     16       97.86     97.73     97.97     98.03     97.72     97.88     97.81\n",
      "     17       97.83     97.63     97.98     98.09     97.70     97.86     97.75\n",
      "     18       97.79     97.73     97.82     97.97     97.55     97.83     97.82\n",
      "     19       97.87     97.69     98.01     98.04     97.80     97.84     97.87\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9787 \n",
      "Accuracies (test): [0.9769, 0.9801, 0.9804, 0.978, 0.9784, 0.9787]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 7\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       97.24     97.62     97.94     98.01     97.66     97.75     97.81     93.90\n",
      "      1       97.44     97.64     97.98     97.97     97.57     97.78     97.86     95.26\n",
      "      2       97.57     97.70     97.99     98.05     97.58     97.79     97.79     96.12\n",
      "      3       97.64     97.66     97.80     98.00     97.65     97.85     97.89     96.61\n",
      "      4       97.70     97.71     97.99     98.05     97.72     97.85     97.75     96.84\n",
      "      5       97.73     97.69     97.96     97.98     97.69     97.81     97.91     97.07\n",
      "      6       97.74     97.64     98.00     98.07     97.66     97.80     97.79     97.24\n",
      "      7       97.78     97.71     97.95     98.02     97.61     97.90     97.87     97.37\n",
      "      8       97.76     97.71     97.97     98.08     97.56     97.81     97.71     97.48\n",
      "      9       97.76     97.71     97.86     98.03     97.60     97.86     97.84     97.44\n",
      "     10       97.79     97.68     97.88     97.99     97.56     97.89     97.87     97.66\n",
      "     11       97.80     97.64     98.05     98.04     97.61     97.82     97.75     97.66\n",
      "     12       97.80     97.66     97.91     98.04     97.59     97.77     97.84     97.79\n",
      "     13       97.81     97.72     97.95     97.88     97.64     97.79     97.88     97.78\n",
      "     14       97.79     97.63     97.84     98.03     97.58     97.82     97.77     97.86\n",
      "     15       97.79     97.68     97.95     97.94     97.56     97.77     97.79     97.87\n",
      "     16       97.83     97.67     97.92     97.95     97.58     97.79     97.89     98.00\n",
      "     17       97.82     97.66     97.97     97.94     97.63     97.85     97.74     97.95\n",
      "     18       97.83     97.71     97.92     97.96     97.63     97.83     97.78     97.97\n",
      "     19       97.82     97.67     97.80     98.00     97.56     97.86     97.81     98.05\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9782 \n",
      "Accuracies (test): [0.9767, 0.978, 0.98, 0.9756, 0.9786, 0.9781, 0.9805]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 8\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       97.32     97.66     97.80     97.95     97.62     97.75     97.67     98.01     94.12\n",
      "      1       97.48     97.72     97.69     98.02     97.55     97.88     97.63     97.95     95.40\n",
      "      2       97.58     97.65     97.73     97.91     97.60     97.79     97.79     98.01     96.17\n",
      "      3       97.60     97.67     97.65     97.99     97.50     97.78     97.66     97.94     96.57\n",
      "      4       97.63     97.60     97.71     97.97     97.40     97.75     97.69     98.00     96.91\n",
      "      5       97.68     97.72     97.73     97.95     97.47     97.81     97.72     97.99     97.06\n",
      "      6       97.70     97.67     97.74     97.93     97.39     97.82     97.70     98.07     97.27\n",
      "      7       97.69     97.74     97.78     97.87     97.41     97.73     97.67     97.93     97.42\n",
      "      8       97.70     97.66     97.69     97.94     97.37     97.82     97.70     97.99     97.44\n",
      "      9       97.70     97.75     97.70     97.89     97.57     97.77     97.58     97.83     97.55\n",
      "     10       97.71     97.63     97.76     97.90     97.29     97.81     97.72     97.95     97.62\n",
      "     11       97.72     97.60     97.68     97.96     97.36     97.80     97.76     97.99     97.65\n",
      "     12       97.70     97.56     97.66     97.84     97.40     97.73     97.74     97.95     97.71\n",
      "     13       97.75     97.65     97.73     97.91     97.50     97.73     97.58     98.05     97.89\n",
      "     14       97.76     97.70     97.74     97.98     97.33     97.80     97.68     97.97     97.89\n",
      "     15       97.72     97.67     97.66     97.85     97.37     97.81     97.61     97.97     97.84\n",
      "     16       97.72     97.65     97.79     97.94     97.30     97.79     97.54     97.91     97.87\n",
      "     17       97.73     97.61     97.67     97.93     97.36     97.79     97.58     97.96     97.98\n",
      "     18       97.71     97.63     97.57     97.94     97.35     97.69     97.59     97.86     98.03\n",
      "     19       97.77     97.70     97.67     97.96     97.43     97.80     97.58     97.98     98.01\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9777 \n",
      "Accuracies (test): [0.977, 0.9767, 0.9796, 0.9743, 0.978, 0.9758, 0.9798, 0.9801]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 9\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       97.30     97.54     97.67     97.81     97.36     97.71     97.60     97.84     97.99     94.21\n",
      "      1       97.44     97.56     97.74     97.76     97.30     97.76     97.58     97.70     98.02     95.52\n",
      "      2       97.55     97.58     97.73     97.88     97.34     97.77     97.56     97.80     98.04     96.29\n",
      "      3       97.54     97.54     97.64     97.85     97.25     97.71     97.52     97.78     97.87     96.74\n",
      "      4       97.63     97.64     97.58     97.85     97.37     97.85     97.57     97.78     97.95     97.09\n",
      "      5       97.67     97.56     97.66     97.87     97.41     97.81     97.59     97.87     97.96     97.34\n",
      "      6       97.67     97.60     97.64     97.76     97.33     97.79     97.60     97.90     97.96     97.41\n",
      "      7       97.66     97.57     97.60     97.88     97.33     97.73     97.50     97.86     98.01     97.48\n",
      "      8       97.67     97.57     97.55     97.76     97.25     97.83     97.63     97.75     98.06     97.65\n",
      "      9       97.64     97.53     97.56     97.76     97.31     97.68     97.38     97.85     97.97     97.75\n",
      "     10       97.68     97.55     97.58     97.81     97.29     97.79     97.57     97.79     97.95     97.75\n",
      "     11       97.66     97.61     97.60     97.78     97.32     97.71     97.50     97.72     97.94     97.72\n",
      "     12       97.65     97.59     97.61     97.76     97.29     97.67     97.44     97.70     97.98     97.77\n",
      "     13       97.67     97.60     97.61     97.80     97.34     97.67     97.53     97.69     97.94     97.87\n",
      "     14       97.65     97.55     97.58     97.79     97.14     97.74     97.51     97.77     97.89     97.92\n",
      "     15       97.69     97.61     97.64     97.81     97.30     97.70     97.51     97.83     97.85     97.96\n",
      "     16       97.67     97.58     97.60     97.75     97.31     97.73     97.44     97.68     98.07     97.88\n",
      "     17       97.67     97.70     97.60     97.78     97.32     97.67     97.41     97.66     97.93     97.95\n",
      "     18       97.67     97.59     97.71     97.76     97.19     97.73     97.47     97.73     97.91     97.93\n",
      "     19       97.65     97.64     97.62     97.64     97.26     97.60     97.40     97.69     97.95     98.02\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9765 \n",
      "Accuracies (test): [0.9764, 0.9762, 0.9764, 0.9726, 0.976, 0.974, 0.9769, 0.9795, 0.9802]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 10\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc    t10 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "      0       97.28     97.65     97.58     97.73     97.33     97.55     97.31     97.74     97.98     98.06      93.91\n",
      "      1       97.41     97.59     97.59     97.82     97.26     97.44     97.44     97.77     97.89     98.08      95.26\n",
      "      2       97.48     97.69     97.67     97.68     97.26     97.59     97.37     97.71     97.86     98.03      95.98\n",
      "      3       97.50     97.56     97.52     97.76     97.23     97.47     97.46     97.64     97.93     97.99      96.41\n",
      "      4       97.55     97.71     97.61     97.68     97.33     97.46     97.42     97.70     97.84     98.00      96.70\n",
      "      5       97.56     97.66     97.53     97.65     97.17     97.53     97.45     97.63     97.96     98.02      96.96\n",
      "      6       97.56     97.64     97.59     97.56     97.26     97.50     97.42     97.67     97.95     97.94      97.12\n",
      "      7       97.58     97.61     97.62     97.71     97.26     97.50     97.32     97.64     97.91     97.94      97.33\n",
      "      8       97.61     97.67     97.57     97.62     97.22     97.51     97.38     97.71     97.99     97.97      97.43\n",
      "      9       97.60     97.63     97.62     97.65     97.21     97.61     97.40     97.55     97.91     97.92      97.49\n",
      "     10       97.55     97.58     97.52     97.60     97.08     97.43     97.31     97.64     97.85     97.88      97.60\n",
      "     11       97.61     97.76     97.68     97.64     97.13     97.42     97.31     97.68     97.85     97.93      97.66\n",
      "     12       97.57     97.64     97.57     97.62     97.09     97.41     97.38     97.60     97.83     97.86      97.66\n",
      "     13       97.60     97.59     97.50     97.66     97.04     97.53     97.48     97.63     97.96     97.92      97.72\n",
      "     14       97.60     97.64     97.58     97.68     97.12     97.41     97.42     97.58     97.87     97.90      97.81\n",
      "     15       97.60     97.64     97.51     97.64     97.13     97.54     97.42     97.59     97.85     97.87      97.82\n",
      "     16       97.58     97.58     97.50     97.52     97.04     97.53     97.36     97.56     97.87     97.87      97.94\n",
      "     17       97.57     97.64     97.59     97.45     97.14     97.40     97.27     97.64     97.78     97.92      97.91\n",
      "     18       97.58     97.61     97.57     97.55     96.96     97.49     97.38     97.59     97.89     97.85      97.93\n",
      "     19       97.60     97.67     97.57     97.54     97.18     97.46     97.39     97.49     97.83     97.88      97.98\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9760 \n",
      "Accuracies (test): [0.9767, 0.9757, 0.9754, 0.9718, 0.9746, 0.9739, 0.9749, 0.9783, 0.9788, 0.9798]\n",
      "---\n",
      "\n",
      "\n",
      "------------------- DONE -------------------\n",
      "\n",
      "\n",
      "0.9759899999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = read_config_and_run(\"fsvi_optimized.pkl\", task_sequence)\n",
    "exp = lutils.read_exp(logdir)\n",
    "show_final_average_accuracy(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-FSVI (no coreset) <a name=\"res3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading experiments: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1156.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache:\n",
      "Running on clpc158.cs.ox.ac.uk\n",
      "Jax is running on gpu\n",
      "\n",
      "\n",
      "Input arguments:\n",
      " {\n",
      "    \"command\":\"cl\",\n",
      "    \"data_training\":\"continual_learning_pmnist\",\n",
      "    \"data_ood\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"model_type\":\"fsvi_mlp\",\n",
      "    \"optimizer\":\"adam\",\n",
      "    \"optimizer_var\":\"not_specified\",\n",
      "    \"momentum\":0.0,\n",
      "    \"momentum_var\":0.0,\n",
      "    \"schedule\":\"not_specified\",\n",
      "    \"architecture\":[\n",
      "        100,\n",
      "        100\n",
      "    ],\n",
      "    \"activation\":\"relu\",\n",
      "    \"prior_mean\":\"0.0\",\n",
      "    \"prior_cov\":\"0.001\",\n",
      "    \"prior_covs\":[\n",
      "        0.0\n",
      "    ],\n",
      "    \"prior_type\":\"bnn_induced\",\n",
      "    \"epochs\":5,\n",
      "    \"start_var_opt\":0,\n",
      "    \"batch_size\":128,\n",
      "    \"learning_rate\":0.0001,\n",
      "    \"learning_rate_var\":0.001,\n",
      "    \"dropout_rate\":0.0,\n",
      "    \"regularization\":0.0,\n",
      "    \"inducing_points\":0,\n",
      "    \"n_marginals\":1,\n",
      "    \"n_condition\":128,\n",
      "    \"inducing_input_type\":\"uniform_rand\",\n",
      "    \"inducing_input_ood_data\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"inducing_input_ood_data_size\":50000,\n",
      "    \"kl_scale\":\"equal\",\n",
      "    \"feature_map_jacobian\":false,\n",
      "    \"feature_map_jacobian_train_only\":false,\n",
      "    \"feature_map_type\":\"not_specified\",\n",
      "    \"td_prior_scale\":0.0,\n",
      "    \"feature_update\":1,\n",
      "    \"full_cov\":false,\n",
      "    \"n_samples\":5,\n",
      "    \"n_samples_eval\":5,\n",
      "    \"tau\":1.0,\n",
      "    \"noise_std\":1.0,\n",
      "    \"ind_lim\":\"ind_-1_1\",\n",
      "    \"logging_frequency\":10,\n",
      "    \"figsize\":[\n",
      "        \"10\",\n",
      "        \"4\"\n",
      "    ],\n",
      "    \"seed\":12,\n",
      "    \"save\":false,\n",
      "    \"name\":\"\",\n",
      "    \"evaluate\":false,\n",
      "    \"resume_training\":false,\n",
      "    \"no_final_layer_bias\":false,\n",
      "    \"extra_linear_layer\":false,\n",
      "    \"map_initialization\":false,\n",
      "    \"stochastic_linearization\":false,\n",
      "    \"grad_flow_jacobian\":false,\n",
      "    \"stochastic_prior_mean\":\"not_specified\",\n",
      "    \"batch_normalization\":false,\n",
      "    \"batch_normalization_mod\":\"not_specified\",\n",
      "    \"final_layer_variational\":false,\n",
      "    \"kl_sup\":\"not_specified\",\n",
      "    \"kl_sampled\":false,\n",
      "    \"fixed_inner_layers_variational_var\":false,\n",
      "    \"init_logvar\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_lin\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_conv\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"perturbation_param\":0.01,\n",
      "    \"logroot\":\"ablation\",\n",
      "    \"subdir\":\"reproduce_main_results_2\",\n",
      "    \"wandb_project\":\"not_specified\",\n",
      "    \"n_inducing_inputs\":40,\n",
      "    \"n_inducing_inputs_first_task\":\"not_specified\",\n",
      "    \"n_inducing_inputs_second_task\":\"not_specified\",\n",
      "    \"inducing_inputs_bound\":[\n",
      "        0.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"fix_shuffle\":false,\n",
      "    \"use_generative_model\":false,\n",
      "    \"inducing_inputs_add_mode\":0,\n",
      "    \"inducing_input_adjustment\":false,\n",
      "    \"not_use_coreset\":true,\n",
      "    \"inducing_input_augmentation\":false,\n",
      "    \"plotting\":false,\n",
      "    \"logging\":1,\n",
      "    \"use_val_split\":false,\n",
      "    \"not_use_val_split\":true,\n",
      "    \"coreset\":\"random\",\n",
      "    \"coreset_entropy_mode\":\"soft_highest\",\n",
      "    \"coreset_entropy_offset\":\"0.0\",\n",
      "    \"coreset_kl_heuristic\":\"lowest\",\n",
      "    \"coreset_kl_offset\":\"0.0\",\n",
      "    \"coreset_elbo_heuristic\":\"lowest\",\n",
      "    \"coreset_elbo_offset\":\"0.0\",\n",
      "    \"coreset_elbo_n_samples\":5,\n",
      "    \"coreset_n_tasks\":\"not_specified\",\n",
      "    \"coreset_entropy_n_mixed\":1,\n",
      "    \"n_coreset_inputs_per_task\":\"not_specified\",\n",
      "    \"full_ntk\":false,\n",
      "    \"constant_inducing_points\":false,\n",
      "    \"n_permuted_tasks\":10,\n",
      "    \"n_omniglot_tasks\":20,\n",
      "    \"epochs_first_task\":\"10\",\n",
      "    \"identity_cov\":false,\n",
      "    \"n_epochs_save_params\":\"not_specified\",\n",
      "    \"n_augment\":\"not_specified\",\n",
      "    \"augment_mode\":\"constant\",\n",
      "    \"n_valid\":\"same\",\n",
      "    \"learning_rate_first_task\":\"not_specified\",\n",
      "    \"save_alt\":true,\n",
      "    \"save_first_task\":false,\n",
      "    \"first_task_load_exp_path\":\"not_specified\",\n",
      "    \"only_task_id\":\"not_specified\",\n",
      "    \"loss_type\":1,\n",
      "    \"only_trainable_head\":false,\n",
      "    \"n_omniglot_coreset_chars\":2,\n",
      "    \"omniglot_randomize_test_split\":false,\n",
      "    \"omniglot_randomize_task_sequence\":false,\n",
      "    \"n_inducing_input_adjust_amount\":\"not_specified\",\n",
      "    \"save_all_params\":false,\n",
      "    \"task\":\"continual_learning_pmnist\",\n",
      "    \"architecture_arg\":\"fc_100_100\",\n",
      "    \"init_logvar_minval\":0.0,\n",
      "    \"init_logvar_maxval\":0.0,\n",
      "    \"init_logvar_lin_minval\":0.0,\n",
      "    \"init_logvar_lin_maxval\":0.0,\n",
      "    \"init_logvar_conv_minval\":0.0,\n",
      "    \"init_logvar_conv_maxval\":0.0\n",
      "} \n",
      "\n",
      "\n",
      "MAP initialization: False\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (posterior): False\n",
      "init_logvar_lin_minval: -10.0\n",
      "init_logvar_lin_maxval: -8.0\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (prior): False\n",
      "\n",
      "\n",
      "Learning task 1\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------\n",
      "  epoch    mean acc    t1 acc\n",
      "-------  ----------  --------\n",
      "      0       40.74     40.74\n",
      "      1       76.29     76.29\n",
      "      2       84.52     84.52\n",
      "      3       87.70     87.70\n",
      "      4       89.13     89.13\n",
      "      5       90.13     90.13\n",
      "      6       90.81     90.81\n",
      "      7       91.37     91.37\n",
      "      8       91.99     91.99\n",
      "      9       92.61     92.61\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9261 \n",
      "Accuracies (test): [0.9261]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 2\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc\n",
      "-------  ----------  --------  --------\n",
      "      0       89.67     91.22     88.13\n",
      "      1       90.59     90.60     90.58\n",
      "      2       91.01     90.20     91.82\n",
      "      3       91.22     89.68     92.77\n",
      "      4       90.86     88.35     93.37\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9086 \n",
      "Accuracies (test): [0.8835, 0.9337]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 3\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc\n",
      "-------  ----------  --------  --------  --------\n",
      "      0       89.95     87.47     91.93     90.46\n",
      "      1       89.96     86.35     91.39     92.14\n",
      "      2       90.29     85.52     92.15     93.19\n",
      "      3       90.27     85.35     91.61     93.84\n",
      "      4       89.94     83.83     91.47     94.53\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8994 \n",
      "Accuracies (test): [0.8383, 0.9147, 0.9453]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 4\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "      0       89.95     83.06     91.44     93.66     91.66\n",
      "      1       90.08     81.89     91.82     93.45     93.17\n",
      "      2       89.45     79.30     91.70     93.11     93.71\n",
      "      3       89.33     78.46     91.46     93.17     94.22\n",
      "      4       89.05     76.88     91.16     93.33     94.82\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8905 \n",
      "Accuracies (test): [0.7688, 0.9116, 0.9333, 0.9482]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 5\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "      0       89.55     80.14     88.86     91.79     94.58     92.37\n",
      "      1       89.09     77.53     87.93     91.58     94.42     93.98\n",
      "      2       89.50     77.94     88.19     92.09     94.54     94.75\n",
      "      3       88.56     74.86     85.96     92.32     94.50     95.16\n",
      "      4       87.84     73.64     84.45     91.46     94.12     95.52\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8784 \n",
      "Accuracies (test): [0.7364, 0.8445, 0.9146, 0.9412, 0.9552]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 6\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "      0       87.44     74.98     81.38     87.81     93.76     94.49     92.20\n",
      "      1       87.26     72.62     80.94     88.37     93.89     94.15     93.59\n",
      "      2       86.92     72.15     79.96     87.91     92.98     94.11     94.42\n",
      "      3       86.79     72.05     79.22     87.63     93.01     93.91     94.94\n",
      "      4       85.58     69.83     77.60     85.22     91.90     93.54     95.38\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8558 \n",
      "Accuracies (test): [0.6983, 0.776, 0.8522, 0.919, 0.9354, 0.9538]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 7\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       87.30     74.52     76.49     89.89     90.64     92.97     94.60     91.99\n",
      "      1       87.25     74.73     75.79     89.15     90.24     92.52     94.65     93.69\n",
      "      2       86.98     74.72     75.85     88.84     88.88     91.41     94.57     94.58\n",
      "      3       86.76     73.50     74.92     88.63     89.12     91.66     94.60     94.90\n",
      "      4       86.73     73.05     75.38     88.48     88.74     91.29     94.74     95.41\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8673 \n",
      "Accuracies (test): [0.7305, 0.7538, 0.8848, 0.8874, 0.9129, 0.9474, 0.9541]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 8\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       86.63     68.87     74.76     88.97     88.36     91.93     93.26     94.74     92.12\n",
      "      1       86.01     69.06     71.64     87.51     87.46     91.44     92.78     94.59     93.61\n",
      "      2       86.81     71.10     73.23     87.70     88.91     91.46     92.99     94.60     94.52\n",
      "      3       87.04     72.39     72.77     88.16     89.03     91.87     92.67     94.52     94.95\n",
      "      4       87.05     72.38     73.56     88.22     88.70     91.83     91.89     94.37     95.42\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8705 \n",
      "Accuracies (test): [0.7238, 0.7356, 0.8822, 0.887, 0.9183, 0.9189, 0.9437, 0.9542]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 9\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       86.81     71.73     71.43     86.76     87.49     89.37     92.37     94.07     95.27     92.83\n",
      "      1       86.45     68.71     70.61     85.63     87.37     88.98     92.98     94.31     95.35     94.11\n",
      "      2       86.43     69.40     69.75     86.02     87.06     89.20     92.80     93.90     95.02     94.75\n",
      "      3       86.16     69.83     69.67     84.90     85.90     88.80     92.14     93.64     95.23     95.30\n",
      "      4       85.86     68.55     68.13     84.63     86.25     89.00     92.27     93.44     94.90     95.55\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8586 \n",
      "Accuracies (test): [0.6855, 0.6813, 0.8463, 0.8625, 0.89, 0.9227, 0.9344, 0.949, 0.9555]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 10\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc    t10 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "      0       85.22     67.19     66.91     85.08     82.05     87.23     91.74     91.72     93.48     94.85      91.93\n",
      "      1       84.81     66.87     64.19     84.77     80.52     86.35     91.64     92.01     93.13     95.03      93.58\n",
      "      2       83.83     65.10     61.19     84.01     78.52     85.82     91.50     90.68     92.45     94.59      94.39\n",
      "      3       83.67     66.13     59.17     83.38     78.49     85.90     91.18     90.43     92.18     94.68      95.11\n",
      "      4       83.40     64.87     60.62     83.47     76.62     85.27     90.66     90.36     92.09     94.55      95.48\n",
      "Adding inducing inputs to the coreset randomly\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.8340 \n",
      "Accuracies (test): [0.6487, 0.6062, 0.8347, 0.7662, 0.8527, 0.9066, 0.9036, 0.9209, 0.9455, 0.9548]\n",
      "---\n",
      "\n",
      "\n",
      "------------------- DONE -------------------\n",
      "\n",
      "\n",
      "0.83399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = read_config_and_run(\"fsvi_no_coreset.pkl\", task_sequence)\n",
    "exp = lutils.read_exp(logdir)\n",
    "show_final_average_accuracy(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-FSVI (minimal coreset) <a name=\"res4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading experiments: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 1177.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache:\n",
      "Running on oat2.cs.ox.ac.uk\n",
      "Jax is running on gpu\n",
      "\n",
      "\n",
      "Input arguments:\n",
      " {\n",
      "    \"command\":\"cl\",\n",
      "    \"data_training\":\"continual_learning_pmnist\",\n",
      "    \"data_ood\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"model_type\":\"fsvi_mlp\",\n",
      "    \"optimizer\":\"adam\",\n",
      "    \"optimizer_var\":\"not_specified\",\n",
      "    \"momentum\":0.0,\n",
      "    \"momentum_var\":0.0,\n",
      "    \"schedule\":\"not_specified\",\n",
      "    \"architecture\":[\n",
      "        300,\n",
      "        300\n",
      "    ],\n",
      "    \"activation\":\"relu\",\n",
      "    \"prior_mean\":\"0.0\",\n",
      "    \"prior_cov\":\"10.0\",\n",
      "    \"prior_covs\":[\n",
      "        0.0\n",
      "    ],\n",
      "    \"prior_type\":\"bnn_induced\",\n",
      "    \"epochs\":10,\n",
      "    \"start_var_opt\":0,\n",
      "    \"batch_size\":128,\n",
      "    \"learning_rate\":0.0005,\n",
      "    \"learning_rate_var\":0.001,\n",
      "    \"dropout_rate\":0.0,\n",
      "    \"regularization\":0.0,\n",
      "    \"inducing_points\":0,\n",
      "    \"n_marginals\":1,\n",
      "    \"n_condition\":128,\n",
      "    \"inducing_input_type\":\"train_pixel_rand_0.0\",\n",
      "    \"inducing_input_ood_data\":[\n",
      "        \"not_specified\"\n",
      "    ],\n",
      "    \"inducing_input_ood_data_size\":50000,\n",
      "    \"kl_scale\":\"equal\",\n",
      "    \"feature_map_jacobian\":false,\n",
      "    \"feature_map_jacobian_train_only\":false,\n",
      "    \"feature_map_type\":\"not_specified\",\n",
      "    \"td_prior_scale\":0.0,\n",
      "    \"feature_update\":1,\n",
      "    \"full_cov\":false,\n",
      "    \"n_samples\":5,\n",
      "    \"n_samples_eval\":5,\n",
      "    \"tau\":1.0,\n",
      "    \"noise_std\":1.0,\n",
      "    \"ind_lim\":\"ind_-1_1\",\n",
      "    \"logging_frequency\":10,\n",
      "    \"figsize\":[\n",
      "        \"10\",\n",
      "        \"4\"\n",
      "    ],\n",
      "    \"seed\":4,\n",
      "    \"save\":false,\n",
      "    \"name\":\"\",\n",
      "    \"evaluate\":false,\n",
      "    \"resume_training\":false,\n",
      "    \"no_final_layer_bias\":false,\n",
      "    \"extra_linear_layer\":false,\n",
      "    \"map_initialization\":false,\n",
      "    \"stochastic_linearization\":false,\n",
      "    \"grad_flow_jacobian\":false,\n",
      "    \"stochastic_prior_mean\":\"not_specified\",\n",
      "    \"batch_normalization\":false,\n",
      "    \"batch_normalization_mod\":\"not_specified\",\n",
      "    \"final_layer_variational\":false,\n",
      "    \"kl_sup\":\"not_specified\",\n",
      "    \"kl_sampled\":false,\n",
      "    \"fixed_inner_layers_variational_var\":false,\n",
      "    \"init_logvar\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_lin\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"init_logvar_conv\":[\n",
      "        0.0,\n",
      "        0.0\n",
      "    ],\n",
      "    \"perturbation_param\":0.01,\n",
      "    \"logroot\":\"ablation\",\n",
      "    \"subdir\":\"reproduce_main_results_2\",\n",
      "    \"wandb_project\":\"not_specified\",\n",
      "    \"n_inducing_inputs\":10,\n",
      "    \"n_inducing_inputs_first_task\":\"not_specified\",\n",
      "    \"n_inducing_inputs_second_task\":\"not_specified\",\n",
      "    \"inducing_inputs_bound\":[\n",
      "        0.0,\n",
      "        1.0\n",
      "    ],\n",
      "    \"fix_shuffle\":false,\n",
      "    \"use_generative_model\":false,\n",
      "    \"inducing_inputs_add_mode\":0,\n",
      "    \"inducing_input_adjustment\":false,\n",
      "    \"not_use_coreset\":false,\n",
      "    \"inducing_input_augmentation\":false,\n",
      "    \"plotting\":false,\n",
      "    \"logging\":1,\n",
      "    \"use_val_split\":false,\n",
      "    \"not_use_val_split\":true,\n",
      "    \"coreset\":\"random_per_class\",\n",
      "    \"coreset_entropy_mode\":\"soft_highest\",\n",
      "    \"coreset_entropy_offset\":\"0.0\",\n",
      "    \"coreset_kl_heuristic\":\"lowest\",\n",
      "    \"coreset_kl_offset\":\"0.0\",\n",
      "    \"coreset_elbo_heuristic\":\"lowest\",\n",
      "    \"coreset_elbo_offset\":\"0.0\",\n",
      "    \"coreset_elbo_n_samples\":5,\n",
      "    \"coreset_n_tasks\":\"not_specified\",\n",
      "    \"coreset_entropy_n_mixed\":1,\n",
      "    \"n_coreset_inputs_per_task\":\"10\",\n",
      "    \"full_ntk\":false,\n",
      "    \"constant_inducing_points\":false,\n",
      "    \"n_permuted_tasks\":10,\n",
      "    \"n_omniglot_tasks\":20,\n",
      "    \"epochs_first_task\":10,\n",
      "    \"identity_cov\":false,\n",
      "    \"n_epochs_save_params\":\"not_specified\",\n",
      "    \"n_augment\":\"not_specified\",\n",
      "    \"augment_mode\":\"constant\",\n",
      "    \"n_valid\":\"same\",\n",
      "    \"learning_rate_first_task\":\"not_specified\",\n",
      "    \"save_alt\":true,\n",
      "    \"save_first_task\":false,\n",
      "    \"first_task_load_exp_path\":\"not_specified\",\n",
      "    \"only_task_id\":\"not_specified\",\n",
      "    \"loss_type\":1,\n",
      "    \"only_trainable_head\":false,\n",
      "    \"n_omniglot_coreset_chars\":2,\n",
      "    \"omniglot_randomize_test_split\":false,\n",
      "    \"omniglot_randomize_task_sequence\":false,\n",
      "    \"n_inducing_input_adjust_amount\":\"not_specified\",\n",
      "    \"save_all_params\":false,\n",
      "    \"task\":\"continual_learning_pmnist\",\n",
      "    \"architecture_arg\":\"fc_300_300\",\n",
      "    \"init_logvar_minval\":0.0,\n",
      "    \"init_logvar_maxval\":0.0,\n",
      "    \"init_logvar_lin_minval\":0.0,\n",
      "    \"init_logvar_lin_maxval\":0.0,\n",
      "    \"init_logvar_conv_minval\":0.0,\n",
      "    \"init_logvar_conv_maxval\":0.0\n",
      "} \n",
      "\n",
      "\n",
      "MAP initialization: False\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (posterior): False\n",
      "init_logvar_lin_minval: -10.0\n",
      "init_logvar_lin_maxval: -8.0\n",
      "Full NTK computation: False\n",
      "Stochastic linearization (prior): False\n",
      "\n",
      "\n",
      "Learning task 1\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------\n",
      "  epoch    mean acc    t1 acc\n",
      "-------  ----------  --------\n",
      "      0       92.11     92.11\n",
      "      1       93.87     93.87\n",
      "      2       94.84     94.84\n",
      "      3       95.52     95.52\n",
      "      4       96.18     96.18\n",
      "      5       96.61     96.61\n",
      "      6       96.97     96.97\n",
      "      7       97.16     97.16\n",
      "      8       97.26     97.26\n",
      "      9       97.45     97.45\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9745 \n",
      "Accuracies (test): [0.9745]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 2\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc\n",
      "-------  ----------  --------  --------\n",
      "      0       95.40     96.53     94.27\n",
      "      1       96.03     96.23     95.84\n",
      "      2       96.19     95.99     96.38\n",
      "      3       96.45     96.09     96.81\n",
      "      4       96.56     96.14     96.97\n",
      "      5       96.43     95.74     97.11\n",
      "      6       96.70     96.03     97.38\n",
      "      7       96.89     96.10     97.68\n",
      "      8       96.65     95.69     97.60\n",
      "      9       96.80     95.76     97.83\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9679 \n",
      "Accuracies (test): [0.9576, 0.9783]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 3\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc\n",
      "-------  ----------  --------  --------  --------\n",
      "      0       95.93     94.74     97.54     95.52\n",
      "      1       96.32     95.06     97.49     96.42\n",
      "      2       96.60     95.37     97.41     97.02\n",
      "      3       96.70     95.40     97.41     97.30\n",
      "      4       96.77     95.47     97.44     97.40\n",
      "      5       96.74     95.46     97.18     97.58\n",
      "      6       96.78     95.42     97.25     97.66\n",
      "      7       96.85     95.66     97.10     97.80\n",
      "      8       96.92     95.67     97.21     97.87\n",
      "      9       96.91     95.55     97.25     97.93\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9691 \n",
      "Accuracies (test): [0.9555, 0.9725, 0.9793]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 4\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc\n",
      "-------  ----------  --------  --------  --------  --------\n",
      "      0       96.42     95.44     96.62     97.45     96.16\n",
      "      1       96.67     95.46     96.78     97.43     97.01\n",
      "      2       96.64     95.13     96.73     97.46     97.22\n",
      "      3       96.81     95.36     96.87     97.42     97.60\n",
      "      4       96.87     95.28     96.83     97.53     97.84\n",
      "      5       96.86     95.50     96.75     97.49     97.69\n",
      "      6       96.75     95.00     96.80     97.41     97.81\n",
      "      7       96.78     95.02     96.81     97.40     97.91\n",
      "      8       96.77     95.03     96.70     97.38     97.99\n",
      "      9       96.74     94.83     96.66     97.37     98.11\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9674 \n",
      "Accuracies (test): [0.9483, 0.9666, 0.9737, 0.9811]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 5\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------\n",
      "      0       96.16     94.53     95.79     96.84     97.80     95.83\n",
      "      1       96.28     94.53     95.70     96.67     97.70     96.78\n",
      "      2       96.25     94.13     95.71     96.46     97.69     97.24\n",
      "      3       96.32     94.17     95.75     96.63     97.69     97.35\n",
      "      4       96.20     93.89     95.72     96.25     97.61     97.55\n",
      "      5       96.18     93.95     95.60     96.21     97.59     97.56\n",
      "      6       96.15     93.69     95.52     96.27     97.57     97.68\n",
      "      7       96.08     93.78     95.44     95.96     97.48     97.74\n",
      "      8       96.12     93.96     95.33     95.93     97.55     97.82\n",
      "      9       95.96     93.82     95.19     95.60     97.40     97.79\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9596 \n",
      "Accuracies (test): [0.9382, 0.9519, 0.956, 0.974, 0.9779]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 6\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------\n",
      "      0       95.33     92.13     94.72     95.18     97.07     97.49     95.39\n",
      "      1       95.37     91.45     94.85     95.06     97.02     97.53     96.29\n",
      "      2       95.48     91.75     94.56     95.05     96.90     97.51     97.09\n",
      "      3       95.46     91.86     94.27     94.99     96.96     97.37     97.31\n",
      "      4       95.28     91.09     94.31     94.77     96.72     97.40     97.40\n",
      "      5       95.38     91.28     94.30     94.89     96.75     97.39     97.65\n",
      "      6       95.23     91.27     93.64     94.63     96.89     97.38     97.60\n",
      "      7       95.14     90.92     93.75     94.45     96.75     97.29     97.71\n",
      "      8       95.25     91.06     94.00     94.55     96.69     97.38     97.82\n",
      "      9       94.99     90.52     93.70     94.24     96.49     97.16     97.82\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9499 \n",
      "Accuracies (test): [0.9052, 0.937, 0.9424, 0.9649, 0.9716, 0.9782]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 7\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       94.71     89.85     92.50     94.24     96.34     97.22     97.42     95.42\n",
      "      1       94.80     89.53     92.52     94.41     96.09     97.11     97.41     96.55\n",
      "      2       94.67     89.09     92.15     94.02     96.11     96.96     97.45     96.89\n",
      "      3       94.63     88.73     92.29     93.94     95.98     96.96     97.41     97.12\n",
      "      4       94.70     89.48     92.29     93.80     95.81     96.88     97.29     97.37\n",
      "      5       94.47     88.96     91.76     93.49     95.71     96.69     97.35     97.30\n",
      "      6       94.33     88.60     91.34     93.25     95.70     96.76     97.29     97.36\n",
      "      7       94.35     88.56     91.92     93.24     95.48     96.59     97.22     97.45\n",
      "      8       94.35     88.63     91.57     93.20     95.56     96.67     97.30     97.49\n",
      "      9       94.17     88.12     91.37     93.21     95.24     96.42     97.21     97.59\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9417 \n",
      "Accuracies (test): [0.8812, 0.9137, 0.9321, 0.9524, 0.9642, 0.9721, 0.9759]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 8\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       93.78     89.19     91.54     90.30     94.33     95.63     96.91     97.10     95.27\n",
      "      1       93.80     88.34     91.95     90.15     94.33     95.49     96.94     97.01     96.18\n",
      "      2       93.63     88.56     91.04     89.81     94.07     95.30     96.75     96.92     96.56\n",
      "      3       93.65     88.43     90.83     89.78     94.27     95.31     96.83     96.92     96.86\n",
      "      4       93.46     88.44     90.39     89.24     94.18     95.25     96.65     96.67     96.83\n",
      "      5       93.38     88.30     91.06     88.53     93.90     94.72     96.57     96.73     97.20\n",
      "      6       93.30     87.84     90.58     88.46     93.89     94.80     96.56     96.82     97.45\n",
      "      7       93.43     88.69     90.83     88.67     93.66     94.96     96.64     96.54     97.43\n",
      "      8       93.45     88.79     90.75     88.75     93.71     94.92     96.61     96.59     97.49\n",
      "      9       93.19     88.49     90.48     87.94     93.40     94.79     96.59     96.42     97.43\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9319 \n",
      "Accuracies (test): [0.8849, 0.9048, 0.8794, 0.934, 0.9479, 0.9659, 0.9642, 0.9743]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 9\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "      0       92.85     89.07     88.50     86.42     92.63     94.46     95.56     96.30     97.41     95.26\n",
      "      1       92.84     89.03     88.72     85.98     92.47     94.23     95.54     95.97     97.28     96.32\n",
      "      2       92.54     87.98     87.48     85.70     92.31     93.89     95.61     95.93     97.27     96.70\n",
      "      3       92.43     88.37     87.39     85.93     91.91     93.14     95.03     95.95     97.17     96.95\n",
      "      4       92.69     88.82     87.58     86.20     92.56     93.46     95.15     96.00     97.26     97.22\n",
      "      5       92.39     88.29     87.22     85.75     92.27     92.79     94.85     95.90     97.24     97.24\n",
      "      6       92.20     87.84     86.57     85.24     92.36     92.79     94.96     95.72     96.98     97.31\n",
      "      7       92.05     88.01     86.34     84.68     92.01     92.58     94.44     95.81     97.14     97.40\n",
      "      8       92.05     87.54     86.26     85.15     91.99     92.49     94.84     95.68     96.99     97.50\n",
      "      9       91.93     87.38     86.24     84.91     91.67     92.42     94.72     95.51     96.96     97.52\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9193 \n",
      "Accuracies (test): [0.8738, 0.8624, 0.8491, 0.9167, 0.9242, 0.9472, 0.9551, 0.9696, 0.9752]\n",
      "---\n",
      "\n",
      "\n",
      "Learning task 10\n",
      "Nomenclature:\n",
      "\tacc: accuracy in %\n",
      "\tt1: the first task\n",
      "\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "  epoch    mean acc    t1 acc    t2 acc    t3 acc    t4 acc    t5 acc    t6 acc    t7 acc    t8 acc    t9 acc    t10 acc\n",
      "-------  ----------  --------  --------  --------  --------  --------  --------  --------  --------  --------  ---------\n",
      "      0       91.45     86.11     83.16     85.21     90.79     91.36     94.09     95.48     95.86     97.18      95.24\n",
      "      1       91.34     84.76     82.11     85.21     90.90     91.48     94.11     95.38     95.81     97.28      96.31\n",
      "      2       91.47     84.78     83.46     85.23     90.48     91.58     94.39     95.30     95.76     97.04      96.71\n",
      "      3       91.31     84.19     82.93     84.52     90.75     91.36     94.29     95.27     95.65     97.04      97.07\n",
      "      4       91.39     84.75     83.03     85.01     90.39     91.30     94.30     95.30     95.52     97.18      97.14\n",
      "      5       91.45     84.41     83.58     84.98     90.96     91.45     94.28     95.19     95.46     97.02      97.14\n",
      "      6       91.15     84.46     82.26     84.33     90.23     91.01     94.19     95.21     95.41     96.94      97.43\n",
      "      7       91.15     84.46     82.24     83.87     90.57     91.21     93.87     95.37     95.43     97.01      97.44\n",
      "      8       91.13     83.58     83.08     84.26     90.68     91.27     93.91     95.00     95.30     96.80      97.44\n",
      "      9       90.92     83.76     82.86     83.75     90.22     90.32     93.70     95.01     95.24     96.86      97.52\n",
      "Adding inducing inputs to the coreset randomly, 10 samples in total, with each class getting the same number of samples\n",
      "For tasks seen so far, \n",
      "---\n",
      "Mean accuracy (test): 0.9092 \n",
      "Accuracies (test): [0.8376, 0.8286, 0.8375, 0.9022, 0.9032, 0.937, 0.9501, 0.9524, 0.9686, 0.9752]\n",
      "---\n",
      "\n",
      "\n",
      "------------------- DONE -------------------\n",
      "\n",
      "\n",
      "0.9092399999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = read_config_and_run(\"fsvi_minimal_coreset.pkl\", task_sequence)\n",
    "exp = lutils.read_exp(logdir)\n",
    "show_final_average_accuracy(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCL (random-choice coreset) <a name=\"res5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading experiments: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 5607.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache:\n",
      "Running on oat18.cs.ox.ac.uk\n",
      "Running with: python /auto/users/timner/qixuan/function-space-variational-inference/fsvi_cl/baselines/vcl/run_vcl.py --dataset pmnist --n_epochs 100 --batch_size 256 --hidden_size 100 --n_layers 2 --seed 7 --select_method random_choice --n_permuted_tasks 10 --logroot ablation --subdir reproduce_main_results_3 --n_coreset_inputs_per_task 200\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('Epoch:', '0001', 'cost=', '0.494620047')\n",
      "('Epoch:', '0006', 'cost=', '0.068687391')\n",
      "('Epoch:', '0011', 'cost=', '0.032833647')\n",
      "('Epoch:', '0016', 'cost=', '0.015344139')\n",
      "('Epoch:', '0021', 'cost=', '0.006667245')\n",
      "('Epoch:', '0026', 'cost=', '0.004755347')\n",
      "('Epoch:', '0031', 'cost=', '0.001242538')\n",
      "('Epoch:', '0036', 'cost=', '0.000305422')\n",
      "('Epoch:', '0041', 'cost=', '0.000169750')\n",
      "('Epoch:', '0046', 'cost=', '0.001465945')\n",
      "('Epoch:', '0051', 'cost=', '0.000185845')\n",
      "('Epoch:', '0056', 'cost=', '0.000103580')\n",
      "('Epoch:', '0061', 'cost=', '0.000062706')\n",
      "('Epoch:', '0066', 'cost=', '0.000037142')\n",
      "('Epoch:', '0071', 'cost=', '0.000021699')\n",
      "('Epoch:', '0076', 'cost=', '0.000012700')\n",
      "('Epoch:', '0081', 'cost=', '0.000498890')\n",
      "('Epoch:', '0086', 'cost=', '0.000080650')\n",
      "('Epoch:', '0091', 'cost=', '0.000045684')\n",
      "('Epoch:', '0096', 'cost=', '0.000027817')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '3.719999964')\n",
      "('Epoch:', '0006', 'cost=', '3.068726732')\n",
      "('Epoch:', '0011', 'cost=', '2.471644072')\n",
      "('Epoch:', '0016', 'cost=', '1.949530340')\n",
      "('Epoch:', '0021', 'cost=', '1.525171383')\n",
      "('Epoch:', '0026', 'cost=', '1.235027367')\n",
      "('Epoch:', '0031', 'cost=', '1.071485342')\n",
      "('Epoch:', '0036', 'cost=', '0.955264210')\n",
      "('Epoch:', '0041', 'cost=', '0.861240286')\n",
      "('Epoch:', '0046', 'cost=', '0.780641314')\n",
      "('Epoch:', '0051', 'cost=', '0.712325765')\n",
      "('Epoch:', '0056', 'cost=', '0.652889921')\n",
      "('Epoch:', '0061', 'cost=', '0.602924073')\n",
      "('Epoch:', '0066', 'cost=', '0.559976890')\n",
      "('Epoch:', '0071', 'cost=', '0.523752140')\n",
      "('Epoch:', '0076', 'cost=', '0.492286224')\n",
      "('Epoch:', '0081', 'cost=', '0.465231498')\n",
      "('Epoch:', '0086', 'cost=', '0.442393973')\n",
      "('Epoch:', '0091', 'cost=', '0.419284233')\n",
      "('Epoch:', '0096', 'cost=', '0.401471155')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '12.781785011')\n",
      "('Epoch:', '0006', 'cost=', '12.766431808')\n",
      "('Epoch:', '0011', 'cost=', '12.730389595')\n",
      "('Epoch:', '0016', 'cost=', '12.721552849')\n",
      "('Epoch:', '0021', 'cost=', '12.691448212')\n",
      "('Epoch:', '0026', 'cost=', '12.686961174')\n",
      "('Epoch:', '0031', 'cost=', '12.684742928')\n",
      "('Epoch:', '0036', 'cost=', '12.644677162')\n",
      "('Epoch:', '0041', 'cost=', '12.623793602')\n",
      "('Epoch:', '0046', 'cost=', '12.636015892')\n",
      "('Epoch:', '0051', 'cost=', '12.618396759')\n",
      "('Epoch:', '0056', 'cost=', '12.610642433')\n",
      "('Epoch:', '0061', 'cost=', '12.598072052')\n",
      "('Epoch:', '0066', 'cost=', '12.582851410')\n",
      "('Epoch:', '0071', 'cost=', '12.554226875')\n",
      "('Epoch:', '0076', 'cost=', '12.550589561')\n",
      "('Epoch:', '0081', 'cost=', '12.532691002')\n",
      "('Epoch:', '0086', 'cost=', '12.516596794')\n",
      "('Epoch:', '0091', 'cost=', '12.501760483')\n",
      "('Epoch:', '0096', 'cost=', '12.484856606')\n",
      "Optimization Finished!\n",
      "Accuracy at task 0: [0.982]\n",
      "('Epoch:', '0001', 'cost=', '2.984262899')\n",
      "('Epoch:', '0006', 'cost=', '0.772695393')\n",
      "('Epoch:', '0011', 'cost=', '0.529620461')\n",
      "('Epoch:', '0016', 'cost=', '0.426382332')\n",
      "('Epoch:', '0021', 'cost=', '0.367073960')\n",
      "('Epoch:', '0026', 'cost=', '0.329426404')\n",
      "('Epoch:', '0031', 'cost=', '0.306173224')\n",
      "('Epoch:', '0036', 'cost=', '0.290408158')\n",
      "('Epoch:', '0041', 'cost=', '0.279424598')\n",
      "('Epoch:', '0046', 'cost=', '0.271869173')\n",
      "('Epoch:', '0051', 'cost=', '0.264027369')\n",
      "('Epoch:', '0056', 'cost=', '0.259686236')\n",
      "('Epoch:', '0061', 'cost=', '0.255917856')\n",
      "('Epoch:', '0066', 'cost=', '0.252097843')\n",
      "('Epoch:', '0071', 'cost=', '0.250158588')\n",
      "('Epoch:', '0076', 'cost=', '0.248371471')\n",
      "('Epoch:', '0081', 'cost=', '0.247054946')\n",
      "('Epoch:', '0086', 'cost=', '0.244403329')\n",
      "('Epoch:', '0091', 'cost=', '0.242279894')\n",
      "('Epoch:', '0096', 'cost=', '0.241409274')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '6.528529167')\n",
      "('Epoch:', '0006', 'cost=', '6.465653419')\n",
      "('Epoch:', '0011', 'cost=', '6.442570448')\n",
      "('Epoch:', '0016', 'cost=', '6.417303324')\n",
      "('Epoch:', '0021', 'cost=', '6.395993233')\n",
      "('Epoch:', '0026', 'cost=', '6.393821955')\n",
      "('Epoch:', '0031', 'cost=', '6.383414745')\n",
      "('Epoch:', '0036', 'cost=', '6.365932226')\n",
      "('Epoch:', '0041', 'cost=', '6.349385500')\n",
      "('Epoch:', '0046', 'cost=', '6.361012220')\n",
      "('Epoch:', '0051', 'cost=', '6.321828842')\n",
      "('Epoch:', '0056', 'cost=', '6.308427811')\n",
      "('Epoch:', '0061', 'cost=', '6.292862415')\n",
      "('Epoch:', '0066', 'cost=', '6.288539648')\n",
      "('Epoch:', '0071', 'cost=', '6.284900427')\n",
      "('Epoch:', '0076', 'cost=', '6.248578787')\n",
      "('Epoch:', '0081', 'cost=', '6.252826452')\n",
      "('Epoch:', '0086', 'cost=', '6.234958410')\n",
      "('Epoch:', '0091', 'cost=', '6.226711512')\n",
      "('Epoch:', '0096', 'cost=', '6.220439672')\n",
      "Optimization Finished!\n",
      "Accuracy at task 1: [0.9767, 0.9723]\n",
      "('Epoch:', '0001', 'cost=', '2.119640406')\n",
      "('Epoch:', '0006', 'cost=', '0.538706906')\n",
      "('Epoch:', '0011', 'cost=', '0.404557829')\n",
      "('Epoch:', '0016', 'cost=', '0.344179789')\n",
      "('Epoch:', '0021', 'cost=', '0.306381085')\n",
      "('Epoch:', '0026', 'cost=', '0.283193375')\n",
      "('Epoch:', '0031', 'cost=', '0.269591298')\n",
      "('Epoch:', '0036', 'cost=', '0.260548609')\n",
      "('Epoch:', '0041', 'cost=', '0.252598482')\n",
      "('Epoch:', '0046', 'cost=', '0.247644572')\n",
      "('Epoch:', '0051', 'cost=', '0.244098697')\n",
      "('Epoch:', '0056', 'cost=', '0.241128559')\n",
      "('Epoch:', '0061', 'cost=', '0.237790339')\n",
      "('Epoch:', '0066', 'cost=', '0.237057203')\n",
      "('Epoch:', '0071', 'cost=', '0.233330908')\n",
      "('Epoch:', '0076', 'cost=', '0.233329620')\n",
      "('Epoch:', '0081', 'cost=', '0.231963639')\n",
      "('Epoch:', '0086', 'cost=', '0.230434051')\n",
      "('Epoch:', '0091', 'cost=', '0.228962795')\n",
      "('Epoch:', '0096', 'cost=', '0.228321768')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '4.395171324')\n",
      "('Epoch:', '0006', 'cost=', '4.338244279')\n",
      "('Epoch:', '0011', 'cost=', '4.313039462')\n",
      "('Epoch:', '0016', 'cost=', '4.296081702')\n",
      "('Epoch:', '0021', 'cost=', '4.306243896')\n",
      "('Epoch:', '0026', 'cost=', '4.276867390')\n",
      "('Epoch:', '0031', 'cost=', '4.272414366')\n",
      "('Epoch:', '0036', 'cost=', '4.240996838')\n",
      "('Epoch:', '0041', 'cost=', '4.243958314')\n",
      "('Epoch:', '0046', 'cost=', '4.231571515')\n",
      "('Epoch:', '0051', 'cost=', '4.228916486')\n",
      "('Epoch:', '0056', 'cost=', '4.199113846')\n",
      "('Epoch:', '0061', 'cost=', '4.191421668')\n",
      "('Epoch:', '0066', 'cost=', '4.172295411')\n",
      "('Epoch:', '0071', 'cost=', '4.154428005')\n",
      "('Epoch:', '0076', 'cost=', '4.153731346')\n",
      "('Epoch:', '0081', 'cost=', '4.130075455')\n",
      "('Epoch:', '0086', 'cost=', '4.121513844')\n",
      "('Epoch:', '0091', 'cost=', '4.114199162')\n",
      "('Epoch:', '0096', 'cost=', '4.100260417')\n",
      "Optimization Finished!\n",
      "Accuracy at task 2: [0.9693, 0.9666, 0.9698]\n",
      "('Epoch:', '0001', 'cost=', '2.094227778')\n",
      "('Epoch:', '0006', 'cost=', '0.545095312')\n",
      "('Epoch:', '0011', 'cost=', '0.418933937')\n",
      "('Epoch:', '0016', 'cost=', '0.357578539')\n",
      "('Epoch:', '0021', 'cost=', '0.320275315')\n",
      "('Epoch:', '0026', 'cost=', '0.295246491')\n",
      "('Epoch:', '0031', 'cost=', '0.280165974')\n",
      "('Epoch:', '0036', 'cost=', '0.271974711')\n",
      "('Epoch:', '0041', 'cost=', '0.263869017')\n",
      "('Epoch:', '0046', 'cost=', '0.259775536')\n",
      "('Epoch:', '0051', 'cost=', '0.255396358')\n",
      "('Epoch:', '0056', 'cost=', '0.251655965')\n",
      "('Epoch:', '0061', 'cost=', '0.249035459')\n",
      "('Epoch:', '0066', 'cost=', '0.246145678')\n",
      "('Epoch:', '0071', 'cost=', '0.244838529')\n",
      "('Epoch:', '0076', 'cost=', '0.243464718')\n",
      "('Epoch:', '0081', 'cost=', '0.241559678')\n",
      "('Epoch:', '0086', 'cost=', '0.240021390')\n",
      "('Epoch:', '0091', 'cost=', '0.239346816')\n",
      "('Epoch:', '0096', 'cost=', '0.238089560')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '3.444101095')\n",
      "('Epoch:', '0006', 'cost=', '3.362044692')\n",
      "('Epoch:', '0011', 'cost=', '3.319129229')\n",
      "('Epoch:', '0016', 'cost=', '3.287362516')\n",
      "('Epoch:', '0021', 'cost=', '3.287847817')\n",
      "('Epoch:', '0026', 'cost=', '3.280198395')\n",
      "('Epoch:', '0031', 'cost=', '3.250976443')\n",
      "('Epoch:', '0036', 'cost=', '3.237030864')\n",
      "('Epoch:', '0041', 'cost=', '3.231797338')\n",
      "('Epoch:', '0046', 'cost=', '3.208761513')\n",
      "('Epoch:', '0051', 'cost=', '3.209842443')\n",
      "('Epoch:', '0056', 'cost=', '3.189182103')\n",
      "('Epoch:', '0061', 'cost=', '3.205524504')\n",
      "('Epoch:', '0066', 'cost=', '3.168789625')\n",
      "('Epoch:', '0071', 'cost=', '3.149136543')\n",
      "('Epoch:', '0076', 'cost=', '3.177967310')\n",
      "('Epoch:', '0081', 'cost=', '3.138114870')\n",
      "('Epoch:', '0086', 'cost=', '3.138603628')\n",
      "('Epoch:', '0091', 'cost=', '3.113872826')\n",
      "('Epoch:', '0096', 'cost=', '3.078805089')\n",
      "Optimization Finished!\n",
      "Accuracy at task 3: [0.9584, 0.9594, 0.9653, 0.9698]\n",
      "('Epoch:', '0001', 'cost=', '2.009228189')\n",
      "('Epoch:', '0006', 'cost=', '0.530350132')\n",
      "('Epoch:', '0011', 'cost=', '0.413059432')\n",
      "('Epoch:', '0016', 'cost=', '0.358467591')\n",
      "('Epoch:', '0021', 'cost=', '0.324785481')\n",
      "('Epoch:', '0026', 'cost=', '0.303483216')\n",
      "('Epoch:', '0031', 'cost=', '0.290363498')\n",
      "('Epoch:', '0036', 'cost=', '0.281431121')\n",
      "('Epoch:', '0041', 'cost=', '0.274880683')\n",
      "('Epoch:', '0046', 'cost=', '0.270032663')\n",
      "('Epoch:', '0051', 'cost=', '0.265638330')\n",
      "('Epoch:', '0056', 'cost=', '0.261457147')\n",
      "('Epoch:', '0061', 'cost=', '0.258051841')\n",
      "('Epoch:', '0066', 'cost=', '0.256414308')\n",
      "('Epoch:', '0071', 'cost=', '0.253799382')\n",
      "('Epoch:', '0076', 'cost=', '0.252485207')\n",
      "('Epoch:', '0081', 'cost=', '0.250481656')\n",
      "('Epoch:', '0086', 'cost=', '0.249221877')\n",
      "('Epoch:', '0091', 'cost=', '0.247847683')\n",
      "('Epoch:', '0096', 'cost=', '0.247552436')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '2.838107288')\n",
      "('Epoch:', '0006', 'cost=', '2.763146818')\n",
      "('Epoch:', '0011', 'cost=', '2.734377265')\n",
      "('Epoch:', '0016', 'cost=', '2.715497673')\n",
      "('Epoch:', '0021', 'cost=', '2.709399998')\n",
      "('Epoch:', '0026', 'cost=', '2.690726876')\n",
      "('Epoch:', '0031', 'cost=', '2.686800122')\n",
      "('Epoch:', '0036', 'cost=', '2.676943064')\n",
      "('Epoch:', '0041', 'cost=', '2.666506350')\n",
      "('Epoch:', '0046', 'cost=', '2.645409524')\n",
      "('Epoch:', '0051', 'cost=', '2.634024680')\n",
      "('Epoch:', '0056', 'cost=', '2.628730536')\n",
      "('Epoch:', '0061', 'cost=', '2.616619825')\n",
      "('Epoch:', '0066', 'cost=', '2.607920766')\n",
      "('Epoch:', '0071', 'cost=', '2.600970924')\n",
      "('Epoch:', '0076', 'cost=', '2.585838735')\n",
      "('Epoch:', '0081', 'cost=', '2.580672026')\n",
      "('Epoch:', '0086', 'cost=', '2.574594975')\n",
      "('Epoch:', '0091', 'cost=', '2.554507494')\n",
      "('Epoch:', '0096', 'cost=', '2.551685989')\n",
      "Optimization Finished!\n",
      "Accuracy at task 4: [0.9486, 0.9525, 0.958, 0.963, 0.9669]\n",
      "('Epoch:', '0001', 'cost=', '1.853626993')\n",
      "('Epoch:', '0006', 'cost=', '0.491240461')\n",
      "('Epoch:', '0011', 'cost=', '0.389773543')\n",
      "('Epoch:', '0016', 'cost=', '0.339892928')\n",
      "('Epoch:', '0021', 'cost=', '0.308584511')\n",
      "('Epoch:', '0026', 'cost=', '0.289742796')\n",
      "('Epoch:', '0031', 'cost=', '0.278591972')\n",
      "('Epoch:', '0036', 'cost=', '0.272368737')\n",
      "('Epoch:', '0041', 'cost=', '0.266512281')\n",
      "('Epoch:', '0046', 'cost=', '0.262027203')\n",
      "('Epoch:', '0051', 'cost=', '0.260055760')\n",
      "('Epoch:', '0056', 'cost=', '0.257791237')\n",
      "('Epoch:', '0061', 'cost=', '0.257267838')\n",
      "('Epoch:', '0066', 'cost=', '0.255373643')\n",
      "('Epoch:', '0071', 'cost=', '0.254396806')\n",
      "('Epoch:', '0076', 'cost=', '0.252700990')\n",
      "('Epoch:', '0081', 'cost=', '0.251200929')\n",
      "('Epoch:', '0086', 'cost=', '0.250516230')\n",
      "('Epoch:', '0091', 'cost=', '0.250952340')\n",
      "('Epoch:', '0096', 'cost=', '0.249811761')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '2.442722750')\n",
      "('Epoch:', '0006', 'cost=', '2.345292282')\n",
      "('Epoch:', '0011', 'cost=', '2.325143337')\n",
      "('Epoch:', '0016', 'cost=', '2.313394547')\n",
      "('Epoch:', '0021', 'cost=', '2.297265339')\n",
      "('Epoch:', '0026', 'cost=', '2.290088797')\n",
      "('Epoch:', '0031', 'cost=', '2.274447012')\n",
      "('Epoch:', '0036', 'cost=', '2.267647648')\n",
      "('Epoch:', '0041', 'cost=', '2.247578049')\n",
      "('Epoch:', '0046', 'cost=', '2.244851494')\n",
      "('Epoch:', '0051', 'cost=', '2.233240509')\n",
      "('Epoch:', '0056', 'cost=', '2.213655233')\n",
      "('Epoch:', '0061', 'cost=', '2.210790253')\n",
      "('Epoch:', '0066', 'cost=', '2.200721264')\n",
      "('Epoch:', '0071', 'cost=', '2.185442114')\n",
      "('Epoch:', '0076', 'cost=', '2.173857260')\n",
      "('Epoch:', '0081', 'cost=', '2.162053823')\n",
      "('Epoch:', '0086', 'cost=', '2.149876976')\n",
      "('Epoch:', '0091', 'cost=', '2.147154665')\n",
      "('Epoch:', '0096', 'cost=', '2.149634218')\n",
      "Optimization Finished!\n",
      "Accuracy at task 5: [0.9371, 0.9469, 0.9518, 0.9536, 0.9587, 0.9666]\n",
      "('Epoch:', '0001', 'cost=', '1.805621501')\n",
      "('Epoch:', '0006', 'cost=', '0.490706476')\n",
      "('Epoch:', '0011', 'cost=', '0.391218398')\n",
      "('Epoch:', '0016', 'cost=', '0.346057384')\n",
      "('Epoch:', '0021', 'cost=', '0.316623040')\n",
      "('Epoch:', '0026', 'cost=', '0.298925398')\n",
      "('Epoch:', '0031', 'cost=', '0.289177419')\n",
      "('Epoch:', '0036', 'cost=', '0.284494839')\n",
      "('Epoch:', '0041', 'cost=', '0.278336116')\n",
      "('Epoch:', '0046', 'cost=', '0.275276904')\n",
      "('Epoch:', '0051', 'cost=', '0.271879012')\n",
      "('Epoch:', '0056', 'cost=', '0.270529693')\n",
      "('Epoch:', '0061', 'cost=', '0.267807795')\n",
      "('Epoch:', '0066', 'cost=', '0.266940607')\n",
      "('Epoch:', '0071', 'cost=', '0.264554771')\n",
      "('Epoch:', '0076', 'cost=', '0.264385981')\n",
      "('Epoch:', '0081', 'cost=', '0.263684251')\n",
      "('Epoch:', '0086', 'cost=', '0.261866774')\n",
      "('Epoch:', '0091', 'cost=', '0.261579800')\n",
      "('Epoch:', '0096', 'cost=', '0.260613604')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '2.197102745')\n",
      "('Epoch:', '0006', 'cost=', '2.078032533')\n",
      "('Epoch:', '0011', 'cost=', '2.055415829')\n",
      "('Epoch:', '0016', 'cost=', '2.024687429')\n",
      "('Epoch:', '0021', 'cost=', '2.011182268')\n",
      "('Epoch:', '0026', 'cost=', '2.017105381')\n",
      "('Epoch:', '0031', 'cost=', '1.996701141')\n",
      "('Epoch:', '0036', 'cost=', '1.984196226')\n",
      "('Epoch:', '0041', 'cost=', '1.974894881')\n",
      "('Epoch:', '0046', 'cost=', '1.957092365')\n",
      "('Epoch:', '0051', 'cost=', '1.961089830')\n",
      "('Epoch:', '0056', 'cost=', '1.947194636')\n",
      "('Epoch:', '0061', 'cost=', '1.931791782')\n",
      "('Epoch:', '0066', 'cost=', '1.933656315')\n",
      "('Epoch:', '0071', 'cost=', '1.908611993')\n",
      "('Epoch:', '0076', 'cost=', '1.902472516')\n",
      "('Epoch:', '0081', 'cost=', '1.890715023')\n",
      "('Epoch:', '0086', 'cost=', '1.876179000')\n",
      "('Epoch:', '0091', 'cost=', '1.863513192')\n",
      "('Epoch:', '0096', 'cost=', '1.875307937')\n",
      "Optimization Finished!\n",
      "Accuracy at task 6: [0.9253, 0.9366, 0.9418, 0.9537, 0.9544, 0.9632, 0.96]\n",
      "('Epoch:', '0001', 'cost=', '1.748152025')\n",
      "('Epoch:', '0006', 'cost=', '0.454974896')\n",
      "('Epoch:', '0011', 'cost=', '0.364199409')\n",
      "('Epoch:', '0016', 'cost=', '0.325545137')\n",
      "('Epoch:', '0021', 'cost=', '0.300784531')\n",
      "('Epoch:', '0026', 'cost=', '0.287064333')\n",
      "('Epoch:', '0031', 'cost=', '0.278903987')\n",
      "('Epoch:', '0036', 'cost=', '0.273758247')\n",
      "('Epoch:', '0041', 'cost=', '0.269973349')\n",
      "('Epoch:', '0046', 'cost=', '0.267752766')\n",
      "('Epoch:', '0051', 'cost=', '0.265147713')\n",
      "('Epoch:', '0056', 'cost=', '0.263999743')\n",
      "('Epoch:', '0061', 'cost=', '0.261902106')\n",
      "('Epoch:', '0066', 'cost=', '0.260777651')\n",
      "('Epoch:', '0071', 'cost=', '0.260176360')\n",
      "('Epoch:', '0076', 'cost=', '0.258140283')\n",
      "('Epoch:', '0081', 'cost=', '0.258174400')\n",
      "('Epoch:', '0086', 'cost=', '0.257034599')\n",
      "('Epoch:', '0091', 'cost=', '0.256855815')\n",
      "('Epoch:', '0096', 'cost=', '0.257176143')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '1.992482083')\n",
      "('Epoch:', '0006', 'cost=', '1.879645910')\n",
      "('Epoch:', '0011', 'cost=', '1.845419935')\n",
      "('Epoch:', '0016', 'cost=', '1.814990452')\n",
      "('Epoch:', '0021', 'cost=', '1.814053995')\n",
      "('Epoch:', '0026', 'cost=', '1.791321227')\n",
      "('Epoch:', '0031', 'cost=', '1.777761306')\n",
      "('Epoch:', '0036', 'cost=', '1.778530104')\n",
      "('Epoch:', '0041', 'cost=', '1.765129736')\n",
      "('Epoch:', '0046', 'cost=', '1.745495183')\n",
      "('Epoch:', '0051', 'cost=', '1.744141272')\n",
      "('Epoch:', '0056', 'cost=', '1.718563199')\n",
      "('Epoch:', '0061', 'cost=', '1.722490396')\n",
      "('Epoch:', '0066', 'cost=', '1.718766962')\n",
      "('Epoch:', '0071', 'cost=', '1.695124252')\n",
      "('Epoch:', '0076', 'cost=', '1.686957955')\n",
      "('Epoch:', '0081', 'cost=', '1.673137937')\n",
      "('Epoch:', '0086', 'cost=', '1.663657631')\n",
      "('Epoch:', '0091', 'cost=', '1.662797570')\n",
      "('Epoch:', '0096', 'cost=', '1.647654040')\n",
      "Optimization Finished!\n",
      "Accuracy at task 7: [0.9157, 0.9245, 0.9262, 0.9459, 0.9461, 0.9579, 0.9541, 0.9623]\n",
      "('Epoch:', '0001', 'cost=', '1.930471847')\n",
      "('Epoch:', '0006', 'cost=', '0.489964404')\n",
      "('Epoch:', '0011', 'cost=', '0.395800202')\n",
      "('Epoch:', '0016', 'cost=', '0.348403189')\n",
      "('Epoch:', '0021', 'cost=', '0.321565197')\n",
      "('Epoch:', '0026', 'cost=', '0.302187780')\n",
      "('Epoch:', '0031', 'cost=', '0.291627300')\n",
      "('Epoch:', '0036', 'cost=', '0.285002635')\n",
      "('Epoch:', '0041', 'cost=', '0.279953000')\n",
      "('Epoch:', '0046', 'cost=', '0.275888812')\n",
      "('Epoch:', '0051', 'cost=', '0.271752261')\n",
      "('Epoch:', '0056', 'cost=', '0.270890007')\n",
      "('Epoch:', '0061', 'cost=', '0.269489286')\n",
      "('Epoch:', '0066', 'cost=', '0.267356144')\n",
      "('Epoch:', '0071', 'cost=', '0.266474349')\n",
      "('Epoch:', '0076', 'cost=', '0.265666397')\n",
      "('Epoch:', '0081', 'cost=', '0.263914921')\n",
      "('Epoch:', '0086', 'cost=', '0.263912280')\n",
      "('Epoch:', '0091', 'cost=', '0.262310317')\n",
      "('Epoch:', '0096', 'cost=', '0.262154386')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '1.902505428')\n",
      "('Epoch:', '0006', 'cost=', '1.722561538')\n",
      "('Epoch:', '0011', 'cost=', '1.708068460')\n",
      "('Epoch:', '0016', 'cost=', '1.667666852')\n",
      "('Epoch:', '0021', 'cost=', '1.665013075')\n",
      "('Epoch:', '0026', 'cost=', '1.643661916')\n",
      "('Epoch:', '0031', 'cost=', '1.634663582')\n",
      "('Epoch:', '0036', 'cost=', '1.623690888')\n",
      "('Epoch:', '0041', 'cost=', '1.617990643')\n",
      "('Epoch:', '0046', 'cost=', '1.616635188')\n",
      "('Epoch:', '0051', 'cost=', '1.595387876')\n",
      "('Epoch:', '0056', 'cost=', '1.574585333')\n",
      "('Epoch:', '0061', 'cost=', '1.552627802')\n",
      "('Epoch:', '0066', 'cost=', '1.580542833')\n",
      "('Epoch:', '0071', 'cost=', '1.560859963')\n",
      "('Epoch:', '0076', 'cost=', '1.565777153')\n",
      "('Epoch:', '0081', 'cost=', '1.737982899')\n",
      "('Epoch:', '0086', 'cost=', '1.504031152')\n",
      "('Epoch:', '0091', 'cost=', '1.519699201')\n",
      "('Epoch:', '0096', 'cost=', '1.498351514')\n",
      "Optimization Finished!\n",
      "Accuracy at task 8: [0.902, 0.9236, 0.9125, 0.9287, 0.9387, 0.9497, 0.9449, 0.9522, 0.9641]\n",
      "('Epoch:', '0001', 'cost=', '1.824066442')\n",
      "('Epoch:', '0006', 'cost=', '0.477246291')\n",
      "('Epoch:', '0011', 'cost=', '0.390035951')\n",
      "('Epoch:', '0016', 'cost=', '0.351408578')\n",
      "('Epoch:', '0021', 'cost=', '0.325686369')\n",
      "('Epoch:', '0026', 'cost=', '0.310369737')\n",
      "('Epoch:', '0031', 'cost=', '0.302631466')\n",
      "('Epoch:', '0036', 'cost=', '0.296569813')\n",
      "('Epoch:', '0041', 'cost=', '0.291641583')\n",
      "('Epoch:', '0046', 'cost=', '0.287691780')\n",
      "('Epoch:', '0051', 'cost=', '0.285036184')\n",
      "('Epoch:', '0056', 'cost=', '0.280991640')\n",
      "('Epoch:', '0061', 'cost=', '0.279576546')\n",
      "('Epoch:', '0066', 'cost=', '0.278094103')\n",
      "('Epoch:', '0071', 'cost=', '0.276230169')\n",
      "('Epoch:', '0076', 'cost=', '0.274990248')\n",
      "('Epoch:', '0081', 'cost=', '0.274482174')\n",
      "('Epoch:', '0086', 'cost=', '0.272744496')\n",
      "('Epoch:', '0091', 'cost=', '0.272036749')\n",
      "('Epoch:', '0096', 'cost=', '0.271280935')\n",
      "Optimization Finished!\n",
      "('Epoch:', '0001', 'cost=', '1.895187005')\n",
      "('Epoch:', '0006', 'cost=', '1.657626584')\n",
      "('Epoch:', '0011', 'cost=', '1.610231221')\n",
      "('Epoch:', '0016', 'cost=', '1.590883538')\n",
      "('Epoch:', '0021', 'cost=', '1.580798894')\n",
      "('Epoch:', '0026', 'cost=', '1.561099350')\n",
      "('Epoch:', '0031', 'cost=', '1.549867839')\n",
      "('Epoch:', '0036', 'cost=', '1.544437900')\n",
      "('Epoch:', '0041', 'cost=', '1.531708539')\n",
      "('Epoch:', '0046', 'cost=', '1.521002337')\n",
      "('Epoch:', '0051', 'cost=', '1.515435800')\n",
      "('Epoch:', '0056', 'cost=', '1.499354064')\n",
      "('Epoch:', '0061', 'cost=', '1.488728493')\n",
      "('Epoch:', '0066', 'cost=', '1.474797264')\n",
      "('Epoch:', '0071', 'cost=', '1.467226639')\n",
      "('Epoch:', '0076', 'cost=', '1.456013292')\n",
      "('Epoch:', '0081', 'cost=', '1.446380913')\n",
      "('Epoch:', '0086', 'cost=', '1.439006791')\n",
      "('Epoch:', '0091', 'cost=', '1.426636532')\n",
      "('Epoch:', '0096', 'cost=', '1.418462187')\n",
      "Optimization Finished!\n",
      "Accuracy at task 9: [0.8903, 0.915, 0.8883, 0.917, 0.9293, 0.9406, 0.9281, 0.9427, 0.9538, 0.96]\n",
      "[[0.982     nan    nan    nan    nan    nan    nan    nan    nan    nan]\n",
      " [0.9767 0.9723    nan    nan    nan    nan    nan    nan    nan    nan]\n",
      " [0.9693 0.9666 0.9698    nan    nan    nan    nan    nan    nan    nan]\n",
      " [0.9584 0.9594 0.9653 0.9698    nan    nan    nan    nan    nan    nan]\n",
      " [0.9486 0.9525 0.958  0.963  0.9669    nan    nan    nan    nan    nan]\n",
      " [0.9371 0.9469 0.9518 0.9536 0.9587 0.9666    nan    nan    nan    nan]\n",
      " [0.9253 0.9366 0.9418 0.9537 0.9544 0.9632 0.96      nan    nan    nan]\n",
      " [0.9157 0.9245 0.9262 0.9459 0.9461 0.9579 0.9541 0.9623    nan    nan]\n",
      " [0.902  0.9236 0.9125 0.9287 0.9387 0.9497 0.9449 0.9522 0.9641    nan]\n",
      " [0.8903 0.915  0.8883 0.917  0.9293 0.9406 0.9281 0.9427 0.9538 0.96  ]]\n",
      "\n",
      "0.9265100000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logdir = read_config_and_run(\"vcl_random_coreset.pkl\", task_sequence, \"vcl\")\n",
    "exp = lutils.read_exp(logdir)\n",
    "show_final_average_accuracy(exp, runner=\"vcl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsvi",
   "language": "python",
   "name": "fsvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}